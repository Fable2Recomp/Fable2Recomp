#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_82C8E1BC"))) PPC_WEAK_FUNC(sub_82C8E1BC);
PPC_FUNC_IMPL(__imp__sub_82C8E1BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C8E1C0"))) PPC_WEAK_FUNC(sub_82C8E1C0);
PPC_FUNC_IMPL(__imp__sub_82C8E1C0) {
	PPC_FUNC_PROLOGUE();
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C8E1C8;
	sub_82CA2BE4(ctx, base);
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e710
	if (ctx.cr6.eq) goto loc_82C8E710;
	// lis r11,511
	ctx.r11.s64 = 33488896;
	// li r30,-16
	ctx.r30.s64 = -16;
	// ori r8,r11,65535
	ctx.r8.u64 = ctx.r11.u64 | 65535;
loc_82C8E1E0:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// mr r31,r9
	ctx.r31.u64 = ctx.r9.u64;
	// cmplwi cr6,r31,219
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 219, ctx.xer);
	// bgt cr6,0x82c8e6a0
	if (ctx.cr6.gt) goto loc_82C8E6A0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-7668
	ctx.r12.s64 = ctx.r12.s64 + -7668;
	// rlwinm r0,r31,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r31.u64) {
	case 0:
		goto loc_82C8E57C;
	case 1:
		goto loc_82C8E59C;
	case 2:
		goto loc_82C8E59C;
	case 3:
		goto loc_82C8E59C;
	case 4:
		goto loc_82C8E59C;
	case 5:
		goto loc_82C8E59C;
	case 6:
		goto loc_82C8E59C;
	case 7:
		goto loc_82C8E59C;
	case 8:
		goto loc_82C8E6A0;
	case 9:
		goto loc_82C8E6A0;
	case 10:
		goto loc_82C8E6A0;
	case 11:
		goto loc_82C8E6A0;
	case 12:
		goto loc_82C8E6A0;
	case 13:
		goto loc_82C8E6A0;
	case 14:
		goto loc_82C8E6A0;
	case 15:
		goto loc_82C8E6A0;
	case 16:
		goto loc_82C8E6A0;
	case 17:
		goto loc_82C8E6A0;
	case 18:
		goto loc_82C8E6A0;
	case 19:
		goto loc_82C8E6A0;
	case 20:
		goto loc_82C8E6A0;
	case 21:
		goto loc_82C8E6A0;
	case 22:
		goto loc_82C8E6A0;
	case 23:
		goto loc_82C8E6A0;
	case 24:
		goto loc_82C8E6A0;
	case 25:
		goto loc_82C8E6A0;
	case 26:
		goto loc_82C8E6A0;
	case 27:
		goto loc_82C8E6A0;
	case 28:
		goto loc_82C8E6A0;
	case 29:
		goto loc_82C8E6A0;
	case 30:
		goto loc_82C8E6A0;
	case 31:
		goto loc_82C8E6A0;
	case 32:
		goto loc_82C8E6A0;
	case 33:
		goto loc_82C8E6A0;
	case 34:
		goto loc_82C8E6A0;
	case 35:
		goto loc_82C8E6A0;
	case 36:
		goto loc_82C8E6A0;
	case 37:
		goto loc_82C8E6A0;
	case 38:
		goto loc_82C8E6A0;
	case 39:
		goto loc_82C8E6A0;
	case 40:
		goto loc_82C8E6A0;
	case 41:
		goto loc_82C8E6A0;
	case 42:
		goto loc_82C8E6A0;
	case 43:
		goto loc_82C8E6A0;
	case 44:
		goto loc_82C8E6A0;
	case 45:
		goto loc_82C8E6A0;
	case 46:
		goto loc_82C8E6A0;
	case 47:
		goto loc_82C8E6A0;
	case 48:
		goto loc_82C8E6A0;
	case 49:
		goto loc_82C8E6A0;
	case 50:
		goto loc_82C8E6A0;
	case 51:
		goto loc_82C8E6A0;
	case 52:
		goto loc_82C8E6A0;
	case 53:
		goto loc_82C8E6A0;
	case 54:
		goto loc_82C8E6A0;
	case 55:
		goto loc_82C8E6A0;
	case 56:
		goto loc_82C8E6A0;
	case 57:
		goto loc_82C8E6A0;
	case 58:
		goto loc_82C8E6A0;
	case 59:
		goto loc_82C8E6A0;
	case 60:
		goto loc_82C8E6A0;
	case 61:
		goto loc_82C8E6A0;
	case 62:
		goto loc_82C8E6A0;
	case 63:
		goto loc_82C8E6A0;
	case 64:
		goto loc_82C8E6A0;
	case 65:
		goto loc_82C8E6A0;
	case 66:
		goto loc_82C8E6A0;
	case 67:
		goto loc_82C8E6A0;
	case 68:
		goto loc_82C8E6A0;
	case 69:
		goto loc_82C8E6A0;
	case 70:
		goto loc_82C8E6A0;
	case 71:
		goto loc_82C8E6A0;
	case 72:
		goto loc_82C8E6A0;
	case 73:
		goto loc_82C8E6A0;
	case 74:
		goto loc_82C8E6A0;
	case 75:
		goto loc_82C8E6A0;
	case 76:
		goto loc_82C8E6A0;
	case 77:
		goto loc_82C8E6A0;
	case 78:
		goto loc_82C8E6A0;
	case 79:
		goto loc_82C8E6A0;
	case 80:
		goto loc_82C8E6A0;
	case 81:
		goto loc_82C8E6A0;
	case 82:
		goto loc_82C8E6A0;
	case 83:
		goto loc_82C8E6A0;
	case 84:
		goto loc_82C8E6A0;
	case 85:
		goto loc_82C8E6A0;
	case 86:
		goto loc_82C8E6A0;
	case 87:
		goto loc_82C8E6A0;
	case 88:
		goto loc_82C8E6A0;
	case 89:
		goto loc_82C8E6A0;
	case 90:
		goto loc_82C8E6A0;
	case 91:
		goto loc_82C8E6A0;
	case 92:
		goto loc_82C8E6A0;
	case 93:
		goto loc_82C8E6A0;
	case 94:
		goto loc_82C8E6A0;
	case 95:
		goto loc_82C8E6A0;
	case 96:
		goto loc_82C8E6A0;
	case 97:
		goto loc_82C8E6A0;
	case 98:
		goto loc_82C8E6A0;
	case 99:
		goto loc_82C8E6A0;
	case 100:
		goto loc_82C8E6A0;
	case 101:
		goto loc_82C8E6A0;
	case 102:
		goto loc_82C8E6A0;
	case 103:
		goto loc_82C8E6A0;
	case 104:
		goto loc_82C8E6A0;
	case 105:
		goto loc_82C8E6A0;
	case 106:
		goto loc_82C8E6A0;
	case 107:
		goto loc_82C8E6A0;
	case 108:
		goto loc_82C8E6A0;
	case 109:
		goto loc_82C8E6A0;
	case 110:
		goto loc_82C8E6A0;
	case 111:
		goto loc_82C8E6A0;
	case 112:
		goto loc_82C8E6A0;
	case 113:
		goto loc_82C8E6A0;
	case 114:
		goto loc_82C8E6A0;
	case 115:
		goto loc_82C8E6A0;
	case 116:
		goto loc_82C8E6A0;
	case 117:
		goto loc_82C8E6A0;
	case 118:
		goto loc_82C8E6A0;
	case 119:
		goto loc_82C8E6A0;
	case 120:
		goto loc_82C8E6A0;
	case 121:
		goto loc_82C8E6A0;
	case 122:
		goto loc_82C8E6A0;
	case 123:
		goto loc_82C8E6A0;
	case 124:
		goto loc_82C8E6A0;
	case 125:
		goto loc_82C8E6A0;
	case 126:
		goto loc_82C8E6A0;
	case 127:
		goto loc_82C8E6A0;
	case 128:
		goto loc_82C8E6A0;
	case 129:
		goto loc_82C8E6A0;
	case 130:
		goto loc_82C8E6A0;
	case 131:
		goto loc_82C8E6A0;
	case 132:
		goto loc_82C8E6A0;
	case 133:
		goto loc_82C8E6A0;
	case 134:
		goto loc_82C8E6A0;
	case 135:
		goto loc_82C8E6A0;
	case 136:
		goto loc_82C8E6A0;
	case 137:
		goto loc_82C8E6A0;
	case 138:
		goto loc_82C8E6A0;
	case 139:
		goto loc_82C8E6A0;
	case 140:
		goto loc_82C8E6A0;
	case 141:
		goto loc_82C8E6A0;
	case 142:
		goto loc_82C8E6A0;
	case 143:
		goto loc_82C8E6A0;
	case 144:
		goto loc_82C8E6A0;
	case 145:
		goto loc_82C8E6A0;
	case 146:
		goto loc_82C8E6A0;
	case 147:
		goto loc_82C8E6A0;
	case 148:
		goto loc_82C8E6A0;
	case 149:
		goto loc_82C8E6A0;
	case 150:
		goto loc_82C8E6A0;
	case 151:
		goto loc_82C8E6A0;
	case 152:
		goto loc_82C8E6A0;
	case 153:
		goto loc_82C8E6A0;
	case 154:
		goto loc_82C8E6A0;
	case 155:
		goto loc_82C8E6A0;
	case 156:
		goto loc_82C8E6A0;
	case 157:
		goto loc_82C8E6A0;
	case 158:
		goto loc_82C8E6A0;
	case 159:
		goto loc_82C8E6A0;
	case 160:
		goto loc_82C8E6A0;
	case 161:
		goto loc_82C8E6A0;
	case 162:
		goto loc_82C8E6A0;
	case 163:
		goto loc_82C8E6A0;
	case 164:
		goto loc_82C8E6A0;
	case 165:
		goto loc_82C8E6A0;
	case 166:
		goto loc_82C8E6A0;
	case 167:
		goto loc_82C8E6A0;
	case 168:
		goto loc_82C8E6A0;
	case 169:
		goto loc_82C8E6A0;
	case 170:
		goto loc_82C8E6A0;
	case 171:
		goto loc_82C8E6A0;
	case 172:
		goto loc_82C8E6A0;
	case 173:
		goto loc_82C8E6A0;
	case 174:
		goto loc_82C8E6A0;
	case 175:
		goto loc_82C8E6A0;
	case 176:
		goto loc_82C8E6A0;
	case 177:
		goto loc_82C8E6A0;
	case 178:
		goto loc_82C8E6A0;
	case 179:
		goto loc_82C8E6A0;
	case 180:
		goto loc_82C8E6A0;
	case 181:
		goto loc_82C8E6A0;
	case 182:
		goto loc_82C8E6A0;
	case 183:
		goto loc_82C8E6A0;
	case 184:
		goto loc_82C8E6A0;
	case 185:
		goto loc_82C8E6A0;
	case 186:
		goto loc_82C8E6A0;
	case 187:
		goto loc_82C8E6A0;
	case 188:
		goto loc_82C8E6A0;
	case 189:
		goto loc_82C8E6A0;
	case 190:
		goto loc_82C8E6A0;
	case 191:
		goto loc_82C8E6A0;
	case 192:
		goto loc_82C8E6A0;
	case 193:
		goto loc_82C8E6A0;
	case 194:
		goto loc_82C8E6A0;
	case 195:
		goto loc_82C8E6A0;
	case 196:
		goto loc_82C8E6A0;
	case 197:
		goto loc_82C8E6A0;
	case 198:
		goto loc_82C8E6A0;
	case 199:
		goto loc_82C8E6A0;
	case 200:
		goto loc_82C8E6A0;
	case 201:
		goto loc_82C8E6A0;
	case 202:
		goto loc_82C8E6A0;
	case 203:
		goto loc_82C8E6A0;
	case 204:
		goto loc_82C8E6A0;
	case 205:
		goto loc_82C8E6A0;
	case 206:
		goto loc_82C8E6A0;
	case 207:
		goto loc_82C8E6A0;
	case 208:
		goto loc_82C8E6A0;
	case 209:
		goto loc_82C8E6A0;
	case 210:
		goto loc_82C8E6A0;
	case 211:
		goto loc_82C8E6A0;
	case 212:
		goto loc_82C8E6A0;
	case 213:
		goto loc_82C8E6A0;
	case 214:
		goto loc_82C8E6A0;
	case 215:
		goto loc_82C8E6A0;
	case 216:
		goto loc_82C8E5F0;
	case 217:
		goto loc_82C8E5F0;
	case 218:
		goto loc_82C8E5F0;
	case 219:
		goto loc_82C8E5F0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-6788(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6788);
	// lwz r22,-6756(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6756(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6756);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6496(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6496);
	// lwz r22,-6672(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6672);
	// lwz r22,-6672(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6672);
	// lwz r22,-6672(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6672);
	// lwz r22,-6672(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6672);
loc_82C8E57C:
	// clrlwi r3,r11,24
	ctx.r3.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r3,128
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 128, ctx.xer);
	// bge cr6,0x82c8e59c
	if (!ctx.cr6.lt) goto loc_82C8E59C;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r9,r7
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x82c8e710
	if (ctx.cr6.eq) goto loc_82C8E710;
	// stb r11,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r11.u8);
	// b 0x82c8e6f8
	goto loc_82C8E6F8;
loc_82C8E59C:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r31,r3,r7
	ctx.r31.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r31,2
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 2, ctx.xer);
	// blt cr6,0x82c8e710
	if (ctx.cr6.lt) goto loc_82C8E710;
	// extsb r9,r9
	ctx.r9.s64 = ctx.r9.s8;
	// li r31,-64
	ctx.r31.s64 = -64;
	// rlwinm r29,r11,26,30,31
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3;
	// rlwimi r31,r9,2,26,29
	ctx.r31.u64 = (__builtin_rotateleft32(ctx.r9.u32, 2) & 0x3C) | (ctx.r31.u64 & 0xFFFFFFFFFFFFFFC3);
	// rlwimi r11,r8,7,0,25
	ctx.r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (ctx.r11.u64 & 0xFFFFFFFF0000003F);
	// extsb r9,r31
	ctx.r9.s64 = ctx.r31.s8;
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// or r9,r9,r29
	ctx.r9.u64 = ctx.r9.u64 | ctx.r29.u64;
	// stb r9,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, ctx.r9.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// stb r31,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r31.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = ctx.r11.s64 + 1;
	// stw r3,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r3.u32);
	// b 0x82c8e704
	goto loc_82C8E704;
loc_82C8E5F0:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r9,r3,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c8e710
	if (ctx.cr6.lt) goto loc_82C8E710;
	// rlwinm r9,r11,26,30,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3;
	// rlwinm r31,r31,2,28,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xC;
	// li r29,-128
	ctx.r29.s64 = -128;
	// or r9,r9,r31
	ctx.r9.u64 = ctx.r9.u64 | ctx.r31.u64;
	// rlwinm r31,r11,30,28,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0xF;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// li r28,-32
	ctx.r28.s64 = -32;
	// srawi r27,r9,2
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r27.s64 = ctx.r9.s32 >> 2;
	// rlwimi r29,r9,4,26,27
	ctx.r29.u64 = (__builtin_rotateleft32(ctx.r9.u32, 4) & 0x30) | (ctx.r29.u64 & 0xFFFFFFFFFFFFFFCF);
	// or r9,r27,r30
	ctx.r9.u64 = ctx.r27.u64 | ctx.r30.u64;
	// extsb r29,r29
	ctx.r29.s64 = ctx.r29.s8;
	// stb r9,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, ctx.r9.u8);
	// rlwimi r28,r11,2,28,29
	ctx.r28.u64 = (__builtin_rotateleft32(ctx.r11.u32, 2) & 0xC) | (ctx.r28.u64 & 0xFFFFFFFFFFFFFFF3);
	// or r3,r31,r29
	ctx.r3.u64 = ctx.r31.u64 | ctx.r29.u64;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r9,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r9.u32);
	// stb r3,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r3.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// clrlwi r3,r3,30
	ctx.r3.u64 = ctx.r3.u32 & 0x3;
	// or r3,r28,r3
	ctx.r3.u64 = ctx.r28.u64 | ctx.r3.u64;
	// rlwinm r31,r9,26,6,31
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 26) & 0x3FFFFFF;
	// rlwinm r3,r3,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwimi r9,r8,7,0,25
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (ctx.r9.u64 & 0xFFFFFFFF0000003F);
	// extsb r3,r3
	ctx.r3.s64 = ctx.r3.s8;
	// or r3,r3,r31
	ctx.r3.u64 = ctx.r3.u64 | ctx.r31.u64;
	// stb r3,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r3.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// stb r9,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r9.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r3,r11,1
	ctx.r3.s64 = ctx.r11.s64 + 1;
	// stw r3,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r3.u32);
	// b 0x82c8e704
	goto loc_82C8E704;
loc_82C8E6A0:
	// lwz r3,0(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// subf r31,r3,r7
	ctx.r31.s64 = ctx.r7.s64 - ctx.r3.s64;
	// cmpwi cr6,r31,3
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 3, ctx.xer);
	// blt cr6,0x82c8e710
	if (ctx.cr6.lt) goto loc_82C8E710;
	// li r31,-32
	ctx.r31.s64 = -32;
	// li r29,-128
	ctx.r29.s64 = -128;
	// rlwimi r31,r9,28,28,31
	ctx.r31.u64 = (__builtin_rotateleft32(ctx.r9.u32, 28) & 0xF) | (ctx.r31.u64 & 0xFFFFFFFFFFFFFFF0);
	// rlwimi r29,r9,2,26,29
	ctx.r29.u64 = (__builtin_rotateleft32(ctx.r9.u32, 2) & 0x3C) | (ctx.r29.u64 & 0xFFFFFFFFFFFFFFC3);
	// stb r31,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, ctx.r31.u8);
	// rlwinm r3,r11,26,30,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// addi r11,r9,1
	ctx.r11.s64 = ctx.r9.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// extsb r11,r29
	ctx.r11.s64 = ctx.r29.s8;
	// rlwimi r31,r8,7,0,25
	ctx.r31.u64 = (__builtin_rotateleft32(ctx.r8.u32, 7) & 0xFFFFFFC0) | (ctx.r31.u64 & 0xFFFFFFFF0000003F);
	// or r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 | ctx.r3.u64;
	// stb r3,1(r9)
	PPC_STORE_U8(ctx.r9.u32 + 1, ctx.r3.u8);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// stb r31,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r31.u8);
loc_82C8E6F8:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82C8E704:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8e1e0
	if (!ctx.cr6.eq) goto loc_82C8E1E0;
loc_82C8E710:
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
}

__attribute__((alias("__imp__sub_82C8E718"))) PPC_WEAK_FUNC(sub_82C8E718);
PPC_FUNC_IMPL(__imp__sub_82C8E718) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// subf r9,r10,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r10.s64;
	// subf r8,r11,r5
	ctx.r8.s64 = ctx.r5.s64 - ctx.r11.s64;
	// rlwinm r3,r9,0,0,30
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFE;
	// cmpw cr6,r8,r3
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r3.s32, ctx.xer);
	// ble cr6,0x82c8e748
	if (!ctx.cr6.gt) goto loc_82C8E748;
	// lbz r10,-2(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + -2);
	// rlwinm r9,r10,0,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF8;
	// cmplwi cr6,r9,216
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 216, ctx.xer);
	// bne cr6,0x82c8e748
	if (!ctx.cr6.eq) goto loc_82C8E748;
	// addi r5,r5,-2
	ctx.r5.s64 = ctx.r5.s64 + -2;
loc_82C8E748:
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82C8E750:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplw cr6,r11,r7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r7.u32, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rotlwi r3,r9,8
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// or r10,r3,r8
	ctx.r10.u64 = ctx.r3.u64 | ctx.r8.u64;
	// sth r10,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r10.u16);
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r8,r11,2
	ctx.r8.s64 = ctx.r11.s64 + 2;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r3,r11,2
	ctx.r3.s64 = ctx.r11.s64 + 2;
	// rotlwi r11,r3,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// stw r3,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r3.u32);
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8e750
	if (!ctx.cr6.eq) goto loc_82C8E750;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8E79C"))) PPC_WEAK_FUNC(sub_82C8E79C);
PPC_FUNC_IMPL(__imp__sub_82C8E79C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C8E7A0"))) PPC_WEAK_FUNC(sub_82C8E7A0);
PPC_FUNC_IMPL(__imp__sub_82C8E7A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e8ac
	if (ctx.cr6.eq) goto loc_82C8E8AC;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8e994
	if (!ctx.cr6.eq) goto loc_82C8E994;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,45
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 45, ctx.xer);
	// bne cr6,0x82c8e994
	if (!ctx.cr6.eq) goto loc_82C8E994;
	// addi r10,r4,2
	ctx.r10.s64 = ctx.r4.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e8ac
	if (ctx.cr6.eq) goto loc_82C8E8AC;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C8E7E0:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8e7fc
	if (!ctx.cr6.eq) goto loc_82C8E7FC;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8e804
	goto loc_82C8E804;
loc_82C8E7FC:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8E804;
	sub_82C8DAE8(ctx, base);
loc_82C8E804:
	// cmplwi cr6,r3,27
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 27, ctx.xer);
	// bgt cr6,0x82c8e89c
	if (ctx.cr6.gt) goto loc_82C8E89C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-6108
	ctx.r12.s64 = ctx.r12.s64 + -6108;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8E964;
	case 1:
		goto loc_82C8E964;
	case 2:
		goto loc_82C8E89C;
	case 3:
		goto loc_82C8E89C;
	case 4:
		goto loc_82C8E89C;
	case 5:
		goto loc_82C8E894;
	case 6:
		goto loc_82C8E8C0;
	case 7:
		goto loc_82C8E8D4;
	case 8:
		goto loc_82C8E964;
	case 9:
		goto loc_82C8E89C;
	case 10:
		goto loc_82C8E89C;
	case 11:
		goto loc_82C8E89C;
	case 12:
		goto loc_82C8E89C;
	case 13:
		goto loc_82C8E89C;
	case 14:
		goto loc_82C8E89C;
	case 15:
		goto loc_82C8E89C;
	case 16:
		goto loc_82C8E89C;
	case 17:
		goto loc_82C8E89C;
	case 18:
		goto loc_82C8E89C;
	case 19:
		goto loc_82C8E89C;
	case 20:
		goto loc_82C8E89C;
	case 21:
		goto loc_82C8E89C;
	case 22:
		goto loc_82C8E89C;
	case 23:
		goto loc_82C8E89C;
	case 24:
		goto loc_82C8E89C;
	case 25:
		goto loc_82C8E89C;
	case 26:
		goto loc_82C8E89C;
	case 27:
		goto loc_82C8E8E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-5788(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5788);
	// lwz r22,-5788(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5788);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5996(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5996);
	// lwz r22,-5952(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5952);
	// lwz r22,-5932(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5932);
	// lwz r22,-5788(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5788);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5988(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5988);
	// lwz r22,-5912(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5912);
loc_82C8E894:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c8e950
	if (ctx.cr6.lt) goto loc_82C8E950;
loc_82C8E89C:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8E8A4:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8e7e0
	if (!ctx.cr6.eq) goto loc_82C8E7E0;
loc_82C8E8AC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8E8C0:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c8e950
	if (ctx.cr6.lt) goto loc_82C8E950;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c8e8a4
	goto loc_82C8E8A4;
loc_82C8E8D4:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c8e950
	if (ctx.cr6.lt) goto loc_82C8E950;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c8e8a4
	goto loc_82C8E8A4;
loc_82C8E8E8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e8ac
	if (ctx.cr6.eq) goto loc_82C8E8AC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8e8a4
	if (!ctx.cr6.eq) goto loc_82C8E8A4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,45
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 45, ctx.xer);
	// bne cr6,0x82c8e8a4
	if (!ctx.cr6.eq) goto loc_82C8E8A4;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e8ac
	if (ctx.cr6.eq) goto loc_82C8E8AC;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c8e97c
	if (!ctx.cr6.eq) goto loc_82C8E97C;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c8e97c
	if (!ctx.cr6.eq) goto loc_82C8E97C;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,13
	ctx.r3.s64 = 13;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8E950:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8E964:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8E97C:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8E994:
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8E9AC"))) PPC_WEAK_FUNC(sub_82C8E9AC);
PPC_FUNC_IMPL(__imp__sub_82C8E9AC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C8E9B0"))) PPC_WEAK_FUNC(sub_82C8E9B0);
PPC_FUNC_IMPL(__imp__sub_82C8E9B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8e9e0
	if (!ctx.cr6.eq) goto loc_82C8E9E0;
loc_82C8E9CC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8E9E0:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8e9fc
	if (!ctx.cr6.eq) goto loc_82C8E9FC;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8ea04
	goto loc_82C8EA04;
loc_82C8E9FC:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8EA04;
	sub_82C8DAE8(ctx, base);
loc_82C8EA04:
	// addi r11,r3,-20
	ctx.r11.s64 = ctx.r3.s64 + -20;
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// bgt cr6,0x82c8ec10
	if (ctx.cr6.gt) goto loc_82C8EC10;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-5592
	ctx.r12.s64 = ctx.r12.s64 + -5592;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8EA64;
	case 1:
		goto loc_82C8EC10;
	case 2:
		goto loc_82C8EA80;
	case 3:
		goto loc_82C8EC10;
	case 4:
		goto loc_82C8EA80;
	case 5:
		goto loc_82C8EC10;
	case 6:
		goto loc_82C8EC10;
	case 7:
		goto loc_82C8EA48;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-5532(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5532);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5504(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5504);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5504(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5504);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5560(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5560);
loc_82C8EA48:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8e7a0
	ctx.lr = 0x82C8EA54;
	sub_82C8E7A0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8EA64:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,33
	ctx.r3.s64 = 33;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8EA80:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e9cc
	if (ctx.cr6.eq) goto loc_82C8E9CC;
loc_82C8EA8C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8eaa8
	if (!ctx.cr6.eq) goto loc_82C8EAA8;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8eab0
	goto loc_82C8EAB0;
loc_82C8EAA8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8EAB0;
	sub_82C8DAE8(ctx, base);
loc_82C8EAB0:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bgt cr6,0x82c8ec10
	if (ctx.cr6.gt) goto loc_82C8EC10;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-5420
	ctx.r12.s64 = ctx.r12.s64 + -5420;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8EBF8;
	case 1:
		goto loc_82C8EBF8;
	case 2:
		goto loc_82C8EC10;
	case 3:
		goto loc_82C8EC10;
	case 4:
		goto loc_82C8EC10;
	case 5:
		goto loc_82C8EC10;
	case 6:
		goto loc_82C8EC10;
	case 7:
		goto loc_82C8EC10;
	case 8:
		goto loc_82C8EC10;
	case 9:
		goto loc_82C8EC10;
	case 10:
		goto loc_82C8EC10;
	case 11:
		goto loc_82C8EC10;
	case 12:
		goto loc_82C8EBF8;
	case 13:
		goto loc_82C8EB2C;
	case 14:
		goto loc_82C8EC10;
	case 15:
		goto loc_82C8EB2C;
	case 16:
		goto loc_82C8EC10;
	case 17:
		goto loc_82C8EC10;
	case 18:
		goto loc_82C8EC10;
	case 19:
		goto loc_82C8EC10;
	case 20:
		goto loc_82C8EC10;
	case 21:
		goto loc_82C8EB4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5332(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5332);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5332(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5332);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5300(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5300);
loc_82C8EB2C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8ea8c
	if (!ctx.cr6.eq) goto loc_82C8EA8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8EB4C:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8e9cc
	if (ctx.cr6.eq) goto loc_82C8E9CC;
	// lbz r3,3(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8eb74
	if (!ctx.cr6.eq) goto loc_82C8EB74;
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8eb7c
	goto loc_82C8EB7C;
loc_82C8EB74:
	// lbz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8EB7C;
	sub_82C8DAE8(ctx, base);
loc_82C8EB7C:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bgt cr6,0x82c8ebf8
	if (ctx.cr6.gt) goto loc_82C8EBF8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-5216
	ctx.r12.s64 = ctx.r12.s64 + -5216;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8EC10;
	case 1:
		goto loc_82C8EC10;
	case 2:
		goto loc_82C8EBF8;
	case 3:
		goto loc_82C8EBF8;
	case 4:
		goto loc_82C8EBF8;
	case 5:
		goto loc_82C8EBF8;
	case 6:
		goto loc_82C8EBF8;
	case 7:
		goto loc_82C8EBF8;
	case 8:
		goto loc_82C8EBF8;
	case 9:
		goto loc_82C8EBF8;
	case 10:
		goto loc_82C8EBF8;
	case 11:
		goto loc_82C8EBF8;
	case 12:
		goto loc_82C8EC10;
	case 13:
		goto loc_82C8EBF8;
	case 14:
		goto loc_82C8EBF8;
	case 15:
		goto loc_82C8EBF8;
	case 16:
		goto loc_82C8EBF8;
	case 17:
		goto loc_82C8EBF8;
	case 18:
		goto loc_82C8EBF8;
	case 19:
		goto loc_82C8EBF8;
	case 20:
		goto loc_82C8EBF8;
	case 21:
		goto loc_82C8EC10;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5128);
	// lwz r22,-5104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -5104);
loc_82C8EBF8:
	// li r3,16
	ctx.r3.s64 = 16;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8EC10:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8EC28"))) PPC_WEAK_FUNC(sub_82C8EC28);
PPC_FUNC_IMPL(__imp__sub_82C8EC28) {
	PPC_FUNC_PROLOGUE();
	// li r11,11
	ctx.r11.s64 = 11;
	// subf r10,r4,r5
	ctx.r10.s64 = ctx.r5.s64 - ctx.r4.s64;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// cmpwi cr6,r10,6
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 6, ctx.xer);
	// bne cr6,0x82c8ece0
	if (!ctx.cr6.eq) goto loc_82C8ECE0;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8ece0
	if (!ctx.cr6.eq) goto loc_82C8ECE0;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,88
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 88, ctx.xer);
	// beq cr6,0x82c8ec6c
	if (ctx.cr6.eq) goto loc_82C8EC6C;
	// cmpwi cr6,r11,120
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 120, ctx.xer);
	// beq cr6,0x82c8ec70
	if (ctx.cr6.eq) goto loc_82C8EC70;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C8EC6C:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82C8EC70:
	// lbz r10,3(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c8ece0
	if (!ctx.cr6.eq) goto loc_82C8ECE0;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,77
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 77, ctx.xer);
	// beq cr6,0x82c8eca0
	if (ctx.cr6.eq) goto loc_82C8ECA0;
	// cmpwi cr6,r10,109
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 109, ctx.xer);
	// beq cr6,0x82c8eca4
	if (ctx.cr6.eq) goto loc_82C8ECA4;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C8ECA0:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82C8ECA4:
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c8ece0
	if (!ctx.cr6.eq) goto loc_82C8ECE0;
	// lbz r11,2(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,76
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 76, ctx.xer);
	// beq cr6,0x82c8ecd0
	if (ctx.cr6.eq) goto loc_82C8ECD0;
	// cmpwi cr6,r11,108
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 108, ctx.xer);
	// bne cr6,0x82c8ece0
	if (!ctx.cr6.eq) goto loc_82C8ECE0;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82c8ecd8
	if (ctx.cr6.eq) goto loc_82C8ECD8;
loc_82C8ECD0:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C8ECD8:
	// li r11,12
	ctx.r11.s64 = 12;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82C8ECE0:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8ECE8"))) PPC_WEAK_FUNC(sub_82C8ECE8);
PPC_FUNC_IMPL(__imp__sub_82C8ECE8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C8ECF0;
	sub_82CA2BE8(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r31,r10
	ctx.r31.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82c8ed1c
	if (!ctx.cr6.eq) goto loc_82C8ED1C;
loc_82C8ED10:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C8ED1C:
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c8ed38
	if (!ctx.cr6.eq) goto loc_82C8ED38;
	// add r11,r4,r29
	ctx.r11.u64 = ctx.r4.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8ed40
	goto loc_82C8ED40;
loc_82C8ED38:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8ED40;
	sub_82C8DAE8(ctx, base);
loc_82C8ED40:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8f124
	if (ctx.cr6.gt) goto loc_82C8F124;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-4752
	ctx.r12.s64 = ctx.r12.s64 + -4752;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8F0E8;
	case 1:
		goto loc_82C8F100;
	case 2:
		goto loc_82C8F118;
	case 3:
		goto loc_82C8F124;
	case 4:
		goto loc_82C8F124;
	case 5:
		goto loc_82C8F124;
	case 6:
		goto loc_82C8F124;
	case 7:
		goto loc_82C8F124;
	case 8:
		goto loc_82C8F124;
	case 9:
		goto loc_82C8F124;
	case 10:
		goto loc_82C8F124;
	case 11:
		goto loc_82C8F124;
	case 12:
		goto loc_82C8F124;
	case 13:
		goto loc_82C8F124;
	case 14:
		goto loc_82C8F124;
	case 15:
		goto loc_82C8F124;
	case 16:
		goto loc_82C8F124;
	case 17:
		goto loc_82C8EE08;
	case 18:
		goto loc_82C8F124;
	case 19:
		goto loc_82C8EE08;
	case 20:
		goto loc_82C8F124;
	case 21:
		goto loc_82C8F124;
	case 22:
		goto loc_82C8F124;
	case 23:
		goto loc_82C8F124;
	case 24:
		goto loc_82C8EDD4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-3864(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3864);
	// lwz r22,-3840(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3840);
	// lwz r22,-3816(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3816);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4600(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4600);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4600(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4600);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4652(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4652);
loc_82C8EDD4:
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r5,r4,27
	ctx.r5.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r6,r5
	ctx.r4.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r5.u8 & 0x3F));
	// lbzx r3,r7,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r11.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r5,r7,r4
	ctx.r5.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82c8f124
	if (ctx.cr6.eq) goto loc_82C8F124;
loc_82C8EE08:
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r5,r30
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c8ed10
	if (ctx.cr6.eq) goto loc_82C8ED10;
loc_82C8EE14:
	// lbz r10,1(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// lbz r4,0(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c8ee30
	if (!ctx.cr6.eq) goto loc_82C8EE30;
	// add r11,r4,r29
	ctx.r11.u64 = ctx.r4.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8ee38
	goto loc_82C8EE38;
loc_82C8EE30:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8EE38;
	sub_82C8DAE8(ctx, base);
loc_82C8EE38:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8ef0c
	if (ctx.cr6.gt) goto loc_82C8EF0C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-4516
	ctx.r12.s64 = ctx.r12.s64 + -4516;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8EF1C;
	case 1:
		goto loc_82C8EF34;
	case 2:
		goto loc_82C8EF4C;
	case 3:
		goto loc_82C8EF0C;
	case 4:
		goto loc_82C8EF64;
	case 5:
		goto loc_82C8EF64;
	case 6:
		goto loc_82C8EF0C;
	case 7:
		goto loc_82C8EF0C;
	case 8:
		goto loc_82C8EF0C;
	case 9:
		goto loc_82C8EF0C;
	case 10:
		goto loc_82C8F098;
	case 11:
		goto loc_82C8EF0C;
	case 12:
		goto loc_82C8EF0C;
	case 13:
		goto loc_82C8EF0C;
	case 14:
		goto loc_82C8EF0C;
	case 15:
		goto loc_82C8EF0C;
	case 16:
		goto loc_82C8EF64;
	case 17:
		goto loc_82C8EEF4;
	case 18:
		goto loc_82C8EF0C;
	case 19:
		goto loc_82C8EEF4;
	case 20:
		goto loc_82C8EEF4;
	case 21:
		goto loc_82C8EEF4;
	case 22:
		goto loc_82C8EEF4;
	case 23:
		goto loc_82C8EF0C;
	case 24:
		goto loc_82C8EEC0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-4324(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4324);
	// lwz r22,-4300(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4300);
	// lwz r22,-4276(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4276);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4252);
	// lwz r22,-4252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4252);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-3944(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3944);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4252(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4252);
	// lwz r22,-4364(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4364(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4364(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4364(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4364(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4364);
	// lwz r22,-4340(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4340);
	// lwz r22,-4416(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4416);
loc_82C8EEC0:
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// addi r9,r8,1536
	ctx.r9.s64 = ctx.r8.s64 + 1536;
	// rlwinm r10,r4,27,29,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r6,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r11,r9
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r9.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// and r7,r9,r4
	ctx.r7.u64 = ctx.r9.u64 & ctx.r4.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c8ef0c
	if (ctx.cr6.eq) goto loc_82C8EF0C;
loc_82C8EEF4:
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r5,r30
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82c8ee14
	if (!ctx.cr6.eq) goto loc_82C8EE14;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C8EF0C:
	// stw r5,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r5.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C8EF1C:
	// subf r11,r5,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8ef0c
	if (!ctx.cr6.lt) goto loc_82C8EF0C;
loc_82C8EF28:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C8EF34:
	// subf r11,r5,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c8ef0c
	if (!ctx.cr6.lt) goto loc_82C8EF0C;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C8EF4C:
	// subf r11,r5,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c8ef0c
	if (!ctx.cr6.lt) goto loc_82C8EF0C;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C8EF64:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8ec28
	ctx.lr = 0x82C8EF74;
	sub_82C8EC28(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8ef0c
	if (ctx.cr6.eq) goto loc_82C8EF0C;
	// addi r10,r5,2
	ctx.r10.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c8ed10
	if (ctx.cr6.eq) goto loc_82C8ED10;
	// subf r9,r10,r30
	ctx.r9.s64 = ctx.r30.s64 - ctx.r10.s64;
loc_82C8EF8C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8efa8
	if (!ctx.cr6.eq) goto loc_82C8EFA8;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8efb0
	goto loc_82C8EFB0;
loc_82C8EFA8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8EFB0;
	sub_82C8DAE8(ctx, base);
loc_82C8EFB0:
	// cmplwi cr6,r3,15
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 15, ctx.xer);
	// bgt cr6,0x82c8f018
	if (ctx.cr6.gt) goto loc_82C8F018;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-4144
	ctx.r12.s64 = ctx.r12.s64 + -4144;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8F124;
	case 1:
		goto loc_82C8F124;
	case 2:
		goto loc_82C8F018;
	case 3:
		goto loc_82C8F018;
	case 4:
		goto loc_82C8F018;
	case 5:
		goto loc_82C8F010;
	case 6:
		goto loc_82C8F034;
	case 7:
		goto loc_82C8F048;
	case 8:
		goto loc_82C8F124;
	case 9:
		goto loc_82C8F018;
	case 10:
		goto loc_82C8F018;
	case 11:
		goto loc_82C8F018;
	case 12:
		goto loc_82C8F018;
	case 13:
		goto loc_82C8F018;
	case 14:
		goto loc_82C8F018;
	case 15:
		goto loc_82C8F05C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4080(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4080);
	// lwz r22,-4044(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4044);
	// lwz r22,-4024(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4024);
	// lwz r22,-3804(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3804);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4072(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4072);
	// lwz r22,-4004(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4004);
loc_82C8F010:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c8ef28
	if (ctx.cr6.lt) goto loc_82C8EF28;
loc_82C8F018:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8F020:
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82c8ef8c
	if (!ctx.cr6.eq) goto loc_82C8EF8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C8F034:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c8ef28
	if (ctx.cr6.lt) goto loc_82C8EF28;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c8f020
	goto loc_82C8F020;
loc_82C8F048:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c8ef28
	if (ctx.cr6.lt) goto loc_82C8EF28;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c8f020
	goto loc_82C8F020;
loc_82C8F05C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c8ed10
	if (ctx.cr6.eq) goto loc_82C8ED10;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8f020
	if (!ctx.cr6.eq) goto loc_82C8F020;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// bne cr6,0x82c8f020
	if (!ctx.cr6.eq) goto loc_82C8F020;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C8F098:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8ec28
	ctx.lr = 0x82C8F0A8;
	sub_82C8EC28(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c8ef0c
	if (ctx.cr6.eq) goto loc_82C8EF0C;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r5,r30
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c8ed10
	if (ctx.cr6.eq) goto loc_82C8ED10;
	// lbz r11,1(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8ef0c
	if (!ctx.cr6.eq) goto loc_82C8EF0C;
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// bne cr6,0x82c8ef0c
	if (!ctx.cr6.eq) goto loc_82C8EF0C;
	// addi r11,r5,2
	ctx.r11.s64 = ctx.r5.s64 + 2;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C8F0E8:
	// subf r11,r10,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8f124
	if (!ctx.cr6.lt) goto loc_82C8F124;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C8F100:
	// subf r11,r10,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c8f124
	if (!ctx.cr6.lt) goto loc_82C8F124;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C8F118:
	// subf r11,r10,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8ef28
	if (ctx.cr6.lt) goto loc_82C8EF28;
loc_82C8F124:
	// stw r10,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
}

__attribute__((alias("__imp__sub_82C8F134"))) PPC_WEAK_FUNC(sub_82C8F134);
PPC_FUNC_IMPL(__imp__sub_82C8F134) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C8F138"))) PPC_WEAK_FUNC(sub_82C8F138);
PPC_FUNC_IMPL(__imp__sub_82C8F138) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f168
	if (!ctx.cr6.eq) goto loc_82C8F168;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F168:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c8f19c
	if (ctx.cr6.eq) goto loc_82C8F19C;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8f198
	if (!ctx.cr6.eq) goto loc_82C8F198;
loc_82C8F184:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F198:
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C8F19C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8f1b8
	if (!ctx.cr6.eq) goto loc_82C8F1B8;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f1c0
	goto loc_82C8F1C0;
loc_82C8F1B8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F1C0;
	sub_82C8DAE8(ctx, base);
loc_82C8F1C0:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c8f348
	if (ctx.cr6.gt) goto loc_82C8F348;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-3616
	ctx.r12.s64 = ctx.r12.s64 + -3616;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8F330;
	case 1:
		goto loc_82C8F330;
	case 2:
		goto loc_82C8F348;
	case 3:
		goto loc_82C8F348;
	case 4:
		goto loc_82C8F20C;
	case 5:
		goto loc_82C8F2E8;
	case 6:
		goto loc_82C8F308;
	case 7:
		goto loc_82C8F31C;
	case 8:
		goto loc_82C8F330;
	case 9:
		goto loc_82C8F278;
	case 10:
		goto loc_82C8F2CC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-3280(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3280);
	// lwz r22,-3280(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3280);
	// lwz r22,-3256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3256);
	// lwz r22,-3256(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3256);
	// lwz r22,-3572(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3572);
	// lwz r22,-3352(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3352);
	// lwz r22,-3320(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3320);
	// lwz r22,-3300(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3300);
	// lwz r22,-3280(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3280);
	// lwz r22,-3464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3464);
	// lwz r22,-3380(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3380);
loc_82C8F20C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f184
	if (ctx.cr6.eq) goto loc_82C8F184;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c8f34c
	if (!ctx.cr6.eq) goto loc_82C8F34C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c8f34c
	if (!ctx.cr6.eq) goto loc_82C8F34C;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f184
	if (ctx.cr6.eq) goto loc_82C8F184;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c8f270
	if (!ctx.cr6.eq) goto loc_82C8F270;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c8f270
	if (!ctx.cr6.eq) goto loc_82C8F270;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,40
	ctx.r3.s64 = 40;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F270:
	// addi r10,r11,-2
	ctx.r10.s64 = ctx.r11.s64 + -2;
	// b 0x82c8f34c
	goto loc_82C8F34C;
loc_82C8F278:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f184
	if (ctx.cr6.eq) goto loc_82C8F184;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8f2a0
	if (!ctx.cr6.eq) goto loc_82C8F2A0;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f2a8
	goto loc_82C8F2A8;
loc_82C8F2A0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F2A8;
	sub_82C8DAE8(ctx, base);
loc_82C8F2A8:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c8f2b4
	if (!ctx.cr6.eq) goto loc_82C8F2B4;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8F2B4:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F2CC:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F2E8:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8f348
	if (!ctx.cr6.lt) goto loc_82C8F348;
loc_82C8F2F4:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F308:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c8f2f4
	if (ctx.cr6.lt) goto loc_82C8F2F4;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c8f34c
	goto loc_82C8F34C;
loc_82C8F31C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c8f2f4
	if (ctx.cr6.lt) goto loc_82C8F2F4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c8f34c
	goto loc_82C8F34C;
loc_82C8F330:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F348:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8F34C:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f3e0
	if (ctx.cr6.eq) goto loc_82C8F3E0;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C8F358:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8f374
	if (!ctx.cr6.eq) goto loc_82C8F374;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f37c
	goto loc_82C8F37C;
loc_82C8F374:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F37C;
	sub_82C8DAE8(ctx, base);
loc_82C8F37C:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c8f3d0
	if (ctx.cr6.gt) goto loc_82C8F3D0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-3172
	ctx.r12.s64 = ctx.r12.s64 + -3172;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8F3E0;
	case 1:
		goto loc_82C8F3E0;
	case 2:
		goto loc_82C8F3D0;
	case 3:
		goto loc_82C8F3D0;
	case 4:
		goto loc_82C8F3E0;
	case 5:
		goto loc_82C8F3C8;
	case 6:
		goto loc_82C8F3F8;
	case 7:
		goto loc_82C8F40C;
	case 8:
		goto loc_82C8F3E0;
	case 9:
		goto loc_82C8F3E0;
	case 10:
		goto loc_82C8F3E0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-3104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3120(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3120);
	// lwz r22,-3120(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3120);
	// lwz r22,-3104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3128(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3128);
	// lwz r22,-3080(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3080);
	// lwz r22,-3060(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3060);
	// lwz r22,-3104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
	// lwz r22,-3104(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -3104);
loc_82C8F3C8:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c8f3e0
	if (ctx.cr6.lt) goto loc_82C8F3E0;
loc_82C8F3D0:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8F3D8:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f358
	if (!ctx.cr6.eq) goto loc_82C8F358;
loc_82C8F3E0:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F3F8:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c8f3e0
	if (ctx.cr6.lt) goto loc_82C8F3E0;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c8f3d8
	goto loc_82C8F3D8;
loc_82C8F40C:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c8f3e0
	if (ctx.cr6.lt) goto loc_82C8F3E0;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c8f3d8
	goto loc_82C8F3D8;
}

__attribute__((alias("__imp__sub_82C8F420"))) PPC_WEAK_FUNC(sub_82C8F420);
PPC_FUNC_IMPL(__imp__sub_82C8F420) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f44c
	if (!ctx.cr6.eq) goto loc_82C8F44C;
loc_82C8F444:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F44C:
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c8f468
	if (!ctx.cr6.eq) goto loc_82C8F468;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f470
	goto loc_82C8F470;
loc_82C8F468:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F470;
	sub_82C8DAE8(ctx, base);
loc_82C8F470:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8f720
	if (ctx.cr6.gt) goto loc_82C8F720;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r7,r9,-4144
	ctx.r7.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-2912
	ctx.r12.s64 = ctx.r12.s64 + -2912;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8F638;
	case 1:
		goto loc_82C8F64C;
	case 2:
		goto loc_82C8F70C;
	case 3:
		goto loc_82C8F720;
	case 4:
		goto loc_82C8F720;
	case 5:
		goto loc_82C8F720;
	case 6:
		goto loc_82C8F720;
	case 7:
		goto loc_82C8F720;
	case 8:
		goto loc_82C8F720;
	case 9:
		goto loc_82C8F720;
	case 10:
		goto loc_82C8F720;
	case 11:
		goto loc_82C8F720;
	case 12:
		goto loc_82C8F720;
	case 13:
		goto loc_82C8F720;
	case 14:
		goto loc_82C8F720;
	case 15:
		goto loc_82C8F720;
	case 16:
		goto loc_82C8F720;
	case 17:
		goto loc_82C8F538;
	case 18:
		goto loc_82C8F720;
	case 19:
		goto loc_82C8F538;
	case 20:
		goto loc_82C8F720;
	case 21:
		goto loc_82C8F720;
	case 22:
		goto loc_82C8F720;
	case 23:
		goto loc_82C8F720;
	case 24:
		goto loc_82C8F504;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-2504(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2504);
	// lwz r22,-2484(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2484);
	// lwz r22,-2292(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2292);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2760(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2760);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2760(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2760);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2812(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2812);
loc_82C8F504:
	// clrlwi r8,r8,24
	ctx.r8.u64 = ctx.r8.u32 & 0xFF;
	// addi r11,r7,1280
	ctx.r11.s64 = ctx.r7.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r8,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r11.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r8,r7
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c8f720
	if (ctx.cr6.eq) goto loc_82C8F720;
loc_82C8F538:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f444
	if (ctx.cr6.eq) goto loc_82C8F444;
loc_82C8F544:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c8f560
	if (!ctx.cr6.eq) goto loc_82C8F560;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f568
	goto loc_82C8F568;
loc_82C8F560:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F568;
	sub_82C8DAE8(ctx, base);
loc_82C8F568:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8f720
	if (ctx.cr6.gt) goto loc_82C8F720;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-2676
	ctx.r12.s64 = ctx.r12.s64 + -2676;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8F638;
	case 1:
		goto loc_82C8F64C;
	case 2:
		goto loc_82C8F70C;
	case 3:
		goto loc_82C8F720;
	case 4:
		goto loc_82C8F660;
	case 5:
		goto loc_82C8F660;
	case 6:
		goto loc_82C8F6FC;
	case 7:
		goto loc_82C8F720;
	case 8:
		goto loc_82C8F720;
	case 9:
		goto loc_82C8F720;
	case 10:
		goto loc_82C8F720;
	case 11:
		goto loc_82C8F720;
	case 12:
		goto loc_82C8F720;
	case 13:
		goto loc_82C8F720;
	case 14:
		goto loc_82C8F720;
	case 15:
		goto loc_82C8F720;
	case 16:
		goto loc_82C8F660;
	case 17:
		goto loc_82C8F624;
	case 18:
		goto loc_82C8F624;
	case 19:
		goto loc_82C8F624;
	case 20:
		goto loc_82C8F624;
	case 21:
		goto loc_82C8F624;
	case 22:
		goto loc_82C8F624;
	case 23:
		goto loc_82C8F720;
	case 24:
		goto loc_82C8F5F0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-2504(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2504);
	// lwz r22,-2484(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2484);
	// lwz r22,-2292(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2292);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2464);
	// lwz r22,-2464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2464);
	// lwz r22,-2308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2308);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2464);
	// lwz r22,-2524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2524(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2524);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2576(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2576);
loc_82C8F5F0:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r8,r7,1536
	ctx.r8.s64 = ctx.r7.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r8
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r8,r7
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c8f720
	if (ctx.cr6.eq) goto loc_82C8F720;
loc_82C8F624:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f544
	if (!ctx.cr6.eq) goto loc_82C8F544;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F638:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8f720
	if (!ctx.cr6.lt) goto loc_82C8F720;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F64C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c8f720
	if (!ctx.cr6.lt) goto loc_82C8F720;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F660:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f444
	if (ctx.cr6.eq) goto loc_82C8F444;
loc_82C8F66C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8f688
	if (!ctx.cr6.eq) goto loc_82C8F688;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f690
	goto loc_82C8F690;
loc_82C8F688:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F690;
	sub_82C8DAE8(ctx, base);
loc_82C8F690:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,12
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 12, ctx.xer);
	// bgt cr6,0x82c8f720
	if (ctx.cr6.gt) goto loc_82C8F720;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-2380
	ctx.r12.s64 = ctx.r12.s64 + -2380;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8F6E8;
	case 1:
		goto loc_82C8F6E8;
	case 2:
		goto loc_82C8F6FC;
	case 3:
		goto loc_82C8F720;
	case 4:
		goto loc_82C8F720;
	case 5:
		goto loc_82C8F720;
	case 6:
		goto loc_82C8F720;
	case 7:
		goto loc_82C8F720;
	case 8:
		goto loc_82C8F720;
	case 9:
		goto loc_82C8F720;
	case 10:
		goto loc_82C8F720;
	case 11:
		goto loc_82C8F720;
	case 12:
		goto loc_82C8F6E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-2328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2328);
	// lwz r22,-2328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2328);
	// lwz r22,-2308(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2308);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2272(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2272);
	// lwz r22,-2328(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2328);
loc_82C8F6E8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f66c
	if (!ctx.cr6.eq) goto loc_82C8F66C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F6FC:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,5
	ctx.r3.s64 = 5;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F70C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c8f720
	if (!ctx.cr6.lt) goto loc_82C8F720;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8f728
	goto loc_82C8F728;
loc_82C8F720:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C8F728:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8F740"))) PPC_WEAK_FUNC(sub_82C8F740);
PPC_FUNC_IMPL(__imp__sub_82C8F740) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f7e4
	if (ctx.cr6.eq) goto loc_82C8F7E4;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8f778
	if (!ctx.cr6.eq) goto loc_82C8F778;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f780
	goto loc_82C8F780;
loc_82C8F778:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F780;
	sub_82C8DAE8(ctx, base);
loc_82C8F780:
	// cmpwi cr6,r3,24
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 24, ctx.xer);
	// blt cr6,0x82c8f814
	if (ctx.cr6.lt) goto loc_82C8F814;
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// bgt cr6,0x82c8f814
	if (ctx.cr6.gt) goto loc_82C8F814;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f7e4
	if (ctx.cr6.eq) goto loc_82C8F7E4;
loc_82C8F79C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8f7b8
	if (!ctx.cr6.eq) goto loc_82C8F7B8;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f7c0
	goto loc_82C8F7C0;
loc_82C8F7B8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F7C0;
	sub_82C8DAE8(ctx, base);
loc_82C8F7C0:
	// cmpwi cr6,r3,18
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 18, ctx.xer);
	// beq cr6,0x82c8f7f8
	if (ctx.cr6.eq) goto loc_82C8F7F8;
	// cmpwi cr6,r3,23
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 23, ctx.xer);
	// ble cr6,0x82c8f814
	if (!ctx.cr6.gt) goto loc_82C8F814;
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// bgt cr6,0x82c8f814
	if (ctx.cr6.gt) goto loc_82C8F814;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f79c
	if (!ctx.cr6.eq) goto loc_82C8F79C;
loc_82C8F7E4:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F7F8:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,10
	ctx.r3.s64 = 10;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F814:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8F82C"))) PPC_WEAK_FUNC(sub_82C8F82C);
PPC_FUNC_IMPL(__imp__sub_82C8F82C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C8F830"))) PPC_WEAK_FUNC(sub_82C8F830);
PPC_FUNC_IMPL(__imp__sub_82C8F830) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f910
	if (ctx.cr6.eq) goto loc_82C8F910;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// extsb r11,r3
	ctx.r11.s64 = ctx.r3.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c8f89c
	if (!ctx.cr6.eq) goto loc_82C8F89C;
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,120
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 120, ctx.xer);
	// bne cr6,0x82c8f884
	if (!ctx.cr6.eq) goto loc_82C8F884;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8f740
	ctx.lr = 0x82C8F874;
	sub_82C8F740(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F884:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c8f89c
	if (!ctx.cr6.eq) goto loc_82C8F89C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f8a4
	goto loc_82C8F8A4;
loc_82C8F89C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F8A4;
	sub_82C8DAE8(ctx, base);
loc_82C8F8A4:
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// beq cr6,0x82c8f8c4
	if (ctx.cr6.eq) goto loc_82C8F8C4;
loc_82C8F8AC:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F8C4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f910
	if (ctx.cr6.eq) goto loc_82C8F910;
loc_82C8F8D0:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8f8ec
	if (!ctx.cr6.eq) goto loc_82C8F8EC;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f8f4
	goto loc_82C8F8F4;
loc_82C8F8EC:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F8F4;
	sub_82C8DAE8(ctx, base);
loc_82C8F8F4:
	// cmpwi cr6,r3,18
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 18, ctx.xer);
	// beq cr6,0x82c8f924
	if (ctx.cr6.eq) goto loc_82C8F924;
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// bne cr6,0x82c8f8ac
	if (!ctx.cr6.eq) goto loc_82C8F8AC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f8d0
	if (!ctx.cr6.eq) goto loc_82C8F8D0;
loc_82C8F910:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C8F924:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,10
	ctx.r3.s64 = 10;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8F940"))) PPC_WEAK_FUNC(sub_82C8F940);
PPC_FUNC_IMPL(__imp__sub_82C8F940) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8f96c
	if (!ctx.cr6.eq) goto loc_82C8F96C;
loc_82C8F964:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8F96C:
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c8f988
	if (!ctx.cr6.eq) goto loc_82C8F988;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8f990
	goto loc_82C8F990;
loc_82C8F988:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8F990;
	sub_82C8DAE8(ctx, base);
loc_82C8F990:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8fbb4
	if (ctx.cr6.gt) goto loc_82C8FBB4;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-1600
	ctx.r12.s64 = ctx.r12.s64 + -1600;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8FB58;
	case 1:
		goto loc_82C8FB6C;
	case 2:
		goto loc_82C8FB80;
	case 3:
		goto loc_82C8FBB4;
	case 4:
		goto loc_82C8FBB4;
	case 5:
		goto loc_82C8FBB4;
	case 6:
		goto loc_82C8FBB4;
	case 7:
		goto loc_82C8FBB4;
	case 8:
		goto loc_82C8FBB4;
	case 9:
		goto loc_82C8FBB4;
	case 10:
		goto loc_82C8FBB4;
	case 11:
		goto loc_82C8FBB4;
	case 12:
		goto loc_82C8FBB4;
	case 13:
		goto loc_82C8FBB4;
	case 14:
		goto loc_82C8FBA4;
	case 15:
		goto loc_82C8FBB4;
	case 16:
		goto loc_82C8FBB4;
	case 17:
		goto loc_82C8FA58;
	case 18:
		goto loc_82C8FBB4;
	case 19:
		goto loc_82C8FA58;
	case 20:
		goto loc_82C8FBB4;
	case 21:
		goto loc_82C8FBB4;
	case 22:
		goto loc_82C8FBB4;
	case 23:
		goto loc_82C8FBB4;
	case 24:
		goto loc_82C8FA24;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-1192(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1192);
	// lwz r22,-1172(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1172);
	// lwz r22,-1152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1152);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1116(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1116);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1448(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1448);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1448(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1448);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1500(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1500);
loc_82C8FA24:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r7,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r11.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c8fbb4
	if (ctx.cr6.eq) goto loc_82C8FBB4;
loc_82C8FA58:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c8f964
	if (ctx.cr6.eq) goto loc_82C8F964;
loc_82C8FA64:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c8fa80
	if (!ctx.cr6.eq) goto loc_82C8FA80;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8fa88
	goto loc_82C8FA88;
loc_82C8FA80:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8FA88;
	sub_82C8DAE8(ctx, base);
loc_82C8FA88:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8fbb4
	if (ctx.cr6.gt) goto loc_82C8FBB4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-1364
	ctx.r12.s64 = ctx.r12.s64 + -1364;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C8FB58;
	case 1:
		goto loc_82C8FB6C;
	case 2:
		goto loc_82C8FB80;
	case 3:
		goto loc_82C8FBB4;
	case 4:
		goto loc_82C8FBB4;
	case 5:
		goto loc_82C8FBB4;
	case 6:
		goto loc_82C8FBB4;
	case 7:
		goto loc_82C8FBB4;
	case 8:
		goto loc_82C8FBB4;
	case 9:
		goto loc_82C8FBB4;
	case 10:
		goto loc_82C8FBB4;
	case 11:
		goto loc_82C8FBB4;
	case 12:
		goto loc_82C8FBB4;
	case 13:
		goto loc_82C8FB94;
	case 14:
		goto loc_82C8FBB4;
	case 15:
		goto loc_82C8FBB4;
	case 16:
		goto loc_82C8FBB4;
	case 17:
		goto loc_82C8FB44;
	case 18:
		goto loc_82C8FBB4;
	case 19:
		goto loc_82C8FB44;
	case 20:
		goto loc_82C8FB44;
	case 21:
		goto loc_82C8FB44;
	case 22:
		goto loc_82C8FB44;
	case 23:
		goto loc_82C8FBB4;
	case 24:
		goto loc_82C8FB10;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-1192(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1192);
	// lwz r22,-1172(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1172);
	// lwz r22,-1152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1152);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1132(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1132);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1212(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1212(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1212(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1212(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1212(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1212);
	// lwz r22,-1100(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1100);
	// lwz r22,-1264(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1264);
loc_82C8FB10:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r7,r8,1536
	ctx.r7.s64 = ctx.r8.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c8fbb4
	if (ctx.cr6.eq) goto loc_82C8FBB4;
loc_82C8FB44:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8fa64
	if (!ctx.cr6.eq) goto loc_82C8FA64;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FB58:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8fbb4
	if (!ctx.cr6.lt) goto loc_82C8FBB4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FB6C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c8fbb4
	if (!ctx.cr6.lt) goto loc_82C8FBB4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FB80:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c8fbb4
	if (!ctx.cr6.lt) goto loc_82C8FBB4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FB94:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,9
	ctx.r3.s64 = 9;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FBA4:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c8f830
	ctx.lr = 0x82C8FBB0;
	sub_82C8F830(ctx, base);
	// b 0x82c8fbbc
	goto loc_82C8FBBC;
loc_82C8FBB4:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C8FBBC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C8FBD4"))) PPC_WEAK_FUNC(sub_82C8FBD4);
PPC_FUNC_IMPL(__imp__sub_82C8FBD4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C8FBD8"))) PPC_WEAK_FUNC(sub_82C8FBD8);
PPC_FUNC_IMPL(__imp__sub_82C8FBD8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C8FBE0;
	sub_82CA2BE0(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r27,1
	ctx.r27.s64 = 1;
	// addi r29,r11,-4144
	ctx.r29.s64 = ctx.r11.s64 + -4144;
loc_82C8FC08:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c8fc24
	if (!ctx.cr6.eq) goto loc_82C8FC24;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8fc2c
	goto loc_82C8FC2C;
loc_82C8FC24:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8FC2C;
	sub_82C8DAE8(ctx, base);
loc_82C8FC2C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8fe30
	if (ctx.cr6.gt) goto loc_82C8FE30;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-944
	ctx.r12.s64 = ctx.r12.s64 + -944;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90118;
	case 1:
		goto loc_82C90130;
	case 2:
		goto loc_82C90148;
	case 3:
		goto loc_82C8FE30;
	case 4:
		goto loc_82C8FDE0;
	case 5:
		goto loc_82C8FDE0;
	case 6:
		goto loc_82C8FE30;
	case 7:
		goto loc_82C8FE30;
	case 8:
		goto loc_82C8FE30;
	case 9:
		goto loc_82C8FE40;
	case 10:
		goto loc_82C8FE30;
	case 11:
		goto loc_82C8FE30;
	case 12:
		goto loc_82C8FE30;
	case 13:
		goto loc_82C8FE30;
	case 14:
		goto loc_82C8FE30;
	case 15:
		goto loc_82C8FE30;
	case 16:
		goto loc_82C8FDE0;
	case 17:
		goto loc_82C90100;
	case 18:
		goto loc_82C8FCE8;
	case 19:
		goto loc_82C90100;
	case 20:
		goto loc_82C90100;
	case 21:
		goto loc_82C90100;
	case 22:
		goto loc_82C90100;
	case 23:
		goto loc_82C8FE30;
	case 24:
		goto loc_82C8FCB4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 280);
	// lwz r22,304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 304);
	// lwz r22,328(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 328);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-544(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -544);
	// lwz r22,-544(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -544);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-448(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -448);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-544(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -544);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-792(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -792);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-844(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -844);
loc_82C8FCB4:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r8,r29,1536
	ctx.r8.s64 = ctx.r29.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r6,r27,r7
	ctx.r6.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r27.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r29
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r29.u32);
	// and r8,r9,r6
	ctx.r8.u64 = ctx.r9.u64 & ctx.r6.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// b 0x82c900fc
	goto loc_82C900FC;
loc_82C8FCE8:
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// bne cr6,0x82c8fe30
	if (!ctx.cr6.eq) goto loc_82C8FE30;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// mr r28,r27
	ctx.r28.u64 = ctx.r27.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c8fd1c
	if (!ctx.cr6.eq) goto loc_82C8FD1C;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8fd24
	goto loc_82C8FD24;
loc_82C8FD1C:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C8FD24;
	sub_82C8DAE8(ctx, base);
loc_82C8FD24:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8fe30
	if (ctx.cr6.gt) goto loc_82C8FE30;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-696
	ctx.r12.s64 = ctx.r12.s64 + -696;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90118;
	case 1:
		goto loc_82C90130;
	case 2:
		goto loc_82C90148;
	case 3:
		goto loc_82C8FE30;
	case 4:
		goto loc_82C8FE30;
	case 5:
		goto loc_82C8FE30;
	case 6:
		goto loc_82C8FE30;
	case 7:
		goto loc_82C8FE30;
	case 8:
		goto loc_82C8FE30;
	case 9:
		goto loc_82C8FE30;
	case 10:
		goto loc_82C8FE30;
	case 11:
		goto loc_82C8FE30;
	case 12:
		goto loc_82C8FE30;
	case 13:
		goto loc_82C8FE30;
	case 14:
		goto loc_82C8FE30;
	case 15:
		goto loc_82C8FE30;
	case 16:
		goto loc_82C8FE30;
	case 17:
		goto loc_82C90100;
	case 18:
		goto loc_82C8FE30;
	case 19:
		goto loc_82C90100;
	case 20:
		goto loc_82C8FE30;
	case 21:
		goto loc_82C8FE30;
	case 22:
		goto loc_82C8FE30;
	case 23:
		goto loc_82C8FE30;
	case 24:
		goto loc_82C8FDAC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 280);
	// lwz r22,304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 304);
	// lwz r22,328(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 328);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-596(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -596);
loc_82C8FDAC:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r8,r29,1280
	ctx.r8.s64 = ctx.r29.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r6,r27,r7
	ctx.r6.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r27.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r29
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r29.u32);
	// and r8,r9,r6
	ctx.r8.u64 = ctx.r9.u64 & ctx.r6.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// b 0x82c900fc
	goto loc_82C900FC;
loc_82C8FDE0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8fe08
	if (!ctx.cr6.eq) goto loc_82C8FE08;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8fe10
	goto loc_82C8FE10;
loc_82C8FE08:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8FE10;
	sub_82C8DAE8(ctx, base);
loc_82C8FE10:
	// cmpwi cr6,r3,14
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 14, ctx.xer);
	// beq cr6,0x82c8fe40
	if (ctx.cr6.eq) goto loc_82C8FE40;
	// cmpwi cr6,r3,9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 9, ctx.xer);
	// blt cr6,0x82c8fe30
	if (ctx.cr6.lt) goto loc_82C8FE30;
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// ble cr6,0x82c8fde0
	if (!ctx.cr6.gt) goto loc_82C8FDE0;
	// cmpwi cr6,r3,21
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 21, ctx.xer);
	// beq cr6,0x82c8fde0
	if (ctx.cr6.eq) goto loc_82C8FDE0;
loc_82C8FE30:
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C8FE40:
	// li r28,0
	ctx.r28.s64 = 0;
loc_82C8FE44:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8fe6c
	if (!ctx.cr6.eq) goto loc_82C8FE6C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r31,76(r11)
	ctx.r31.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8fe78
	goto loc_82C8FE78;
loc_82C8FE6C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8FE74;
	sub_82C8DAE8(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
loc_82C8FE78:
	// cmpwi cr6,r31,12
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 12, ctx.xer);
	// beq cr6,0x82c8feb0
	if (ctx.cr6.eq) goto loc_82C8FEB0;
	// cmpwi cr6,r31,13
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 13, ctx.xer);
	// beq cr6,0x82c8feb0
	if (ctx.cr6.eq) goto loc_82C8FEB0;
	// cmpwi cr6,r31,9
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 9, ctx.xer);
	// blt cr6,0x82c8fe30
	if (ctx.cr6.lt) goto loc_82C8FE30;
	// cmpwi cr6,r31,10
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 10, ctx.xer);
	// ble cr6,0x82c8fe44
	if (!ctx.cr6.gt) goto loc_82C8FE44;
	// cmpwi cr6,r31,21
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 21, ctx.xer);
	// beq cr6,0x82c8fe44
	if (ctx.cr6.eq) goto loc_82C8FE44;
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C8FEB0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C8FEB4:
	// stw r10,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r10.u32);
loc_82C8FEB8:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8fedc
	if (!ctx.cr6.eq) goto loc_82C8FEDC;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8fee4
	goto loc_82C8FEE4;
loc_82C8FEDC:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8FEE4;
	sub_82C8DAE8(ctx, base);
loc_82C8FEE4:
	// cmpw cr6,r3,r31
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r31.s32, ctx.xer);
	// beq cr6,0x82c8ff88
	if (ctx.cr6.eq) goto loc_82C8FF88;
	// cmplwi cr6,r3,8
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 8, ctx.xer);
	// bgt cr6,0x82c8feb0
	if (ctx.cr6.gt) goto loc_82C8FEB0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-244
	ctx.r12.s64 = ctx.r12.s64 + -244;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C8FE30;
	case 1:
		goto loc_82C8FE30;
	case 2:
		goto loc_82C8FE30;
	case 3:
		goto loc_82C8FF68;
	case 4:
		goto loc_82C8FEB0;
	case 5:
		goto loc_82C8FF30;
	case 6:
		goto loc_82C8FF40;
	case 7:
		goto loc_82C8FF54;
	case 8:
		goto loc_82C8FE30;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-152(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -152);
	// lwz r22,-336(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -336);
	// lwz r22,-208(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -208);
	// lwz r22,-192(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -192);
	// lwz r22,-172(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -172);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
loc_82C8FF30:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// blt cr6,0x82c90124
	if (ctx.cr6.lt) goto loc_82C90124;
	// b 0x82c8feb0
	goto loc_82C8FEB0;
loc_82C8FF40:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c90124
	if (ctx.cr6.lt) goto loc_82C90124;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c8feb4
	goto loc_82C8FEB4;
loc_82C8FF54:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c90124
	if (ctx.cr6.lt) goto loc_82C90124;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c8feb4
	goto loc_82C8FEB4;
loc_82C8FF68:
	// addi r6,r1,172
	ctx.r6.s64 = ctx.r1.s64 + 172;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c8f940
	ctx.lr = 0x82C8FF78;
	sub_82C8F940(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// ble cr6,0x82c901bc
	if (!ctx.cr6.gt) goto loc_82C901BC;
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// b 0x82c8feb8
	goto loc_82C8FEB8;
loc_82C8FF88:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c8ffb0
	if (!ctx.cr6.eq) goto loc_82C8FFB0;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c8ffb8
	goto loc_82C8FFB8;
loc_82C8FFB0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C8FFB8;
	sub_82C8DAE8(ctx, base);
loc_82C8FFB8:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,12
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 12, ctx.xer);
	// bgt cr6,0x82c8fe30
	if (ctx.cr6.gt) goto loc_82C8FE30;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,-36
	ctx.r12.s64 = ctx.r12.s64 + -36;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90010;
	case 1:
		goto loc_82C90010;
	case 2:
		goto loc_82C901A8;
	case 3:
		goto loc_82C8FE30;
	case 4:
		goto loc_82C8FE30;
	case 5:
		goto loc_82C8FE30;
	case 6:
		goto loc_82C8FE30;
	case 7:
		goto loc_82C8FE30;
	case 8:
		goto loc_82C90160;
	case 9:
		goto loc_82C8FE30;
	case 10:
		goto loc_82C8FE30;
	case 11:
		goto loc_82C8FE30;
	case 12:
		goto loc_82C90010;
	default:
		__builtin_unreachable();
	}
	// lwz r22,16(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,16(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,424(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 424);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 352);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,16(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
loc_82C90010:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c90038
	if (!ctx.cr6.eq) goto loc_82C90038;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90040
	goto loc_82C90040;
loc_82C90038:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C90040;
	sub_82C8DAE8(ctx, base);
loc_82C90040:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c8fe30
	if (ctx.cr6.gt) goto loc_82C8FE30;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,100
	ctx.r12.s64 = ctx.r12.s64 + 100;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90118;
	case 1:
		goto loc_82C90130;
	case 2:
		goto loc_82C90148;
	case 3:
		goto loc_82C8FE30;
	case 4:
		goto loc_82C90010;
	case 5:
		goto loc_82C90010;
	case 6:
		goto loc_82C901A8;
	case 7:
		goto loc_82C8FE30;
	case 8:
		goto loc_82C8FE30;
	case 9:
		goto loc_82C8FE30;
	case 10:
		goto loc_82C8FE30;
	case 11:
		goto loc_82C8FE30;
	case 12:
		goto loc_82C90160;
	case 13:
		goto loc_82C8FE30;
	case 14:
		goto loc_82C8FE30;
	case 15:
		goto loc_82C8FE30;
	case 16:
		goto loc_82C90010;
	case 17:
		goto loc_82C90100;
	case 18:
		goto loc_82C8FE30;
	case 19:
		goto loc_82C90100;
	case 20:
		goto loc_82C8FE30;
	case 21:
		goto loc_82C8FE30;
	case 22:
		goto loc_82C8FE30;
	case 23:
		goto loc_82C8FE30;
	case 24:
		goto loc_82C900C8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 280);
	// lwz r22,304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 304);
	// lwz r22,328(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 328);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,16(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,16(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,424(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 424);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 352);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,16(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 256);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,-464(r8)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r8.u32 + -464);
	// lwz r22,200(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 200);
loc_82C900C8:
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r8,r29,1280
	ctx.r8.s64 = ctx.r29.s64 + 1280;
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r6,r7,27
	ctx.r6.u64 = ctx.r7.u32 & 0x1F;
	// lbzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// slw r3,r27,r6
	ctx.r3.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r27.u32 << (ctx.r6.u8 & 0x3F));
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r29
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r29.u32);
	// and r7,r8,r3
	ctx.r7.u64 = ctx.r8.u64 & ctx.r3.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
loc_82C900FC:
	// beq cr6,0x82c8fe30
	if (ctx.cr6.eq) goto loc_82C8FE30;
loc_82C90100:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c8fc08
	if (!ctx.cr6.eq) goto loc_82C8FC08;
loc_82C9010C:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82C90110:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C90118:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c8fe30
	if (!ctx.cr6.lt) goto loc_82C8FE30;
loc_82C90124:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C90130:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c8fe30
	if (!ctx.cr6.lt) goto loc_82C8FE30;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C90148:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c8fe30
	if (!ctx.cr6.lt) goto loc_82C8FE30;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C90160:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9010c
	if (ctx.cr6.eq) goto loc_82C9010C;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c90198
	if (!ctx.cr6.eq) goto loc_82C90198;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c90198
	if (!ctx.cr6.eq) goto loc_82C90198;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,3
	ctx.r3.s64 = 3;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C90198:
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C901A8:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C901BC:
	// bne cr6,0x82c90110
	if (!ctx.cr6.eq) goto loc_82C90110;
	// lwz r11,172(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
}

__attribute__((alias("__imp__sub_82C901D0"))) PPC_WEAK_FUNC(sub_82C901D0);
PPC_FUNC_IMPL(__imp__sub_82C901D0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c901fc
	if (!ctx.cr6.eq) goto loc_82C901FC;
loc_82C901F4:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C901FC:
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c90218
	if (!ctx.cr6.eq) goto loc_82C90218;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90220
	goto loc_82C90220;
loc_82C90218:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C90220;
	sub_82C8DAE8(ctx, base);
loc_82C90220:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c90728
	if (ctx.cr6.gt) goto loc_82C90728;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r7,r9,-4144
	ctx.r7.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,592
	ctx.r12.s64 = ctx.r12.s64 + 592;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C904B8;
	case 1:
		goto loc_82C904CC;
	case 2:
		goto loc_82C904E0;
	case 3:
		goto loc_82C90728;
	case 4:
		goto loc_82C90728;
	case 5:
		goto loc_82C90728;
	case 6:
		goto loc_82C90728;
	case 7:
		goto loc_82C90728;
	case 8:
		goto loc_82C90728;
	case 9:
		goto loc_82C90728;
	case 10:
		goto loc_82C90708;
	case 11:
		goto loc_82C90654;
	case 12:
		goto loc_82C90718;
	case 13:
		goto loc_82C90728;
	case 14:
		goto loc_82C90728;
	case 15:
		goto loc_82C90728;
	case 16:
		goto loc_82C90728;
	case 17:
		goto loc_82C902E8;
	case 18:
		goto loc_82C90728;
	case 19:
		goto loc_82C902E8;
	case 20:
		goto loc_82C90728;
	case 21:
		goto loc_82C90728;
	case 22:
		goto loc_82C90728;
	case 23:
		goto loc_82C90728;
	case 24:
		goto loc_82C902B4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,1208(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1208);
	// lwz r22,1228(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1228);
	// lwz r22,1248(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1248);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1800(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1800);
	// lwz r22,1620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1620);
	// lwz r22,1816(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1816);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 744);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 744);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,692(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 692);
loc_82C902B4:
	// clrlwi r8,r8,24
	ctx.r8.u64 = ctx.r8.u32 & 0xFF;
	// addi r11,r7,1280
	ctx.r11.s64 = ctx.r7.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r8,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r11.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r8,r7
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c90728
	if (ctx.cr6.eq) goto loc_82C90728;
loc_82C902E8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c901f4
	if (ctx.cr6.eq) goto loc_82C901F4;
loc_82C902F8:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c90314
	if (!ctx.cr6.eq) goto loc_82C90314;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9031c
	goto loc_82C9031C;
loc_82C90314:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C9031C;
	sub_82C8DAE8(ctx, base);
loc_82C9031C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c90728
	if (ctx.cr6.gt) goto loc_82C90728;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,832
	ctx.r12.s64 = ctx.r12.s64 + 832;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C904B8;
	case 1:
		goto loc_82C904CC;
	case 2:
		goto loc_82C904E0;
	case 3:
		goto loc_82C90728;
	case 4:
		goto loc_82C904F4;
	case 5:
		goto loc_82C904F4;
	case 6:
		goto loc_82C90608;
	case 7:
		goto loc_82C90728;
	case 8:
		goto loc_82C90728;
	case 9:
		goto loc_82C90728;
	case 10:
		goto loc_82C90728;
	case 11:
		goto loc_82C90728;
	case 12:
		goto loc_82C90618;
	case 13:
		goto loc_82C90728;
	case 14:
		goto loc_82C90728;
	case 15:
		goto loc_82C90728;
	case 16:
		goto loc_82C904F4;
	case 17:
		goto loc_82C904A4;
	case 18:
		goto loc_82C903AC;
	case 19:
		goto loc_82C904A4;
	case 20:
		goto loc_82C904A4;
	case 21:
		goto loc_82C904A4;
	case 22:
		goto loc_82C904A4;
	case 23:
		goto loc_82C90728;
	case 24:
		goto loc_82C903A4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,1208(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1208);
	// lwz r22,1228(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1228);
	// lwz r22,1248(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1248);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1268(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1268);
	// lwz r22,1268(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1268);
	// lwz r22,1544(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1544);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1560(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1560);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1268(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1268);
	// lwz r22,1188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,940(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 940);
	// lwz r22,1188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,932(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 932);
loc_82C903A4:
	// addi r3,r7,1536
	ctx.r3.s64 = ctx.r7.s64 + 1536;
	// b 0x82c90474
	goto loc_82C90474;
loc_82C903AC:
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne cr6,0x82c90728
	if (!ctx.cr6.eq) goto loc_82C90728;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// mr r8,r31
	ctx.r8.u64 = ctx.r31.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c901f4
	if (ctx.cr6.eq) goto loc_82C901F4;
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c903e0
	if (!ctx.cr6.eq) goto loc_82C903E0;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c903e8
	goto loc_82C903E8;
loc_82C903E0:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C903E8;
	sub_82C8DAE8(ctx, base);
loc_82C903E8:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c90728
	if (ctx.cr6.gt) goto loc_82C90728;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,1036
	ctx.r12.s64 = ctx.r12.s64 + 1036;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C904B8;
	case 1:
		goto loc_82C904CC;
	case 2:
		goto loc_82C904E0;
	case 3:
		goto loc_82C90728;
	case 4:
		goto loc_82C90728;
	case 5:
		goto loc_82C90728;
	case 6:
		goto loc_82C90728;
	case 7:
		goto loc_82C90728;
	case 8:
		goto loc_82C90728;
	case 9:
		goto loc_82C90728;
	case 10:
		goto loc_82C90728;
	case 11:
		goto loc_82C90728;
	case 12:
		goto loc_82C90728;
	case 13:
		goto loc_82C90728;
	case 14:
		goto loc_82C90728;
	case 15:
		goto loc_82C90728;
	case 16:
		goto loc_82C90728;
	case 17:
		goto loc_82C904A4;
	case 18:
		goto loc_82C90728;
	case 19:
		goto loc_82C904A4;
	case 20:
		goto loc_82C90728;
	case 21:
		goto loc_82C90728;
	case 22:
		goto loc_82C90728;
	case 23:
		goto loc_82C90728;
	case 24:
		goto loc_82C90470;
	default:
		__builtin_unreachable();
	}
	// lwz r22,1208(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1208);
	// lwz r22,1228(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1228);
	// lwz r22,1248(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1248);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1188);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1136);
loc_82C90470:
	// addi r3,r7,1280
	ctx.r3.s64 = ctx.r7.s64 + 1280;
loc_82C90474:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r4
	ctx.r4.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r3,r11,r3
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r3.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r9,r7
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// and r11,r3,r4
	ctx.r11.u64 = ctx.r3.u64 & ctx.r4.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c90728
	if (ctx.cr6.eq) goto loc_82C90728;
loc_82C904A4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c902f8
	if (!ctx.cr6.eq) goto loc_82C902F8;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C904B8:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c90728
	if (!ctx.cr6.lt) goto loc_82C90728;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C904CC:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c90728
	if (!ctx.cr6.lt) goto loc_82C90728;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C904E0:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c90728
	if (!ctx.cr6.lt) goto loc_82C90728;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C904F4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c901f4
	if (ctx.cr6.eq) goto loc_82C901F4;
loc_82C90500:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c9051c
	if (!ctx.cr6.eq) goto loc_82C9051C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90524
	goto loc_82C90524;
loc_82C9051C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C90524;
	sub_82C8DAE8(ctx, base);
loc_82C90524:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c90728
	if (ctx.cr6.gt) goto loc_82C90728;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,1352
	ctx.r12.s64 = ctx.r12.s64 + 1352;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C904B8;
	case 1:
		goto loc_82C904CC;
	case 2:
		goto loc_82C904E0;
	case 3:
		goto loc_82C90728;
	case 4:
		goto loc_82C905AC;
	case 5:
		goto loc_82C905AC;
	case 6:
		goto loc_82C90608;
	case 7:
		goto loc_82C90728;
	case 8:
		goto loc_82C90728;
	case 9:
		goto loc_82C90728;
	case 10:
		goto loc_82C90728;
	case 11:
		goto loc_82C90728;
	case 12:
		goto loc_82C90618;
	case 13:
		goto loc_82C90728;
	case 14:
		goto loc_82C90728;
	case 15:
		goto loc_82C90728;
	case 16:
		goto loc_82C905AC;
	case 17:
		goto loc_82C905F8;
	case 18:
		goto loc_82C90728;
	case 19:
		goto loc_82C905F8;
	case 20:
		goto loc_82C90728;
	case 21:
		goto loc_82C90728;
	case 22:
		goto loc_82C90728;
	case 23:
		goto loc_82C90728;
	case 24:
		goto loc_82C905C0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,1208(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1208);
	// lwz r22,1228(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1228);
	// lwz r22,1248(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1248);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1452(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1452);
	// lwz r22,1452(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1452);
	// lwz r22,1544(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1544);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1560(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1560);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1452(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1452);
	// lwz r22,1528(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1528);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1528(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1528);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1832);
	// lwz r22,1472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1472);
loc_82C905AC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c90500
	if (!ctx.cr6.eq) goto loc_82C90500;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c90730
	goto loc_82C90730;
loc_82C905C0:
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r8,r7,1280
	ctx.r8.s64 = ctx.r7.s64 + 1280;
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r3,r4,27
	ctx.r3.u64 = ctx.r4.u32 & 0x1F;
	// lbzx r11,r11,r8
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// slw r8,r31,r3
	ctx.r8.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r3.u8 & 0x3F));
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r4,r11,r9
	ctx.r4.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r3,r4,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r3,r7
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r7.u32);
	// and r9,r11,r8
	ctx.r9.u64 = ctx.r11.u64 & ctx.r8.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c90728
	if (ctx.cr6.eq) goto loc_82C90728;
loc_82C905F8:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c8fbd8
	ctx.lr = 0x82C90604;
	sub_82C8FBD8(ctx, base);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90608:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,2
	ctx.r3.s64 = 2;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90618:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c901f4
	if (ctx.cr6.eq) goto loc_82C901F4;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c9064c
	if (!ctx.cr6.eq) goto loc_82C9064C;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c9064c
	if (!ctx.cr6.eq) goto loc_82C9064C;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,4
	ctx.r3.s64 = 4;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C9064C:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c9072c
	goto loc_82C9072C;
loc_82C90654:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c901f4
	if (ctx.cr6.eq) goto loc_82C901F4;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c9067c
	if (!ctx.cr6.eq) goto loc_82C9067C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90684
	goto loc_82C90684;
loc_82C9067C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C90684;
	sub_82C8DAE8(ctx, base);
loc_82C90684:
	// cmpwi cr6,r3,20
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 20, ctx.xer);
	// beq cr6,0x82c906a4
	if (ctx.cr6.eq) goto loc_82C906A4;
	// cmpwi cr6,r3,27
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 27, ctx.xer);
	// bne cr6,0x82c90728
	if (!ctx.cr6.eq) goto loc_82C90728;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c8e7a0
	ctx.lr = 0x82C906A0;
	sub_82C8E7A0(ctx, base);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C906A4:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// subf r10,r11,r5
	ctx.r10.s64 = ctx.r5.s64 - ctx.r11.s64;
	// cmpwi cr6,r10,12
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 12, ctx.xer);
	// blt cr6,0x82c901f4
	if (ctx.cr6.lt) goto loc_82C901F4;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r9,-4144
	ctx.r9.s64 = ctx.r9.s64 + -4144;
loc_82C906C0:
	// lbz r8,1(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c906fc
	if (!ctx.cr6.eq) goto loc_82C906FC;
	// addi r8,r9,4744
	ctx.r8.s64 = ctx.r9.s64 + 4744;
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lbzx r5,r10,r8
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r8.u32);
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c906fc
	if (!ctx.cr6.eq) goto loc_82C906FC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// cmpwi cr6,r10,6
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 6, ctx.xer);
	// blt cr6,0x82c906c0
	if (ctx.cr6.lt) goto loc_82C906C0;
	// li r3,8
	ctx.r3.s64 = 8;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C906FC:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90708:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c8ece8
	ctx.lr = 0x82C90714;
	sub_82C8ECE8(ctx, base);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90718:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c8f420
	ctx.lr = 0x82C90724;
	sub_82C8F420(ctx, base);
	// b 0x82c90730
	goto loc_82C90730;
loc_82C90728:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C9072C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C90730:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C90748"))) PPC_WEAK_FUNC(sub_82C90748);
PPC_FUNC_IMPL(__imp__sub_82C90748) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c90780
	if (!ctx.cr6.eq) goto loc_82C90780;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90780:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c907b8
	if (ctx.cr6.eq) goto loc_82C907B8;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c907b4
	if (!ctx.cr6.eq) goto loc_82C907B4;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C907B4:
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C907B8:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c907d4
	if (!ctx.cr6.eq) goto loc_82C907D4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c907dc
	goto loc_82C907DC;
loc_82C907D4:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C907DC;
	sub_82C8DAE8(ctx, base);
loc_82C907DC:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c909bc
	if (ctx.cr6.gt) goto loc_82C909BC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,2044
	ctx.r12.s64 = ctx.r12.s64 + 2044;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C909B4;
	case 1:
		goto loc_82C909B4;
	case 2:
		goto loc_82C90828;
	case 3:
		goto loc_82C90848;
	case 4:
		goto loc_82C908E4;
	case 5:
		goto loc_82C90968;
	case 6:
		goto loc_82C9098C;
	case 7:
		goto loc_82C909A0;
	case 8:
		goto loc_82C909B4;
	case 9:
		goto loc_82C90868;
	case 10:
		goto loc_82C908C4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,2484(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2484);
	// lwz r22,2484(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2484);
	// lwz r22,2088(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2088);
	// lwz r22,2120(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2120);
	// lwz r22,2276(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2276);
	// lwz r22,2408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2408);
	// lwz r22,2444(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2444);
	// lwz r22,2464(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2464);
	// lwz r22,2484(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2484);
	// lwz r22,2152(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2152);
	// lwz r22,2244(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2244);
loc_82C90828:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c901d0
	ctx.lr = 0x82C90834;
	sub_82C901D0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90848:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c8f940
	ctx.lr = 0x82C90854;
	sub_82C8F940(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90868:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9088c
	if (!ctx.cr6.eq) goto loc_82C9088C;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C9088C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c908a8
	if (!ctx.cr6.eq) goto loc_82C908A8;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c908b0
	goto loc_82C908B0;
loc_82C908A8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C908B0;
	sub_82C8DAE8(ctx, base);
loc_82C908B0:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c908bc
	if (!ctx.cr6.eq) goto loc_82C908BC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C908BC:
	// li r3,7
	ctx.r3.s64 = 7;
	// b 0x82c90a50
	goto loc_82C90A50;
loc_82C908C4:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C908E4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c90908
	if (!ctx.cr6.eq) goto loc_82C90908;
loc_82C908F0:
	// li r3,-5
	ctx.r3.s64 = -5;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90908:
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c909c0
	if (!ctx.cr6.eq) goto loc_82C909C0;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c909c0
	if (!ctx.cr6.eq) goto loc_82C909C0;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c908f0
	if (ctx.cr6.eq) goto loc_82C908F0;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c90960
	if (!ctx.cr6.eq) goto loc_82C90960;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c90960
	if (!ctx.cr6.eq) goto loc_82C90960;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90960:
	// addi r10,r11,-2
	ctx.r10.s64 = ctx.r11.s64 + -2;
	// b 0x82c909c0
	goto loc_82C909C0;
loc_82C90968:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c909bc
	if (!ctx.cr6.lt) goto loc_82C909BC;
loc_82C90974:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C9098C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c90974
	if (ctx.cr6.lt) goto loc_82C90974;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c909c0
	goto loc_82C909C0;
loc_82C909A0:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c90974
	if (ctx.cr6.lt) goto loc_82C90974;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c909c0
	goto loc_82C909C0;
loc_82C909B4:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c90a50
	goto loc_82C90A50;
loc_82C909BC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C909C0:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c90a4c
	if (ctx.cr6.eq) goto loc_82C90A4C;
	// addi r7,r10,4
	ctx.r7.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,2
	ctx.r8.s64 = ctx.r10.s64 + 2;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C909D4:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c909f0
	if (!ctx.cr6.eq) goto loc_82C909F0;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c909f8
	goto loc_82C909F8;
loc_82C909F0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C909F8;
	sub_82C8DAE8(ctx, base);
loc_82C909F8:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c90ae0
	if (ctx.cr6.gt) goto loc_82C90AE0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,2584
	ctx.r12.s64 = ctx.r12.s64 + 2584;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C90A4C;
	case 1:
		goto loc_82C90A4C;
	case 2:
		goto loc_82C90A4C;
	case 3:
		goto loc_82C90A4C;
	case 4:
		goto loc_82C90AA0;
	case 5:
		goto loc_82C90A44;
	case 6:
		goto loc_82C90A68;
	case 7:
		goto loc_82C90A84;
	case 8:
		goto loc_82C90A4C;
	case 9:
		goto loc_82C90A4C;
	case 10:
		goto loc_82C90A4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,2636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2720);
	// lwz r22,2628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2628);
	// lwz r22,2664(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2664);
	// lwz r22,2692(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2692);
	// lwz r22,2636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
	// lwz r22,2636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2636);
loc_82C90A44:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bge cr6,0x82c90ae0
	if (!ctx.cr6.lt) goto loc_82C90AE0;
loc_82C90A4C:
	// li r3,6
	ctx.r3.s64 = 6;
loc_82C90A50:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C90A68:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c90a4c
	if (ctx.cr6.lt) goto loc_82C90A4C;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// addi r8,r8,3
	ctx.r8.s64 = ctx.r8.s64 + 3;
	// addi r7,r7,3
	ctx.r7.s64 = ctx.r7.s64 + 3;
	// b 0x82c90af0
	goto loc_82C90AF0;
loc_82C90A84:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c90a4c
	if (ctx.cr6.lt) goto loc_82C90A4C;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// b 0x82c90af0
	goto loc_82C90AF0;
loc_82C90AA0:
	// cmplw cr6,r8,r5
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c90a4c
	if (ctx.cr6.eq) goto loc_82C90A4C;
	// lbz r11,3(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c90ae0
	if (!ctx.cr6.eq) goto loc_82C90AE0;
	// lbz r11,0(r8)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c90ae0
	if (!ctx.cr6.eq) goto loc_82C90AE0;
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c90a4c
	if (ctx.cr6.eq) goto loc_82C90A4C;
	// lbz r11,5(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 5);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c90ae0
	if (!ctx.cr6.eq) goto loc_82C90AE0;
	// lbz r11,0(r7)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 0);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// beq cr6,0x82c90afc
	if (ctx.cr6.eq) goto loc_82C90AFC;
loc_82C90AE0:
	// addi r7,r7,2
	ctx.r7.s64 = ctx.r7.s64 + 2;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C90AF0:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c909d4
	if (!ctx.cr6.eq) goto loc_82C909D4;
	// b 0x82c90a4c
	goto loc_82C90A4C;
loc_82C90AFC:
	// addi r11,r10,4
	ctx.r11.s64 = ctx.r10.s64 + 4;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C90B1C"))) PPC_WEAK_FUNC(sub_82C90B1C);
PPC_FUNC_IMPL(__imp__sub_82C90B1C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C90B20"))) PPC_WEAK_FUNC(sub_82C90B20);
PPC_FUNC_IMPL(__imp__sub_82C90B20) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c90b4c
	if (!ctx.cr6.eq) goto loc_82C90B4C;
	// li r3,-22
	ctx.r3.s64 = -22;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90B4C:
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c90b68
	if (!ctx.cr6.eq) goto loc_82C90B68;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90b70
	goto loc_82C90B70;
loc_82C90B68:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C90B70;
	sub_82C8DAE8(ctx, base);
loc_82C90B70:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,25
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 25, ctx.xer);
	// bgt cr6,0x82c90d90
	if (ctx.cr6.gt) goto loc_82C90D90;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,2976
	ctx.r12.s64 = ctx.r12.s64 + 2976;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90D3C;
	case 1:
		goto loc_82C90D50;
	case 2:
		goto loc_82C90D64;
	case 3:
		goto loc_82C90D90;
	case 4:
		goto loc_82C90D88;
	case 5:
		goto loc_82C90D88;
	case 6:
		goto loc_82C90D90;
	case 7:
		goto loc_82C90D90;
	case 8:
		goto loc_82C90D90;
	case 9:
		goto loc_82C90D90;
	case 10:
		goto loc_82C90D90;
	case 11:
		goto loc_82C90D90;
	case 12:
		goto loc_82C90D90;
	case 13:
		goto loc_82C90D90;
	case 14:
		goto loc_82C90D90;
	case 15:
		goto loc_82C90D90;
	case 16:
		goto loc_82C90D88;
	case 17:
		goto loc_82C90C3C;
	case 18:
		goto loc_82C90D90;
	case 19:
		goto loc_82C90C3C;
	case 20:
		goto loc_82C90D90;
	case 21:
		goto loc_82C90D90;
	case 22:
		goto loc_82C90D90;
	case 23:
		goto loc_82C90D90;
	case 24:
		goto loc_82C90C08;
	case 25:
		goto loc_82C90D88;
	default:
		__builtin_unreachable();
	}
	// lwz r22,3388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3388);
	// lwz r22,3408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3408);
	// lwz r22,3428(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3428);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3464(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3464);
	// lwz r22,3464(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3464);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3464(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3464);
	// lwz r22,3132(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3132);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3132(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3132);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3080(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3080);
	// lwz r22,3464(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3464);
loc_82C90C08:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r7,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r11.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c90d90
	if (ctx.cr6.eq) goto loc_82C90D90;
loc_82C90C3C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c90d34
	if (ctx.cr6.eq) goto loc_82C90D34;
loc_82C90C48:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c90c64
	if (!ctx.cr6.eq) goto loc_82C90C64;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90c6c
	goto loc_82C90C6C;
loc_82C90C64:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C90C6C;
	sub_82C8DAE8(ctx, base);
loc_82C90C6C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c90d90
	if (ctx.cr6.gt) goto loc_82C90D90;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,3216
	ctx.r12.s64 = ctx.r12.s64 + 3216;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90D3C;
	case 1:
		goto loc_82C90D50;
	case 2:
		goto loc_82C90D64;
	case 3:
		goto loc_82C90D90;
	case 4:
		goto loc_82C90D90;
	case 5:
		goto loc_82C90D90;
	case 6:
		goto loc_82C90D90;
	case 7:
		goto loc_82C90D90;
	case 8:
		goto loc_82C90D90;
	case 9:
		goto loc_82C90D90;
	case 10:
		goto loc_82C90D90;
	case 11:
		goto loc_82C90D90;
	case 12:
		goto loc_82C90D90;
	case 13:
		goto loc_82C90D78;
	case 14:
		goto loc_82C90D90;
	case 15:
		goto loc_82C90D90;
	case 16:
		goto loc_82C90D90;
	case 17:
		goto loc_82C90D28;
	case 18:
		goto loc_82C90D90;
	case 19:
		goto loc_82C90D28;
	case 20:
		goto loc_82C90D28;
	case 21:
		goto loc_82C90D28;
	case 22:
		goto loc_82C90D28;
	case 23:
		goto loc_82C90D90;
	case 24:
		goto loc_82C90CF4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,3388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3388);
	// lwz r22,3408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3408);
	// lwz r22,3428(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3428);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3448(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3448);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3368(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3368(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3368(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3368(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3368(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3368);
	// lwz r22,3472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3472);
	// lwz r22,3316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3316);
loc_82C90CF4:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r7,r8,1536
	ctx.r7.s64 = ctx.r8.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c90d90
	if (ctx.cr6.eq) goto loc_82C90D90;
loc_82C90D28:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c90c48
	if (!ctx.cr6.eq) goto loc_82C90C48;
loc_82C90D34:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D3C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c90d90
	if (!ctx.cr6.lt) goto loc_82C90D90;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D50:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c90d90
	if (!ctx.cr6.lt) goto loc_82C90D90;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D64:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c90d90
	if (!ctx.cr6.lt) goto loc_82C90D90;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D78:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,28
	ctx.r3.s64 = 28;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c90d98
	goto loc_82C90D98;
loc_82C90D88:
	// li r3,22
	ctx.r3.s64 = 22;
	// b 0x82c90d94
	goto loc_82C90D94;
loc_82C90D90:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C90D94:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C90D98:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C90DB0"))) PPC_WEAK_FUNC(sub_82C90DB0);
PPC_FUNC_IMPL(__imp__sub_82C90DB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c90ddc
	if (!ctx.cr6.eq) goto loc_82C90DDC;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C90DDC:
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c90df8
	if (!ctx.cr6.eq) goto loc_82C90DF8;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90e00
	goto loc_82C90E00;
loc_82C90DF8:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C90E00;
	sub_82C8DAE8(ctx, base);
loc_82C90E00:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c91028
	if (ctx.cr6.gt) goto loc_82C91028;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,3632
	ctx.r12.s64 = ctx.r12.s64 + 3632;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90FE4;
	case 1:
		goto loc_82C90FF8;
	case 2:
		goto loc_82C91014;
	case 3:
		goto loc_82C91028;
	case 4:
		goto loc_82C91028;
	case 5:
		goto loc_82C91028;
	case 6:
		goto loc_82C91028;
	case 7:
		goto loc_82C91028;
	case 8:
		goto loc_82C91028;
	case 9:
		goto loc_82C91028;
	case 10:
		goto loc_82C91028;
	case 11:
		goto loc_82C91028;
	case 12:
		goto loc_82C91028;
	case 13:
		goto loc_82C91028;
	case 14:
		goto loc_82C91028;
	case 15:
		goto loc_82C91028;
	case 16:
		goto loc_82C91028;
	case 17:
		goto loc_82C90EC8;
	case 18:
		goto loc_82C91028;
	case 19:
		goto loc_82C90EC8;
	case 20:
		goto loc_82C91028;
	case 21:
		goto loc_82C91028;
	case 22:
		goto loc_82C91028;
	case 23:
		goto loc_82C91028;
	case 24:
		goto loc_82C90E94;
	default:
		__builtin_unreachable();
	}
	// lwz r22,4068(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4068);
	// lwz r22,4088(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4088);
	// lwz r22,4116(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4116);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,3784(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3784);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,3784(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3784);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,3732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3732);
loc_82C90E94:
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r7,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r11.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c91028
	if (ctx.cr6.eq) goto loc_82C91028;
loc_82C90EC8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c90fdc
	if (ctx.cr6.eq) goto loc_82C90FDC;
loc_82C90ED4:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c90ef0
	if (!ctx.cr6.eq) goto loc_82C90EF0;
	// add r11,r4,r30
	ctx.r11.u64 = ctx.r4.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c90ef8
	goto loc_82C90EF8;
loc_82C90EF0:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C90EF8;
	sub_82C8DAE8(ctx, base);
loc_82C90EF8:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 31, ctx.xer);
	// bgt cr6,0x82c91028
	if (ctx.cr6.gt) goto loc_82C91028;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,3868
	ctx.r12.s64 = ctx.r12.s64 + 3868;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C90FE4;
	case 1:
		goto loc_82C90FF8;
	case 2:
		goto loc_82C91014;
	case 3:
		goto loc_82C91028;
	case 4:
		goto loc_82C9100C;
	case 5:
		goto loc_82C9100C;
	case 6:
		goto loc_82C9100C;
	case 7:
		goto loc_82C91028;
	case 8:
		goto loc_82C91028;
	case 9:
		goto loc_82C91028;
	case 10:
		goto loc_82C91028;
	case 11:
		goto loc_82C91028;
	case 12:
		goto loc_82C91028;
	case 13:
		goto loc_82C91028;
	case 14:
		goto loc_82C91028;
	case 15:
		goto loc_82C91028;
	case 16:
		goto loc_82C9100C;
	case 17:
		goto loc_82C90FD0;
	case 18:
		goto loc_82C91028;
	case 19:
		goto loc_82C90FD0;
	case 20:
		goto loc_82C90FD0;
	case 21:
		goto loc_82C90FD0;
	case 22:
		goto loc_82C90FD0;
	case 23:
		goto loc_82C91028;
	case 24:
		goto loc_82C90F9C;
	case 25:
		goto loc_82C9100C;
	case 26:
		goto loc_82C91028;
	case 27:
		goto loc_82C9100C;
	case 28:
		goto loc_82C91028;
	case 29:
		goto loc_82C91028;
	case 30:
		goto loc_82C91028;
	case 31:
		goto loc_82C9100C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,4068(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4068);
	// lwz r22,4088(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4088);
	// lwz r22,4116(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4116);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4048);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,3996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3996);
	// lwz r22,4108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4136);
	// lwz r22,4108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4108);
loc_82C90F9C:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r7,r8,1536
	ctx.r7.s64 = ctx.r8.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r31,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c91028
	if (ctx.cr6.eq) goto loc_82C91028;
loc_82C90FD0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c90ed4
	if (!ctx.cr6.eq) goto loc_82C90ED4;
loc_82C90FDC:
	// li r3,-20
	ctx.r3.s64 = -20;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C90FE4:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c91028
	if (!ctx.cr6.lt) goto loc_82C91028;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C90FF8:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c91028
	if (!ctx.cr6.lt) goto loc_82C91028;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C9100C:
	// li r3,20
	ctx.r3.s64 = 20;
	// b 0x82c9102c
	goto loc_82C9102C;
loc_82C91014:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c91028
	if (!ctx.cr6.lt) goto loc_82C91028;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c91030
	goto loc_82C91030;
loc_82C91028:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C9102C:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C91030:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C91048"))) PPC_WEAK_FUNC(sub_82C91048);
PPC_FUNC_IMPL(__imp__sub_82C91048) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r8,r4
	ctx.r8.u64 = ctx.r4.u64;
	// cmplw cr6,r5,r6
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, ctx.xer);
	// beq cr6,0x82c910fc
	if (ctx.cr6.eq) goto loc_82C910FC;
	// subf r10,r5,r6
	ctx.r10.s64 = ctx.r6.s64 - ctx.r5.s64;
loc_82C91068:
	// lbz r3,1(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c91084
	if (!ctx.cr6.eq) goto loc_82C91084;
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9108c
	goto loc_82C9108C;
loc_82C91084:
	// lbz r4,0(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C9108C;
	sub_82C8DAE8(ctx, base);
loc_82C9108C:
	// cmplwi cr6,r3,13
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 13, ctx.xer);
	// bgt cr6,0x82c910ec
	if (ctx.cr6.gt) goto loc_82C910EC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,4268
	ctx.r12.s64 = ctx.r12.s64 + 4268;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C91178;
	case 1:
		goto loc_82C91178;
	case 2:
		goto loc_82C910EC;
	case 3:
		goto loc_82C910EC;
	case 4:
		goto loc_82C910EC;
	case 5:
		goto loc_82C910E4;
	case 6:
		goto loc_82C91110;
	case 7:
		goto loc_82C91124;
	case 8:
		goto loc_82C91178;
	case 9:
		goto loc_82C910EC;
	case 10:
		goto loc_82C910EC;
	case 11:
		goto loc_82C910EC;
	case 12:
		goto loc_82C91138;
	case 13:
		goto loc_82C91138;
	default:
		__builtin_unreachable();
	}
	// lwz r22,4472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4472);
	// lwz r22,4472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4472);
	// lwz r22,4332(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4332(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4332(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4324(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4324);
	// lwz r22,4368(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4368);
	// lwz r22,4388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4388);
	// lwz r22,4472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4472);
	// lwz r22,4332(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4332(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4332(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4332);
	// lwz r22,4408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4408);
	// lwz r22,4408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4408);
loc_82C910E4:
	// cmpwi cr6,r10,2
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 2, ctx.xer);
	// blt cr6,0x82c91164
	if (ctx.cr6.lt) goto loc_82C91164;
loc_82C910EC:
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
loc_82C910F4:
	// cmplw cr6,r5,r6
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82c91068
	if (!ctx.cr6.eq) goto loc_82C91068;
loc_82C910FC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91110:
	// cmpwi cr6,r10,3
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 3, ctx.xer);
	// blt cr6,0x82c91164
	if (ctx.cr6.lt) goto loc_82C91164;
	// addi r5,r5,3
	ctx.r5.s64 = ctx.r5.s64 + 3;
	// addi r10,r10,-3
	ctx.r10.s64 = ctx.r10.s64 + -3;
	// b 0x82c910f4
	goto loc_82C910F4;
loc_82C91124:
	// cmpwi cr6,r10,4
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 4, ctx.xer);
	// blt cr6,0x82c91164
	if (ctx.cr6.lt) goto loc_82C91164;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// b 0x82c910f4
	goto loc_82C910F4;
loc_82C91138:
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// cmpw cr6,r3,r9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82c910f4
	if (!ctx.cr6.eq) goto loc_82C910F4;
	// cmplw cr6,r5,r6
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82c91190
	if (!ctx.cr6.eq) goto loc_82C91190;
	// li r3,-27
	ctx.r3.s64 = -27;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91164:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91178:
	// stw r5,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r5.u32);
loc_82C9117C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91190:
	// stw r5,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r5.u32);
	// lbz r3,1(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c911b0
	if (!ctx.cr6.eq) goto loc_82C911B0;
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c911b8
	goto loc_82C911B8;
loc_82C911B0:
	// lbz r4,0(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C911B8;
	sub_82C8DAE8(ctx, base);
loc_82C911B8:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bgt cr6,0x82c9117c
	if (ctx.cr6.gt) goto loc_82C9117C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,4572
	ctx.r12.s64 = ctx.r12.s64 + 4572;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C91234;
	case 1:
		goto loc_82C91234;
	case 2:
		goto loc_82C91234;
	case 3:
		goto loc_82C9117C;
	case 4:
		goto loc_82C9117C;
	case 5:
		goto loc_82C9117C;
	case 6:
		goto loc_82C9117C;
	case 7:
		goto loc_82C9117C;
	case 8:
		goto loc_82C9117C;
	case 9:
		goto loc_82C9117C;
	case 10:
		goto loc_82C9117C;
	case 11:
		goto loc_82C91234;
	case 12:
		goto loc_82C91234;
	case 13:
		goto loc_82C9117C;
	case 14:
		goto loc_82C9117C;
	case 15:
		goto loc_82C9117C;
	case 16:
		goto loc_82C9117C;
	case 17:
		goto loc_82C9117C;
	case 18:
		goto loc_82C9117C;
	case 19:
		goto loc_82C9117C;
	case 20:
		goto loc_82C9117C;
	case 21:
		goto loc_82C91234;
	default:
		__builtin_unreachable();
	}
	// lwz r22,4660(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4660(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4660(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4660(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4660(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4476);
	// lwz r22,4660(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4660);
loc_82C91234:
	// li r3,27
	ctx.r3.s64 = 27;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C91248"))) PPC_WEAK_FUNC(sub_82C91248);
PPC_FUNC_IMPL(__imp__sub_82C91248) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C91250;
	sub_82CA2BEC(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91270
	if (!ctx.cr6.eq) goto loc_82C91270;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91270:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c9129c
	if (ctx.cr6.eq) goto loc_82C9129C;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c91298
	if (!ctx.cr6.eq) goto loc_82C91298;
loc_82C9128C:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91298:
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C9129C:
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c912b8
	if (!ctx.cr6.eq) goto loc_82C912B8;
	// add r11,r4,r29
	ctx.r11.u64 = ctx.r4.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c912c0
	goto loc_82C912C0;
loc_82C912B8:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C912C0;
	sub_82C8DAE8(ctx, base);
loc_82C912C0:
	// addi r9,r3,-2
	ctx.r9.s64 = ctx.r3.s64 + -2;
	// cmplwi cr6,r9,34
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 34, ctx.xer);
	// bgt cr6,0x82c91a64
	if (ctx.cr6.gt) goto loc_82C91A64;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r30,1
	ctx.r30.s64 = 1;
	// addi r31,r11,-4144
	ctx.r31.s64 = ctx.r11.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,4848
	ctx.r12.s64 = ctx.r12.s64 + 4848;
	// rlwinm r0,r9,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_82C913BC;
	case 1:
		goto loc_82C91A64;
	case 2:
		goto loc_82C9157C;
	case 3:
		goto loc_82C91760;
	case 4:
		goto loc_82C91778;
	case 5:
		goto loc_82C91790;
	case 6:
		goto loc_82C91A64;
	case 7:
		goto loc_82C914B0;
	case 8:
		goto loc_82C914CC;
	case 9:
		goto loc_82C91738;
	case 10:
		goto loc_82C9137C;
	case 11:
		goto loc_82C9139C;
	case 12:
		goto loc_82C91A64;
	case 13:
		goto loc_82C91A64;
	case 14:
		goto loc_82C91A64;
	case 15:
		goto loc_82C91A64;
	case 16:
		goto loc_82C91A64;
	case 17:
		goto loc_82C9174C;
	case 18:
		goto loc_82C91568;
	case 19:
		goto loc_82C914CC;
	case 20:
		goto loc_82C917DC;
	case 21:
		goto loc_82C91808;
	case 22:
		goto loc_82C917DC;
	case 23:
		goto loc_82C91808;
	case 24:
		goto loc_82C91808;
	case 25:
		goto loc_82C91808;
	case 26:
		goto loc_82C91A64;
	case 27:
		goto loc_82C917A8;
	case 28:
		goto loc_82C91540;
	case 29:
		goto loc_82C915F4;
	case 30:
		goto loc_82C91608;
	case 31:
		goto loc_82C91A64;
	case 32:
		goto loc_82C91A64;
	case 33:
		goto loc_82C91554;
	case 34:
		goto loc_82C91724;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5052(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5052);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5500(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5500);
	// lwz r22,5984(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5984);
	// lwz r22,6008(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6008);
	// lwz r22,6032(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6032);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5296(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5296);
	// lwz r22,5324(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5324);
	// lwz r22,5944(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5944);
	// lwz r22,4988(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4988);
	// lwz r22,5020(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5020);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5964(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5964);
	// lwz r22,5480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5480);
	// lwz r22,5324(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5324);
	// lwz r22,6108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6108);
	// lwz r22,6152(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6152);
	// lwz r22,6108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6108);
	// lwz r22,6152(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6152);
	// lwz r22,6152(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6152);
	// lwz r22,6152(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6152);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6056(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6056);
	// lwz r22,5440(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5440);
	// lwz r22,5620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5620);
	// lwz r22,5640(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5640);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5460(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5460);
	// lwz r22,5924(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5924);
loc_82C9137C:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,12
	ctx.r3.s64 = 12;
	// bl 0x82c91048
	ctx.lr = 0x82C91394;
	sub_82C91048(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C9139C:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,13
	ctx.r3.s64 = 13;
	// bl 0x82c91048
	ctx.lr = 0x82C913B4;
	sub_82C91048(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C913BC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9128c
	if (ctx.cr6.eq) goto loc_82C9128C;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c913e4
	if (!ctx.cr6.eq) goto loc_82C913E4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c913ec
	goto loc_82C913EC;
loc_82C913E4:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C913EC;
	sub_82C8DAE8(ctx, base);
loc_82C913EC:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c91a64
	if (ctx.cr6.gt) goto loc_82C91A64;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,5136
	ctx.r12.s64 = ctx.r12.s64 + 5136;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9149C;
	case 1:
		goto loc_82C9149C;
	case 2:
		goto loc_82C9149C;
	case 3:
		goto loc_82C91A64;
	case 4:
		goto loc_82C91A64;
	case 5:
		goto loc_82C91A64;
	case 6:
		goto loc_82C91A64;
	case 7:
		goto loc_82C91A64;
	case 8:
		goto loc_82C91A64;
	case 9:
		goto loc_82C91A64;
	case 10:
		goto loc_82C91488;
	case 11:
		goto loc_82C91474;
	case 12:
		goto loc_82C91A64;
	case 13:
		goto loc_82C91A64;
	case 14:
		goto loc_82C91A64;
	case 15:
		goto loc_82C91A64;
	case 16:
		goto loc_82C91A64;
	case 17:
		goto loc_82C9149C;
	case 18:
		goto loc_82C91A64;
	case 19:
		goto loc_82C9149C;
	case 20:
		goto loc_82C91A64;
	case 21:
		goto loc_82C91A64;
	case 22:
		goto loc_82C91A64;
	case 23:
		goto loc_82C91A64;
	case 24:
		goto loc_82C9149C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5276(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,5276(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,5276(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5256);
	// lwz r22,5236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5236);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5276(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5276(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5276(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5276);
loc_82C91474:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8e9b0
	ctx.lr = 0x82C91480;
	sub_82C8E9B0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91488:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c8ece8
	ctx.lr = 0x82C91494;
	sub_82C8ECE8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C9149C:
	// addi r11,r10,-2
	ctx.r11.s64 = ctx.r10.s64 + -2;
	// li r3,29
	ctx.r3.s64 = 29;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C914B0:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c914cc
	if (!ctx.cr6.eq) goto loc_82C914CC;
	// stw r5,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r5.u32);
	// li r3,-15
	ctx.r3.s64 = -15;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C914CC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91530
	if (ctx.cr6.eq) goto loc_82C91530;
loc_82C914D8:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c914f4
	if (!ctx.cr6.eq) goto loc_82C914F4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c914fc
	goto loc_82C914FC;
loc_82C914F4:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C914FC;
	sub_82C8DAE8(ctx, base);
loc_82C914FC:
	// cmpwi cr6,r3,9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 9, ctx.xer);
	// beq cr6,0x82c91518
	if (ctx.cr6.eq) goto loc_82C91518;
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// beq cr6,0x82c91524
	if (ctx.cr6.eq) goto loc_82C91524;
	// cmpwi cr6,r3,21
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 21, ctx.xer);
	// bne cr6,0x82c91530
	if (!ctx.cr6.eq) goto loc_82C91530;
	// b 0x82c91524
	goto loc_82C91524;
loc_82C91518:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91530
	if (ctx.cr6.eq) goto loc_82C91530;
loc_82C91524:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c914d8
	if (!ctx.cr6.eq) goto loc_82C914D8;
loc_82C91530:
	// li r3,15
	ctx.r3.s64 = 15;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91540:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c90b20
	ctx.lr = 0x82C9154C;
	sub_82C90B20(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91554:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,38
	ctx.r3.s64 = 38;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91568:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,25
	ctx.r3.s64 = 25;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C9157C:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91594
	if (!ctx.cr6.eq) goto loc_82C91594;
	// li r3,-26
	ctx.r3.s64 = -26;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91594:
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c915e4
	if (!ctx.cr6.eq) goto loc_82C915E4;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,93
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 93, ctx.xer);
	// bne cr6,0x82c915e4
	if (!ctx.cr6.eq) goto loc_82C915E4;
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9128c
	if (ctx.cr6.eq) goto loc_82C9128C;
	// lbz r9,3(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c915e4
	if (!ctx.cr6.eq) goto loc_82C915E4;
	// lbz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c915e4
	if (!ctx.cr6.eq) goto loc_82C915E4;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// li r3,34
	ctx.r3.s64 = 34;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C915E4:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,26
	ctx.r3.s64 = 26;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C915F4:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,23
	ctx.r3.s64 = 23;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91608:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91620
	if (!ctx.cr6.eq) goto loc_82C91620;
	// li r3,-24
	ctx.r3.s64 = -24;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91620:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c9163c
	if (!ctx.cr6.eq) goto loc_82C9163C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c91644
	goto loc_82C91644;
loc_82C9163C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C91644;
	sub_82C8DAE8(ctx, base);
loc_82C91644:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 27, ctx.xer);
	// bgt cr6,0x82c91a64
	if (ctx.cr6.gt) goto loc_82C91A64;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,5736
	ctx.r12.s64 = ctx.r12.s64 + 5736;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C91714;
	case 1:
		goto loc_82C91714;
	case 2:
		goto loc_82C91714;
	case 3:
		goto loc_82C91A64;
	case 4:
		goto loc_82C91A64;
	case 5:
		goto loc_82C91A64;
	case 6:
		goto loc_82C916EC;
	case 7:
		goto loc_82C91A64;
	case 8:
		goto loc_82C91A64;
	case 9:
		goto loc_82C91A64;
	case 10:
		goto loc_82C91A64;
	case 11:
		goto loc_82C91A64;
	case 12:
		goto loc_82C91714;
	case 13:
		goto loc_82C91A64;
	case 14:
		goto loc_82C91A64;
	case 15:
		goto loc_82C91A64;
	case 16:
		goto loc_82C91A64;
	case 17:
		goto loc_82C91A64;
	case 18:
		goto loc_82C91A64;
	case 19:
		goto loc_82C91A64;
	case 20:
		goto loc_82C91A64;
	case 21:
		goto loc_82C91A64;
	case 22:
		goto loc_82C91A64;
	case 23:
		goto loc_82C91714;
	case 24:
		goto loc_82C916D8;
	case 25:
		goto loc_82C91700;
	case 26:
		goto loc_82C91714;
	case 27:
		goto loc_82C91714;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,5908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,5908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5868(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5868);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,5908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,5848(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5848);
	// lwz r22,5888(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5888);
	// lwz r22,5908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
	// lwz r22,5908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5908);
loc_82C916D8:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,36
	ctx.r3.s64 = 36;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C916EC:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,35
	ctx.r3.s64 = 35;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91700:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,37
	ctx.r3.s64 = 37;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91714:
	// li r3,24
	ctx.r3.s64 = 24;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91724:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,21
	ctx.r3.s64 = 21;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91738:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,17
	ctx.r3.s64 = 17;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C9174C:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c90db0
	ctx.lr = 0x82C91758;
	sub_82C90DB0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91760:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c91a64
	if (!ctx.cr6.lt) goto loc_82C91A64;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91778:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c91a64
	if (!ctx.cr6.lt) goto loc_82C91A64;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91790:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c91a64
	if (!ctx.cr6.lt) goto loc_82C91A64;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C917A8:
	// clrlwi r11,r8,24
	ctx.r11.u64 = ctx.r8.u32 & 0xFF;
	// addi r7,r31,1280
	ctx.r7.s64 = ctx.r31.s64 + 1280;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r8,r30,r4
	ctx.r8.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r30.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r3,r11,r7
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r4,r3,3
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r7,r4,r9
	ctx.r7.u64 = ctx.r4.u64 + ctx.r9.u64;
	// rlwinm r4,r7,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r4,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r31.u32);
	// and r7,r3,r8
	ctx.r7.u64 = ctx.r3.u64 & ctx.r8.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c917e4
	if (ctx.cr6.eq) goto loc_82C917E4;
loc_82C917DC:
	// li r8,18
	ctx.r8.s64 = 18;
	// b 0x82c9180c
	goto loc_82C9180C;
loc_82C917E4:
	// addi r7,r31,1536
	ctx.r7.s64 = ctx.r31.s64 + 1536;
	// lbzx r4,r11,r7
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r31
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	// and r8,r9,r8
	ctx.r8.u64 = ctx.r9.u64 & ctx.r8.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82c91a64
	if (ctx.cr6.eq) goto loc_82C91A64;
loc_82C91808:
	// li r8,19
	ctx.r8.s64 = 19;
loc_82C9180C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91900
	if (ctx.cr6.eq) goto loc_82C91900;
loc_82C91818:
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c91834
	if (!ctx.cr6.eq) goto loc_82C91834;
	// add r11,r4,r29
	ctx.r11.u64 = ctx.r4.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9183c
	goto loc_82C9183C;
loc_82C91834:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C9183C;
	sub_82C8DAE8(ctx, base);
loc_82C9183C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 31, ctx.xer);
	// bgt cr6,0x82c91a64
	if (ctx.cr6.gt) goto loc_82C91A64;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,6240
	ctx.r12.s64 = ctx.r12.s64 + 6240;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C91760;
	case 1:
		goto loc_82C91778;
	case 2:
		goto loc_82C91790;
	case 3:
		goto loc_82C91A64;
	case 4:
		goto loc_82C91A00;
	case 5:
		goto loc_82C91A00;
	case 6:
		goto loc_82C91A00;
	case 7:
		goto loc_82C91A64;
	case 8:
		goto loc_82C91A64;
	case 9:
		goto loc_82C91A64;
	case 10:
		goto loc_82C91A48;
	case 11:
		goto loc_82C91A64;
	case 12:
		goto loc_82C91A64;
	case 13:
		goto loc_82C91A64;
	case 14:
		goto loc_82C91A64;
	case 15:
		goto loc_82C91A00;
	case 16:
		goto loc_82C91A00;
	case 17:
		goto loc_82C919F8;
	case 18:
		goto loc_82C918E0;
	case 19:
		goto loc_82C919F8;
	case 20:
		goto loc_82C919F8;
	case 21:
		goto loc_82C919F8;
	case 22:
		goto loc_82C919F8;
	case 23:
		goto loc_82C91A64;
	case 24:
		goto loc_82C919C4;
	case 25:
		goto loc_82C91A00;
	case 26:
		goto loc_82C91A64;
	case 27:
		goto loc_82C91A00;
	case 28:
		goto loc_82C91A2C;
	case 29:
		goto loc_82C91A10;
	case 30:
		goto loc_82C91A00;
	case 31:
		goto loc_82C91A00;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5984(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5984);
	// lwz r22,6008(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6008);
	// lwz r22,6032(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6032);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6728(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6728);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6368(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6368);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6596);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6756);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6700(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6700);
	// lwz r22,6672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6672);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
	// lwz r22,6656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6656);
loc_82C918E0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmpwi cr6,r8,18
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 18, ctx.xer);
	// beq cr6,0x82c9190c
	if (ctx.cr6.eq) goto loc_82C9190C;
	// cmpwi cr6,r8,41
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 41, ctx.xer);
	// bne cr6,0x82c918f8
	if (!ctx.cr6.eq) goto loc_82C918F8;
loc_82C918F4:
	// li r8,19
	ctx.r8.s64 = 19;
loc_82C918F8:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91818
	if (!ctx.cr6.eq) goto loc_82C91818;
loc_82C91900:
	// neg r3,r8
	ctx.r3.s64 = -ctx.r8.s64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C9190C:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9128c
	if (ctx.cr6.eq) goto loc_82C9128C;
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// li r8,41
	ctx.r8.s64 = 41;
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c91934
	if (!ctx.cr6.eq) goto loc_82C91934;
	// add r11,r4,r29
	ctx.r11.u64 = ctx.r4.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9193c
	goto loc_82C9193C;
loc_82C91934:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8dae8
	ctx.lr = 0x82C9193C;
	sub_82C8DAE8(ctx, base);
loc_82C9193C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c918f4
	if (ctx.cr6.gt) goto loc_82C918F4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,6496
	ctx.r12.s64 = ctx.r12.s64 + 6496;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C91760;
	case 1:
		goto loc_82C91778;
	case 2:
		goto loc_82C91790;
	case 3:
		goto loc_82C918F4;
	case 4:
		goto loc_82C918F4;
	case 5:
		goto loc_82C918F4;
	case 6:
		goto loc_82C918F4;
	case 7:
		goto loc_82C918F4;
	case 8:
		goto loc_82C918F4;
	case 9:
		goto loc_82C918F4;
	case 10:
		goto loc_82C918F4;
	case 11:
		goto loc_82C918F4;
	case 12:
		goto loc_82C918F4;
	case 13:
		goto loc_82C918F4;
	case 14:
		goto loc_82C918F4;
	case 15:
		goto loc_82C918F4;
	case 16:
		goto loc_82C918F4;
	case 17:
		goto loc_82C919F8;
	case 18:
		goto loc_82C918F4;
	case 19:
		goto loc_82C919F8;
	case 20:
		goto loc_82C919F8;
	case 21:
		goto loc_82C919F8;
	case 22:
		goto loc_82C919F8;
	case 23:
		goto loc_82C918F4;
	case 24:
		goto loc_82C919C4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,5984(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5984);
	// lwz r22,6008(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6008);
	// lwz r22,6032(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6032);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6648);
	// lwz r22,6388(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6388);
	// lwz r22,6596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6596);
loc_82C919C4:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// addi r7,r31,1536
	ctx.r7.s64 = ctx.r31.s64 + 1536;
	// rlwinm r9,r4,27,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// slw r3,r30,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r30.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r31
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r31.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c91a64
	if (ctx.cr6.eq) goto loc_82C91A64;
loc_82C919F8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c918f8
	goto loc_82C918F8;
loc_82C91A00:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91A10:
	// cmpwi cr6,r8,19
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 19, ctx.xer);
	// beq cr6,0x82c91a64
	if (ctx.cr6.eq) goto loc_82C91A64;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,32
	ctx.r3.s64 = 32;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91A2C:
	// cmpwi cr6,r8,19
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 19, ctx.xer);
	// beq cr6,0x82c91a64
	if (ctx.cr6.eq) goto loc_82C91A64;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,31
	ctx.r3.s64 = 31;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91A48:
	// cmpwi cr6,r8,19
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 19, ctx.xer);
	// beq cr6,0x82c91a64
	if (ctx.cr6.eq) goto loc_82C91A64;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,30
	ctx.r3.s64 = 30;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C91A64:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
}

__attribute__((alias("__imp__sub_82C91A74"))) PPC_WEAK_FUNC(sub_82C91A74);
PPC_FUNC_IMPL(__imp__sub_82C91A74) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C91A78"))) PPC_WEAK_FUNC(sub_82C91A78);
PPC_FUNC_IMPL(__imp__sub_82C91A78) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91aa8
	if (!ctx.cr6.eq) goto loc_82C91AA8;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91AA8:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C91AAC:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c91ac8
	if (!ctx.cr6.eq) goto loc_82C91AC8;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c91ad0
	goto loc_82C91AD0;
loc_82C91AC8:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C91AD0;
	sub_82C8DAE8(ctx, base);
loc_82C91AD0:
	// addi r11,r3,-2
	ctx.r11.s64 = ctx.r3.s64 + -2;
	// cmplwi cr6,r11,19
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 19, ctx.xer);
	// bgt cr6,0x82c91b54
	if (ctx.cr6.gt) goto loc_82C91B54;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,6900
	ctx.r12.s64 = ctx.r12.s64 + 6900;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C91B9C;
	case 1:
		goto loc_82C91B78;
	case 2:
		goto loc_82C91B54;
	case 3:
		goto loc_82C91B54;
	case 4:
		goto loc_82C91B44;
	case 5:
		goto loc_82C91B4C;
	case 6:
		goto loc_82C91B54;
	case 7:
		goto loc_82C91BD8;
	case 8:
		goto loc_82C91BB4;
	case 9:
		goto loc_82C91B54;
	case 10:
		goto loc_82C91B54;
	case 11:
		goto loc_82C91B54;
	case 12:
		goto loc_82C91B54;
	case 13:
		goto loc_82C91B54;
	case 14:
		goto loc_82C91B54;
	case 15:
		goto loc_82C91B54;
	case 16:
		goto loc_82C91B54;
	case 17:
		goto loc_82C91B54;
	case 18:
		goto loc_82C91B54;
	case 19:
		goto loc_82C91C48;
	default:
		__builtin_unreachable();
	}
	// lwz r22,7068(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7068);
	// lwz r22,7032(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7032);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6980(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6980);
	// lwz r22,6988(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6988);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,7128(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7128);
	// lwz r22,7092(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7092);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,6996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 6996);
	// lwz r22,7240(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7240);
loc_82C91B44:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c91b58
	goto loc_82C91B58;
loc_82C91B4C:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c91b58
	goto loc_82C91B58;
loc_82C91B54:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C91B58:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91aac
	if (!ctx.cr6.eq) goto loc_82C91AAC;
loc_82C91B60:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91B78:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91b60
	if (!ctx.cr6.eq) goto loc_82C91B60;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8f940
	ctx.lr = 0x82C91B8C;
	sub_82C8F940(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91B9C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91BB4:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91b60
	if (!ctx.cr6.eq) goto loc_82C91B60;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91BD8:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91b60
	if (!ctx.cr6.eq) goto loc_82C91B60;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91c00
	if (!ctx.cr6.eq) goto loc_82C91C00;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91C00:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c91c1c
	if (!ctx.cr6.eq) goto loc_82C91C1C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c91c24
	goto loc_82C91C24;
loc_82C91C1C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C91C24;
	sub_82C8DAE8(ctx, base);
loc_82C91C24:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c91c30
	if (!ctx.cr6.eq) goto loc_82C91C30;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C91C30:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91C48:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91b60
	if (!ctx.cr6.eq) goto loc_82C91B60;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,39
	ctx.r3.s64 = 39;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C91C6C"))) PPC_WEAK_FUNC(sub_82C91C6C);
PPC_FUNC_IMPL(__imp__sub_82C91C6C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C91C70"))) PPC_WEAK_FUNC(sub_82C91C70);
PPC_FUNC_IMPL(__imp__sub_82C91C70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91ca0
	if (!ctx.cr6.eq) goto loc_82C91CA0;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91CA0:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C91CA4:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c91cc0
	if (!ctx.cr6.eq) goto loc_82C91CC0;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c91cc8
	goto loc_82C91CC8;
loc_82C91CC0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C91CC8;
	sub_82C8DAE8(ctx, base);
loc_82C91CC8:
	// addi r11,r3,-3
	ctx.r11.s64 = ctx.r3.s64 + -3;
	// cmplwi cr6,r11,27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 27, ctx.xer);
	// bgt cr6,0x82c91d6c
	if (ctx.cr6.gt) goto loc_82C91D6C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,7404
	ctx.r12.s64 = ctx.r12.s64 + 7404;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C91D90;
	case 1:
		goto loc_82C91D6C;
	case 2:
		goto loc_82C91D6C;
	case 3:
		goto loc_82C91D5C;
	case 4:
		goto loc_82C91D64;
	case 5:
		goto loc_82C91D6C;
	case 6:
		goto loc_82C91E08;
	case 7:
		goto loc_82C91DE4;
	case 8:
		goto loc_82C91D6C;
	case 9:
		goto loc_82C91D6C;
	case 10:
		goto loc_82C91D6C;
	case 11:
		goto loc_82C91D6C;
	case 12:
		goto loc_82C91D6C;
	case 13:
		goto loc_82C91D6C;
	case 14:
		goto loc_82C91D6C;
	case 15:
		goto loc_82C91D6C;
	case 16:
		goto loc_82C91D6C;
	case 17:
		goto loc_82C91D6C;
	case 18:
		goto loc_82C91D6C;
	case 19:
		goto loc_82C91D6C;
	case 20:
		goto loc_82C91D6C;
	case 21:
		goto loc_82C91D6C;
	case 22:
		goto loc_82C91D6C;
	case 23:
		goto loc_82C91D6C;
	case 24:
		goto loc_82C91D6C;
	case 25:
		goto loc_82C91D6C;
	case 26:
		goto loc_82C91D6C;
	case 27:
		goto loc_82C91DB4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,7568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7568);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7516(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7516);
	// lwz r22,7524(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7524);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7688(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7688);
	// lwz r22,7652(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7652);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7532);
	// lwz r22,7604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7604);
loc_82C91D5C:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c91d70
	goto loc_82C91D70;
loc_82C91D64:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c91d70
	goto loc_82C91D70;
loc_82C91D6C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C91D70:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91ca4
	if (!ctx.cr6.eq) goto loc_82C91CA4;
loc_82C91D78:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C91D80:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91D90:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91d78
	if (!ctx.cr6.eq) goto loc_82C91D78;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c8f940
	ctx.lr = 0x82C91DA4;
	sub_82C8F940(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91DB4:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91d78
	if (!ctx.cr6.eq) goto loc_82C91D78;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c90b20
	ctx.lr = 0x82C91DC8;
	sub_82C90B20(ctx, base);
	// cmpwi cr6,r3,22
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 22, ctx.xer);
	// bne cr6,0x82c91d80
	if (!ctx.cr6.eq) goto loc_82C91D80;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91DE4:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91d78
	if (!ctx.cr6.eq) goto loc_82C91D78;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91E08:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c91d78
	if (!ctx.cr6.eq) goto loc_82C91D78;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91e30
	if (!ctx.cr6.eq) goto loc_82C91E30;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91E30:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c91e4c
	if (!ctx.cr6.eq) goto loc_82C91E4C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c91e54
	goto loc_82C91E54;
loc_82C91E4C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C91E54;
	sub_82C8DAE8(ctx, base);
loc_82C91E54:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c91e60
	if (!ctx.cr6.eq) goto loc_82C91E60;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C91E60:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C91E78"))) PPC_WEAK_FUNC(sub_82C91E78);
PPC_FUNC_IMPL(__imp__sub_82C91E78) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// li r8,0
	ctx.r8.s64 = 0;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c91ea8
	if (ctx.cr6.eq) goto loc_82C91EA8;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C91EA8:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91f34
	if (ctx.cr6.eq) goto loc_82C91F34;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C91EB4:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c91ed0
	if (!ctx.cr6.eq) goto loc_82C91ED0;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c91ed8
	goto loc_82C91ED8;
loc_82C91ED0:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C91ED8;
	sub_82C8DAE8(ctx, base);
loc_82C91ED8:
	// cmplwi cr6,r3,8
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 8, ctx.xer);
	// bgt cr6,0x82c91f24
	if (ctx.cr6.gt) goto loc_82C91F24;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,7928
	ctx.r12.s64 = ctx.r12.s64 + 7928;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C92044;
	case 1:
		goto loc_82C92044;
	case 2:
		goto loc_82C91F70;
	case 3:
		goto loc_82C91F24;
	case 4:
		goto loc_82C91FC8;
	case 5:
		goto loc_82C91F1C;
	case 6:
		goto loc_82C91F48;
	case 7:
		goto loc_82C91F5C;
	case 8:
		goto loc_82C92044;
	default:
		__builtin_unreachable();
	}
	// lwz r22,8260(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8260);
	// lwz r22,8260(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8260);
	// lwz r22,8048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8048);
	// lwz r22,7972(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7972);
	// lwz r22,8136(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8136);
	// lwz r22,7964(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 7964);
	// lwz r22,8008(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8008);
	// lwz r22,8028(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8028);
	// lwz r22,8260(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8260);
loc_82C91F1C:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c92030
	if (ctx.cr6.lt) goto loc_82C92030;
loc_82C91F24:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
loc_82C91F2C:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c91eb4
	if (!ctx.cr6.eq) goto loc_82C91EB4;
loc_82C91F34:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C91F48:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c92030
	if (ctx.cr6.lt) goto loc_82C92030;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c91f2c
	goto loc_82C91F2C;
loc_82C91F5C:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c92030
	if (ctx.cr6.lt) goto loc_82C92030;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c91f2c
	goto loc_82C91F2C;
loc_82C91F70:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91f34
	if (ctx.cr6.eq) goto loc_82C91F34;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,33
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 33, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91f34
	if (ctx.cr6.eq) goto loc_82C91F34;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,91
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 91, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// b 0x82c91f24
	goto loc_82C91F24;
loc_82C91FC8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91f34
	if (ctx.cr6.eq) goto loc_82C91F34;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c91f34
	if (ctx.cr6.eq) goto loc_82C91F34;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// bne cr6,0x82c91f2c
	if (!ctx.cr6.eq) goto loc_82C91F2C;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82c9205c
	if (ctx.cr6.eq) goto loc_82C9205C;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// b 0x82c91f2c
	goto loc_82C91F2C;
loc_82C92030:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92044:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C9205C:
	// li r3,42
	ctx.r3.s64 = 42;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92074"))) PPC_WEAK_FUNC(sub_82C92074);
PPC_FUNC_IMPL(__imp__sub_82C92074) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C92078"))) PPC_WEAK_FUNC(sub_82C92078);
PPC_FUNC_IMPL(__imp__sub_82C92078) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r10,r4,2
	ctx.r10.s64 = ctx.r4.s64 + 2;
	// addi r7,r5,-2
	ctx.r7.s64 = ctx.r5.s64 + -2;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r7
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x82c921bc
	if (ctx.cr6.eq) goto loc_82C921BC;
loc_82C92098:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// extsb r9,r3
	ctx.r9.s64 = ctx.r3.s8;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c920b8
	if (!ctx.cr6.eq) goto loc_82C920B8;
	// add r11,r4,r8
	ctx.r11.u64 = ctx.r4.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c920bc
	goto loc_82C920BC;
loc_82C920B8:
	// bl 0x82c8dae8
	ctx.lr = 0x82C920BC;
	sub_82C8DAE8(ctx, base);
loc_82C920BC:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 26, ctx.xer);
	// bgt cr6,0x82c92194
	if (ctx.cr6.gt) goto loc_82C92194;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,8416
	ctx.r12.s64 = ctx.r12.s64 + 8416;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C921B0;
	case 1:
		goto loc_82C921B0;
	case 2:
		goto loc_82C92194;
	case 3:
		goto loc_82C92194;
	case 4:
		goto loc_82C921B0;
	case 5:
		goto loc_82C921B0;
	case 6:
		goto loc_82C921B0;
	case 7:
		goto loc_82C921B0;
	case 8:
		goto loc_82C921B0;
	case 9:
		goto loc_82C921B0;
	case 10:
		goto loc_82C921B0;
	case 11:
		goto loc_82C92194;
	case 12:
		goto loc_82C9214C;
	case 13:
		goto loc_82C92178;
	case 14:
		goto loc_82C921B0;
	case 15:
		goto loc_82C921B0;
	case 16:
		goto loc_82C921B0;
	case 17:
		goto loc_82C92178;
	case 18:
		goto loc_82C921B0;
	case 19:
		goto loc_82C92194;
	case 20:
		goto loc_82C92194;
	case 21:
		goto loc_82C921B0;
	case 22:
		goto loc_82C921B0;
	case 23:
		goto loc_82C921B0;
	case 24:
		goto loc_82C921B0;
	case 25:
		goto loc_82C921B0;
	case 26:
		goto loc_82C921B0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8524(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8524);
	// lwz r22,8568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8568);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8568);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8596);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
	// lwz r22,8624(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8624);
loc_82C9214C:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c921b0
	if (!ctx.cr6.eq) goto loc_82C921B0;
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82c921b0
	if (!ctx.cr6.eq) goto loc_82C921B0;
loc_82C92160:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92178:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// beq cr6,0x82c92188
	if (ctx.cr6.eq) goto loc_82C92188;
	// li r11,-1
	ctx.r11.s64 = -1;
loc_82C92188:
	// rlwinm r11,r11,0,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c921b0
	if (ctx.cr6.eq) goto loc_82C921B0;
loc_82C92194:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c92160
	if (!ctx.cr6.eq) goto loc_82C92160;
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,36
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 36, ctx.xer);
	// beq cr6,0x82c921b0
	if (ctx.cr6.eq) goto loc_82C921B0;
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// bne cr6,0x82c92160
	if (!ctx.cr6.eq) goto loc_82C92160;
loc_82C921B0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r7
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, ctx.xer);
	// bne cr6,0x82c92098
	if (!ctx.cr6.eq) goto loc_82C92098;
loc_82C921BC:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C921D0"))) PPC_WEAK_FUNC(sub_82C921D0);
PPC_FUNC_IMPL(__imp__sub_82C921D0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C921D8;
	sub_82CA2BE4(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r27,0
	ctx.r27.s64 = 0;
	// addi r8,r4,2
	ctx.r8.s64 = ctx.r4.s64 + 2;
	// li r29,1
	ctx.r29.s64 = 1;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// mr r30,r27
	ctx.r30.u64 = ctx.r27.u64;
	// addi r31,r8,2
	ctx.r31.s64 = ctx.r8.s64 + 2;
loc_82C921FC:
	// lbz r3,1(r8)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// lbz r4,0(r8)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// extsb r10,r3
	ctx.r10.s64 = ctx.r3.s8;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9221c
	if (!ctx.cr6.eq) goto loc_82C9221C;
	// add r11,r4,r28
	ctx.r11.u64 = ctx.r4.u64 + ctx.r28.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92220
	goto loc_82C92220;
loc_82C9221C:
	// bl 0x82c8dae8
	ctx.lr = 0x82C92220;
	sub_82C8DAE8(ctx, base);
loc_82C92220:
	// addi r11,r3,-3
	ctx.r11.s64 = ctx.r3.s64 + -3;
	// cmplwi cr6,r11,26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 26, ctx.xer);
	// bgt cr6,0x82c924c8
	if (ctx.cr6.gt) goto loc_82C924C8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,8772
	ctx.r12.s64 = ctx.r12.s64 + 8772;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C924A8;
	case 1:
		goto loc_82C924C8;
	case 2:
		goto loc_82C922B0;
	case 3:
		goto loc_82C922D8;
	case 4:
		goto loc_82C92308;
	case 5:
		goto loc_82C924C8;
	case 6:
		goto loc_82C92488;
	case 7:
		goto loc_82C92488;
	case 8:
		goto loc_82C924C0;
	case 9:
		goto loc_82C92338;
	case 10:
		goto loc_82C9238C;
	case 11:
		goto loc_82C924C8;
	case 12:
		goto loc_82C924C8;
	case 13:
		goto loc_82C924C8;
	case 14:
		goto loc_82C924C0;
	case 15:
		goto loc_82C924C8;
	case 16:
		goto loc_82C924C8;
	case 17:
		goto loc_82C924C8;
	case 18:
		goto loc_82C923E0;
	case 19:
		goto loc_82C922B0;
	case 20:
		goto loc_82C924C8;
	case 21:
		goto loc_82C922B0;
	case 22:
		goto loc_82C924C8;
	case 23:
		goto loc_82C924C8;
	case 24:
		goto loc_82C924C8;
	case 25:
		goto loc_82C924C8;
	case 26:
		goto loc_82C922B0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,9384(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9384);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,8880(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8880);
	// lwz r22,8920(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8920);
	// lwz r22,8968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8968);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9352);
	// lwz r22,9352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9352);
	// lwz r22,9408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9408);
	// lwz r22,9016(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9016);
	// lwz r22,9100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9100);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9408);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9184(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9184);
	// lwz r22,8880(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8880);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,8880(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8880);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,9416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9416);
	// lwz r22,8880(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8880);
loc_82C922B0:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c924c8
	if (!ctx.cr6.eq) goto loc_82C924C8;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c922c8
	if (!ctx.cr6.lt) goto loc_82C922C8;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r29.u8);
loc_82C922C8:
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C922D8:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c922f4
	if (!ctx.cr6.eq) goto loc_82C922F4;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c922f0
	if (!ctx.cr6.lt) goto loc_82C922F0;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r29.u8);
loc_82C922F0:
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
loc_82C922F4:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C92308:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c92324
	if (!ctx.cr6.eq) goto loc_82C92324;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c92320
	if (!ctx.cr6.lt) goto loc_82C92320;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r29.u8);
loc_82C92320:
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
loc_82C92324:
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C92338:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// beq cr6,0x82c92360
	if (ctx.cr6.eq) goto loc_82C92360;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c9234c
	if (!ctx.cr6.lt) goto loc_82C9234C;
	// stw r31,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r31.u32);
loc_82C9234C:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r30,12
	ctx.r30.s64 = 12;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C92360:
	// cmpwi cr6,r30,12
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 12, ctx.xer);
	// bne cr6,0x82c924c8
	if (!ctx.cr6.eq) goto loc_82C924C8;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c92378
	if (!ctx.cr6.lt) goto loc_82C92378;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
loc_82C92378:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C9238C:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// beq cr6,0x82c923b4
	if (ctx.cr6.eq) goto loc_82C923B4;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c923a0
	if (!ctx.cr6.lt) goto loc_82C923A0;
	// stw r31,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r31.u32);
loc_82C923A0:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r30,13
	ctx.r30.s64 = 13;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C923B4:
	// cmpwi cr6,r30,13
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 13, ctx.xer);
	// bne cr6,0x82c924c8
	if (!ctx.cr6.eq) goto loc_82C924C8;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c92378
	if (!ctx.cr6.lt) goto loc_82C92378;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C923E0:
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82c923f8
	if (!ctx.cr6.eq) goto loc_82C923F8;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C923F8:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c924c8
	if (!ctx.cr6.eq) goto loc_82C924C8;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c924c8
	if (!ctx.cr6.lt) goto loc_82C924C8;
	// lbz r11,12(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c924c8
	if (ctx.cr6.eq) goto loc_82C924C8;
	// lwz r11,4(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82c92478
	if (ctx.cr6.eq) goto loc_82C92478;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c92478
	if (!ctx.cr6.eq) goto loc_82C92478;
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,32
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 32, ctx.xer);
	// bne cr6,0x82c92478
	if (!ctx.cr6.eq) goto loc_82C92478;
	// lbz r3,3(r8)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r8.u32 + 3);
	// extsb r11,r3
	ctx.r11.s64 = ctx.r3.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c92468
	if (!ctx.cr6.eq) goto loc_82C92468;
	// lbz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// cmplwi cr6,r10,32
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 32, ctx.xer);
	// beq cr6,0x82c92478
	if (ctx.cr6.eq) goto loc_82C92478;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c92468
	if (!ctx.cr6.eq) goto loc_82C92468;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// add r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 + ctx.r28.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92470
	goto loc_82C92470;
loc_82C92468:
	// lbz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92470;
	sub_82C8DAE8(ctx, base);
loc_82C92470:
	// cmpw cr6,r3,r30
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r30.s32, ctx.xer);
	// bne cr6,0x82c924c8
	if (!ctx.cr6.eq) goto loc_82C924C8;
loc_82C92478:
	// stb r27,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r27.u8);
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C92488:
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82c924a0
	if (!ctx.cr6.eq) goto loc_82C924A0;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C924A0:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c924c8
	if (!ctx.cr6.eq) goto loc_82C924C8;
loc_82C924A8:
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c924c8
	if (!ctx.cr6.lt) goto loc_82C924C8;
	// stb r27,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r27.u8);
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C924C0:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c924d4
	if (!ctx.cr6.eq) goto loc_82C924D4;
loc_82C924C8:
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c921fc
	goto loc_82C921FC;
loc_82C924D4:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
}

__attribute__((alias("__imp__sub_82C924E0"))) PPC_WEAK_FUNC(sub_82C924E0);
PPC_FUNC_IMPL(__imp__sub_82C924E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// subf r11,r4,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// srawi r10,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 1;
	// addze r11,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r11.s64 = temp.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82c9262c
	if (ctx.cr6.eq) goto loc_82C9262C;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82c925d8
	if (ctx.cr6.eq) goto loc_82C925D8;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,97
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 97, ctx.xer);
	// beq cr6,0x82c92580
	if (ctx.cr6.eq) goto loc_82C92580;
	// cmpwi cr6,r11,113
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 113, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,3(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,117
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 117, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,111
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 111, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,2(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r11,116
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 116, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// li r3,34
	ctx.r3.s64 = 34;
	// blr 
	return;
loc_82C92580:
	// lbz r10,3(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,112
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 112, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,111
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 111, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,2(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r11,115
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 115, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// li r3,39
	ctx.r3.s64 = 39;
	// blr 
	return;
loc_82C925D8:
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,97
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 97, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,3(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,109
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 109, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,2(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r11,112
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 112, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// li r3,38
	ctx.r3.s64 = 38;
	// blr 
	return;
loc_82C9262C:
	// lbz r11,3(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,2(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// cmplwi cr6,r11,116
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 116, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,103
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 103, ctx.xer);
	// beq cr6,0x82c92670
	if (ctx.cr6.eq) goto loc_82C92670;
	// cmpwi cr6,r11,108
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 108, ctx.xer);
	// bne cr6,0x82c92678
	if (!ctx.cr6.eq) goto loc_82C92678;
	// li r3,60
	ctx.r3.s64 = 60;
	// blr 
	return;
loc_82C92670:
	// li r3,62
	ctx.r3.s64 = 62;
	// blr 
	return;
loc_82C92678:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92680"))) PPC_WEAK_FUNC(sub_82C92680);
PPC_FUNC_IMPL(__imp__sub_82C92680) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C92694:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r9,r10,1
	ctx.r9.s64 = ctx.r10.s64 + 1;
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c926b4
	if (!ctx.cr6.eq) goto loc_82C926B4;
	// add r11,r4,r8
	ctx.r11.u64 = ctx.r4.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c926b8
	goto loc_82C926B8;
loc_82C926B4:
	// bl 0x82c8dae8
	ctx.lr = 0x82C926B8;
	sub_82C8DAE8(ctx, base);
loc_82C926B8:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c927fc
	if (ctx.cr6.gt) goto loc_82C927FC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,9948
	ctx.r12.s64 = ctx.r12.s64 + 9948;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C92774;
	case 1:
		goto loc_82C9275C;
	case 2:
		goto loc_82C92740;
	case 3:
		goto loc_82C927FC;
	case 4:
		goto loc_82C927FC;
	case 5:
		goto loc_82C927FC;
	case 6:
		goto loc_82C927FC;
	case 7:
		goto loc_82C927FC;
	case 8:
		goto loc_82C927FC;
	case 9:
		goto loc_82C927FC;
	case 10:
		goto loc_82C927FC;
	case 11:
		goto loc_82C927FC;
	case 12:
		goto loc_82C927FC;
	case 13:
		goto loc_82C927FC;
	case 14:
		goto loc_82C927FC;
	case 15:
		goto loc_82C927FC;
	case 16:
		goto loc_82C927FC;
	case 17:
		goto loc_82C927B8;
	case 18:
		goto loc_82C927B8;
	case 19:
		goto loc_82C927B8;
	case 20:
		goto loc_82C927B8;
	case 21:
		goto loc_82C927B8;
	case 22:
		goto loc_82C927B8;
	case 23:
		goto loc_82C927FC;
	case 24:
		goto loc_82C927B8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,10100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10100);
	// lwz r22,10076(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10076);
	// lwz r22,10048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10048);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
	// lwz r22,10236(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10236);
	// lwz r22,10168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10168);
loc_82C92740:
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// extsb r7,r4
	ctx.r7.s64 = ctx.r4.s8;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// extsb r6,r11
	ctx.r6.s64 = ctx.r11.s8;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// cmpw cr6,r7,r6
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r6.s32, ctx.xer);
	// bne cr6,0x82c927a4
	if (!ctx.cr6.eq) goto loc_82C927A4;
loc_82C9275C:
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lbz r9,0(r5)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x82c927a4
	if (!ctx.cr6.eq) goto loc_82C927A4;
loc_82C92774:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r11,r10,1
	ctx.r11.s64 = ctx.r10.s64 + 1;
	// lbz r6,0(r5)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r9,r5,1
	ctx.r9.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r7,r6
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82c927a4
	if (!ctx.cr6.eq) goto loc_82C927A4;
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// lbz r6,0(r9)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r5,r9,1
	ctx.r5.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r7,r6
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, ctx.xer);
	// beq cr6,0x82c92694
	if (ctx.cr6.eq) goto loc_82C92694;
loc_82C927A4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C927B8:
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// extsb r7,r4
	ctx.r7.s64 = ctx.r4.s8;
	// addi r11,r5,1
	ctx.r11.s64 = ctx.r5.s64 + 1;
	// extsb r6,r10
	ctx.r6.s64 = ctx.r10.s8;
	// cmpw cr6,r6,r7
	ctx.cr6.compare<int32_t>(ctx.r6.s32, ctx.r7.s32, ctx.xer);
	// bne cr6,0x82c927a4
	if (!ctx.cr6.eq) goto loc_82C927A4;
	// lbz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r10,r9,1
	ctx.r10.s64 = ctx.r9.s64 + 1;
	// lbz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r5,r11,1
	ctx.r5.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r6,r7
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x82c92694
	if (ctx.cr6.eq) goto loc_82C92694;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C927FC:
	// lbz r3,1(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92818
	if (!ctx.cr6.eq) goto loc_82C92818;
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92820
	goto loc_82C92820;
loc_82C92818:
	// lbz r4,0(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92820;
	sub_82C8DAE8(ctx, base);
loc_82C92820:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c928a8
	if (ctx.cr6.gt) goto loc_82C928A8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,10308
	ctx.r12.s64 = ctx.r12.s64 + 10308;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C927A4;
	case 1:
		goto loc_82C927A4;
	case 2:
		goto loc_82C927A4;
	case 3:
		goto loc_82C928A8;
	case 4:
		goto loc_82C928A8;
	case 5:
		goto loc_82C928A8;
	case 6:
		goto loc_82C928A8;
	case 7:
		goto loc_82C928A8;
	case 8:
		goto loc_82C928A8;
	case 9:
		goto loc_82C928A8;
	case 10:
		goto loc_82C928A8;
	case 11:
		goto loc_82C928A8;
	case 12:
		goto loc_82C928A8;
	case 13:
		goto loc_82C928A8;
	case 14:
		goto loc_82C928A8;
	case 15:
		goto loc_82C928A8;
	case 16:
		goto loc_82C928A8;
	case 17:
		goto loc_82C927A4;
	case 18:
		goto loc_82C927A4;
	case 19:
		goto loc_82C927A4;
	case 20:
		goto loc_82C927A4;
	case 21:
		goto loc_82C927A4;
	case 22:
		goto loc_82C927A4;
	case 23:
		goto loc_82C928A8;
	case 24:
		goto loc_82C927A4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
	// lwz r22,10408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10408);
	// lwz r22,10148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10148);
loc_82C928A8:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C928BC"))) PPC_WEAK_FUNC(sub_82C928BC);
PPC_FUNC_IMPL(__imp__sub_82C928BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C928C0"))) PPC_WEAK_FUNC(sub_82C928C0);
PPC_FUNC_IMPL(__imp__sub_82C928C0) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c9290c
	if (ctx.cr6.eq) goto loc_82C9290C;
loc_82C928D0:
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9291c
	if (ctx.cr6.eq) goto loc_82C9291C;
	// lbz r10,1(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c9291c
	if (!ctx.cr6.eq) goto loc_82C9291C;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// cmpw cr6,r9,r11
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82c9291c
	if (!ctx.cr6.eq) goto loc_82C9291C;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// lbz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c928d0
	if (!ctx.cr6.eq) goto loc_82C928D0;
loc_82C9290C:
	// subf r11,r4,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r3,r10,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// blr 
	return;
loc_82C9291C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92924"))) PPC_WEAK_FUNC(sub_82C92924);
PPC_FUNC_IMPL(__imp__sub_82C92924) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C92928"))) PPC_WEAK_FUNC(sub_82C92928);
PPC_FUNC_IMPL(__imp__sub_82C92928) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C92940:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c9295c
	if (!ctx.cr6.eq) goto loc_82C9295C;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92964
	goto loc_82C92964;
loc_82C9295C:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92964;
	sub_82C8DAE8(ctx, base);
loc_82C92964:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c92a04
	if (ctx.cr6.gt) goto loc_82C92A04;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,10632
	ctx.r12.s64 = ctx.r12.s64 + 10632;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C929EC;
	case 1:
		goto loc_82C929F4;
	case 2:
		goto loc_82C929FC;
	case 3:
		goto loc_82C92A04;
	case 4:
		goto loc_82C92A04;
	case 5:
		goto loc_82C92A04;
	case 6:
		goto loc_82C92A04;
	case 7:
		goto loc_82C92A04;
	case 8:
		goto loc_82C92A04;
	case 9:
		goto loc_82C92A04;
	case 10:
		goto loc_82C92A04;
	case 11:
		goto loc_82C92A04;
	case 12:
		goto loc_82C92A04;
	case 13:
		goto loc_82C92A04;
	case 14:
		goto loc_82C92A04;
	case 15:
		goto loc_82C92A04;
	case 16:
		goto loc_82C92A04;
	case 17:
		goto loc_82C929EC;
	case 18:
		goto loc_82C929EC;
	case 19:
		goto loc_82C929EC;
	case 20:
		goto loc_82C929EC;
	case 21:
		goto loc_82C929EC;
	case 22:
		goto loc_82C929EC;
	case 23:
		goto loc_82C92A04;
	case 24:
		goto loc_82C929EC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10740(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10740);
	// lwz r22,10748(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10748);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
	// lwz r22,10756(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10756);
	// lwz r22,10732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10732);
loc_82C929EC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c92940
	goto loc_82C92940;
loc_82C929F4:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c92940
	goto loc_82C92940;
loc_82C929FC:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c92940
	goto loc_82C92940;
loc_82C92A04:
	// subf r3,r8,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r8.s64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92A18"))) PPC_WEAK_FUNC(sub_82C92A18);
PPC_FUNC_IMPL(__imp__sub_82C92A18) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C92A2C:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92a48
	if (!ctx.cr6.eq) goto loc_82C92A48;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92a50
	goto loc_82C92A50;
loc_82C92A48:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92A50;
	sub_82C8DAE8(ctx, base);
loc_82C92A50:
	// cmpwi cr6,r3,9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 9, ctx.xer);
	// blt cr6,0x82c92a70
	if (ctx.cr6.lt) goto loc_82C92A70;
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// ble cr6,0x82c92a68
	if (!ctx.cr6.gt) goto loc_82C92A68;
	// cmpwi cr6,r3,21
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 21, ctx.xer);
	// bne cr6,0x82c92a70
	if (!ctx.cr6.eq) goto loc_82C92A70;
loc_82C92A68:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c92a2c
	goto loc_82C92A2C;
loc_82C92A70:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92A84"))) PPC_WEAK_FUNC(sub_82C92A84);
PPC_FUNC_IMPL(__imp__sub_82C92A84) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C92A88"))) PPC_WEAK_FUNC(sub_82C92A88);
PPC_FUNC_IMPL(__imp__sub_82C92A88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c92b40
	if (ctx.cr6.eq) goto loc_82C92B40;
	// li r9,-1
	ctx.r9.s64 = -1;
loc_82C92AA8:
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92ac4
	if (!ctx.cr6.eq) goto loc_82C92AC4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92acc
	goto loc_82C92ACC;
loc_82C92AC4:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92ACC;
	sub_82C8DAE8(ctx, base);
loc_82C92ACC:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 5, ctx.xer);
	// bgt cr6,0x82c92b28
	if (ctx.cr6.gt) goto loc_82C92B28;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,10992
	ctx.r12.s64 = ctx.r12.s64 + 10992;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C92B28;
	case 1:
		goto loc_82C92B08;
	case 2:
		goto loc_82C92B10;
	case 3:
		goto loc_82C92B28;
	case 4:
		goto loc_82C92B50;
	case 5:
		goto loc_82C92B18;
	default:
		__builtin_unreachable();
	}
	// lwz r22,11048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11048);
	// lwz r22,11016(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11016);
	// lwz r22,11024(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11024);
	// lwz r22,11048(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11048);
	// lwz r22,11088(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11088);
	// lwz r22,11032(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11032);
loc_82C92B08:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c92b2c
	goto loc_82C92B2C;
loc_82C92B10:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c92b2c
	goto loc_82C92B2C;
loc_82C92B18:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// stw r9,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r9.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82C92B28:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C92B2C:
	// lwz r11,4(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r11.u32);
	// bne cr6,0x82c92aa8
	if (!ctx.cr6.eq) goto loc_82C92AA8;
loc_82C92B40:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92B50:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// beq cr6,0x82c92b98
	if (ctx.cr6.eq) goto loc_82C92B98;
	// lbz r3,1(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92b84
	if (!ctx.cr6.eq) goto loc_82C92B84;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92b8c
	goto loc_82C92B8C;
loc_82C92B84:
	// lbz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92B8C;
	sub_82C8DAE8(ctx, base);
loc_82C92B8C:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c92b98
	if (!ctx.cr6.eq) goto loc_82C92B98;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C92B98:
	// stw r9,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r9.u32);
	// b 0x82c92b2c
	goto loc_82C92B2C;
}

__attribute__((alias("__imp__sub_82C92BA0"))) PPC_WEAK_FUNC(sub_82C92BA0);
PPC_FUNC_IMPL(__imp__sub_82C92BA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c92cac
	if (ctx.cr6.eq) goto loc_82C92CAC;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c92d94
	if (!ctx.cr6.eq) goto loc_82C92D94;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,45
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 45, ctx.xer);
	// bne cr6,0x82c92d94
	if (!ctx.cr6.eq) goto loc_82C92D94;
	// addi r10,r4,2
	ctx.r10.s64 = ctx.r4.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c92cac
	if (ctx.cr6.eq) goto loc_82C92CAC;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C92BE0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92bfc
	if (!ctx.cr6.eq) goto loc_82C92BFC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92c04
	goto loc_82C92C04;
loc_82C92BFC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92C04;
	sub_82C8DAE8(ctx, base);
loc_82C92C04:
	// cmplwi cr6,r3,27
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 27, ctx.xer);
	// bgt cr6,0x82c92c9c
	if (ctx.cr6.gt) goto loc_82C92C9C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,11300
	ctx.r12.s64 = ctx.r12.s64 + 11300;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C92D64;
	case 1:
		goto loc_82C92D64;
	case 2:
		goto loc_82C92C9C;
	case 3:
		goto loc_82C92C9C;
	case 4:
		goto loc_82C92C9C;
	case 5:
		goto loc_82C92C94;
	case 6:
		goto loc_82C92CC0;
	case 7:
		goto loc_82C92CD4;
	case 8:
		goto loc_82C92D64;
	case 9:
		goto loc_82C92C9C;
	case 10:
		goto loc_82C92C9C;
	case 11:
		goto loc_82C92C9C;
	case 12:
		goto loc_82C92C9C;
	case 13:
		goto loc_82C92C9C;
	case 14:
		goto loc_82C92C9C;
	case 15:
		goto loc_82C92C9C;
	case 16:
		goto loc_82C92C9C;
	case 17:
		goto loc_82C92C9C;
	case 18:
		goto loc_82C92C9C;
	case 19:
		goto loc_82C92C9C;
	case 20:
		goto loc_82C92C9C;
	case 21:
		goto loc_82C92C9C;
	case 22:
		goto loc_82C92C9C;
	case 23:
		goto loc_82C92C9C;
	case 24:
		goto loc_82C92C9C;
	case 25:
		goto loc_82C92C9C;
	case 26:
		goto loc_82C92C9C;
	case 27:
		goto loc_82C92CE8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,11620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11620);
	// lwz r22,11620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11620);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11412(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11412);
	// lwz r22,11456(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11456);
	// lwz r22,11476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11476);
	// lwz r22,11620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11620);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11420);
	// lwz r22,11496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11496);
loc_82C92C94:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c92d50
	if (ctx.cr6.lt) goto loc_82C92D50;
loc_82C92C9C:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C92CA4:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c92be0
	if (!ctx.cr6.eq) goto loc_82C92BE0;
loc_82C92CAC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92CC0:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c92d50
	if (ctx.cr6.lt) goto loc_82C92D50;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c92ca4
	goto loc_82C92CA4;
loc_82C92CD4:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c92d50
	if (ctx.cr6.lt) goto loc_82C92D50;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c92ca4
	goto loc_82C92CA4;
loc_82C92CE8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c92cac
	if (ctx.cr6.eq) goto loc_82C92CAC;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c92ca4
	if (!ctx.cr6.eq) goto loc_82C92CA4;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,45
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 45, ctx.xer);
	// bne cr6,0x82c92ca4
	if (!ctx.cr6.eq) goto loc_82C92CA4;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c92cac
	if (ctx.cr6.eq) goto loc_82C92CAC;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c92d7c
	if (!ctx.cr6.eq) goto loc_82C92D7C;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c92d7c
	if (!ctx.cr6.eq) goto loc_82C92D7C;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,13
	ctx.r3.s64 = 13;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92D50:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92D64:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92D7C:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92D94:
	// stw r4,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r4.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C92DAC"))) PPC_WEAK_FUNC(sub_82C92DAC);
PPC_FUNC_IMPL(__imp__sub_82C92DAC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C92DB0"))) PPC_WEAK_FUNC(sub_82C92DB0);
PPC_FUNC_IMPL(__imp__sub_82C92DB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c92de0
	if (!ctx.cr6.eq) goto loc_82C92DE0;
loc_82C92DCC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92DE0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92dfc
	if (!ctx.cr6.eq) goto loc_82C92DFC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92e04
	goto loc_82C92E04;
loc_82C92DFC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92E04;
	sub_82C8DAE8(ctx, base);
loc_82C92E04:
	// addi r11,r3,-20
	ctx.r11.s64 = ctx.r3.s64 + -20;
	// cmplwi cr6,r11,7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 7, ctx.xer);
	// bgt cr6,0x82c93010
	if (ctx.cr6.gt) goto loc_82C93010;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,11816
	ctx.r12.s64 = ctx.r12.s64 + 11816;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C92E64;
	case 1:
		goto loc_82C93010;
	case 2:
		goto loc_82C92E80;
	case 3:
		goto loc_82C93010;
	case 4:
		goto loc_82C92E80;
	case 5:
		goto loc_82C93010;
	case 6:
		goto loc_82C93010;
	case 7:
		goto loc_82C92E48;
	default:
		__builtin_unreachable();
	}
	// lwz r22,11876(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11876);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,11904(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11904);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,11904(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11904);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,11848(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 11848);
loc_82C92E48:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c92ba0
	ctx.lr = 0x82C92E54;
	sub_82C92BA0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92E64:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,33
	ctx.r3.s64 = 33;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92E80:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c92dcc
	if (ctx.cr6.eq) goto loc_82C92DCC;
loc_82C92E8C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92ea8
	if (!ctx.cr6.eq) goto loc_82C92EA8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92eb0
	goto loc_82C92EB0;
loc_82C92EA8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92EB0;
	sub_82C8DAE8(ctx, base);
loc_82C92EB0:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bgt cr6,0x82c93010
	if (ctx.cr6.gt) goto loc_82C93010;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,11988
	ctx.r12.s64 = ctx.r12.s64 + 11988;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C92FF8;
	case 1:
		goto loc_82C92FF8;
	case 2:
		goto loc_82C93010;
	case 3:
		goto loc_82C93010;
	case 4:
		goto loc_82C93010;
	case 5:
		goto loc_82C93010;
	case 6:
		goto loc_82C93010;
	case 7:
		goto loc_82C93010;
	case 8:
		goto loc_82C93010;
	case 9:
		goto loc_82C93010;
	case 10:
		goto loc_82C93010;
	case 11:
		goto loc_82C93010;
	case 12:
		goto loc_82C92FF8;
	case 13:
		goto loc_82C92F2C;
	case 14:
		goto loc_82C93010;
	case 15:
		goto loc_82C92F2C;
	case 16:
		goto loc_82C93010;
	case 17:
		goto loc_82C93010;
	case 18:
		goto loc_82C93010;
	case 19:
		goto loc_82C93010;
	case 20:
		goto loc_82C93010;
	case 21:
		goto loc_82C92F4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12076(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12076);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12076(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12076);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12108(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12108);
loc_82C92F2C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c92e8c
	if (!ctx.cr6.eq) goto loc_82C92E8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C92F4C:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c92dcc
	if (ctx.cr6.eq) goto loc_82C92DCC;
	// lbz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c92f74
	if (!ctx.cr6.eq) goto loc_82C92F74;
	// lbz r11,3(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c92f7c
	goto loc_82C92F7C;
loc_82C92F74:
	// lbz r4,3(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// bl 0x82c8dae8
	ctx.lr = 0x82C92F7C;
	sub_82C8DAE8(ctx, base);
loc_82C92F7C:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bgt cr6,0x82c92ff8
	if (ctx.cr6.gt) goto loc_82C92FF8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,12192
	ctx.r12.s64 = ctx.r12.s64 + 12192;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C93010;
	case 1:
		goto loc_82C93010;
	case 2:
		goto loc_82C92FF8;
	case 3:
		goto loc_82C92FF8;
	case 4:
		goto loc_82C92FF8;
	case 5:
		goto loc_82C92FF8;
	case 6:
		goto loc_82C92FF8;
	case 7:
		goto loc_82C92FF8;
	case 8:
		goto loc_82C92FF8;
	case 9:
		goto loc_82C92FF8;
	case 10:
		goto loc_82C92FF8;
	case 11:
		goto loc_82C92FF8;
	case 12:
		goto loc_82C93010;
	case 13:
		goto loc_82C92FF8;
	case 14:
		goto loc_82C92FF8;
	case 15:
		goto loc_82C92FF8;
	case 16:
		goto loc_82C92FF8;
	case 17:
		goto loc_82C92FF8;
	case 18:
		goto loc_82C92FF8;
	case 19:
		goto loc_82C92FF8;
	case 20:
		goto loc_82C92FF8;
	case 21:
		goto loc_82C93010;
	default:
		__builtin_unreachable();
	}
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12280);
	// lwz r22,12304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12304);
loc_82C92FF8:
	// li r3,16
	ctx.r3.s64 = 16;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93010:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C93028"))) PPC_WEAK_FUNC(sub_82C93028);
PPC_FUNC_IMPL(__imp__sub_82C93028) {
	PPC_FUNC_PROLOGUE();
	// li r11,11
	ctx.r11.s64 = 11;
	// subf r10,r4,r5
	ctx.r10.s64 = ctx.r5.s64 - ctx.r4.s64;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// cmpwi cr6,r10,6
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 6, ctx.xer);
	// bne cr6,0x82c930e0
	if (!ctx.cr6.eq) goto loc_82C930E0;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c930e0
	if (!ctx.cr6.eq) goto loc_82C930E0;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,88
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 88, ctx.xer);
	// beq cr6,0x82c9306c
	if (ctx.cr6.eq) goto loc_82C9306C;
	// cmpwi cr6,r11,120
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 120, ctx.xer);
	// beq cr6,0x82c93070
	if (ctx.cr6.eq) goto loc_82C93070;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C9306C:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82C93070:
	// lbz r10,2(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c930e0
	if (!ctx.cr6.eq) goto loc_82C930E0;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,77
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 77, ctx.xer);
	// beq cr6,0x82c930a0
	if (ctx.cr6.eq) goto loc_82C930A0;
	// cmpwi cr6,r10,109
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 109, ctx.xer);
	// beq cr6,0x82c930a4
	if (ctx.cr6.eq) goto loc_82C930A4;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C930A0:
	// li r9,1
	ctx.r9.s64 = 1;
loc_82C930A4:
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c930e0
	if (!ctx.cr6.eq) goto loc_82C930E0;
	// lbz r11,3(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,76
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 76, ctx.xer);
	// beq cr6,0x82c930d0
	if (ctx.cr6.eq) goto loc_82C930D0;
	// cmpwi cr6,r11,108
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 108, ctx.xer);
	// bne cr6,0x82c930e0
	if (!ctx.cr6.eq) goto loc_82C930E0;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82c930d8
	if (ctx.cr6.eq) goto loc_82C930D8;
loc_82C930D0:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82C930D8:
	// li r11,12
	ctx.r11.s64 = 12;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82C930E0:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C930E8"))) PPC_WEAK_FUNC(sub_82C930E8);
PPC_FUNC_IMPL(__imp__sub_82C930E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C930F0;
	sub_82CA2BE8(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r31,r10
	ctx.r31.u64 = ctx.r10.u64;
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82c9311c
	if (!ctx.cr6.eq) goto loc_82C9311C;
loc_82C93110:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9311C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c93138
	if (!ctx.cr6.eq) goto loc_82C93138;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93144
	goto loc_82C93144;
loc_82C93138:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93144;
	sub_82C8DAE8(ctx, base);
loc_82C93144:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c93534
	if (ctx.cr6.gt) goto loc_82C93534;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,12660
	ctx.r12.s64 = ctx.r12.s64 + 12660;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C934F8;
	case 1:
		goto loc_82C93510;
	case 2:
		goto loc_82C93528;
	case 3:
		goto loc_82C93534;
	case 4:
		goto loc_82C93534;
	case 5:
		goto loc_82C93534;
	case 6:
		goto loc_82C93534;
	case 7:
		goto loc_82C93534;
	case 8:
		goto loc_82C93534;
	case 9:
		goto loc_82C93534;
	case 10:
		goto loc_82C93534;
	case 11:
		goto loc_82C93534;
	case 12:
		goto loc_82C93534;
	case 13:
		goto loc_82C93534;
	case 14:
		goto loc_82C93534;
	case 15:
		goto loc_82C93534;
	case 16:
		goto loc_82C93534;
	case 17:
		goto loc_82C93210;
	case 18:
		goto loc_82C93534;
	case 19:
		goto loc_82C93210;
	case 20:
		goto loc_82C93534;
	case 21:
		goto loc_82C93534;
	case 22:
		goto loc_82C93534;
	case 23:
		goto loc_82C93534;
	case 24:
		goto loc_82C931D8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,13560(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13560);
	// lwz r22,13584(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13584);
	// lwz r22,13608(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13608);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,12816(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12816);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,12816(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12816);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,12760(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12760);
loc_82C931D8:
	// clrlwi r4,r7,24
	ctx.r4.u64 = ctx.r7.u32 & 0xFF;
	// lbz r5,1(r10)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r5,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r3,r5,27
	ctx.r3.u64 = ctx.r5.u32 & 0x1F;
	// slw r7,r6,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r5,r4,r11
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r4.u32 + ctx.r11.u32);
	// rotlwi r11,r5,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r5.u32, 3);
	// add r4,r11,r9
	ctx.r4.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r3,r4,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r3,r8
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r8.u32);
	// and r9,r11,r7
	ctx.r9.u64 = ctx.r11.u64 & ctx.r7.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c93534
	if (ctx.cr6.eq) goto loc_82C93534;
loc_82C93210:
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r5,r30
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c93110
	if (ctx.cr6.eq) goto loc_82C93110;
loc_82C9321C:
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c93238
	if (!ctx.cr6.eq) goto loc_82C93238;
	// lbz r11,1(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93244
	goto loc_82C93244;
loc_82C93238:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// lbz r4,1(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93244;
	sub_82C8DAE8(ctx, base);
loc_82C93244:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c9331c
	if (ctx.cr6.gt) goto loc_82C9331C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,12904
	ctx.r12.s64 = ctx.r12.s64 + 12904;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9332C;
	case 1:
		goto loc_82C93344;
	case 2:
		goto loc_82C9335C;
	case 3:
		goto loc_82C9331C;
	case 4:
		goto loc_82C93374;
	case 5:
		goto loc_82C93374;
	case 6:
		goto loc_82C9331C;
	case 7:
		goto loc_82C9331C;
	case 8:
		goto loc_82C9331C;
	case 9:
		goto loc_82C9331C;
	case 10:
		goto loc_82C934A8;
	case 11:
		goto loc_82C9331C;
	case 12:
		goto loc_82C9331C;
	case 13:
		goto loc_82C9331C;
	case 14:
		goto loc_82C9331C;
	case 15:
		goto loc_82C9331C;
	case 16:
		goto loc_82C93374;
	case 17:
		goto loc_82C93304;
	case 18:
		goto loc_82C9331C;
	case 19:
		goto loc_82C93304;
	case 20:
		goto loc_82C93304;
	case 21:
		goto loc_82C93304;
	case 22:
		goto loc_82C93304;
	case 23:
		goto loc_82C9331C;
	case 24:
		goto loc_82C932CC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,13100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13100);
	// lwz r22,13124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13124);
	// lwz r22,13148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13148);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13172(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13172);
	// lwz r22,13172(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13172);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13480);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13172(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13172);
	// lwz r22,13060(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13060(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13060(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13060(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13060(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13060);
	// lwz r22,13084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13084);
	// lwz r22,13004(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13004);
loc_82C932CC:
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// lbz r9,1(r5)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// addi r7,r8,1536
	ctx.r7.s64 = ctx.r8.s64 + 1536;
	// rlwinm r10,r9,27,5,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r4,r9,27
	ctx.r4.u64 = ctx.r9.u32 & 0x1F;
	// slw r3,r6,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r11,r11,r7
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r3
	ctx.r4.u64 = ctx.r7.u64 & ctx.r3.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c9331c
	if (ctx.cr6.eq) goto loc_82C9331C;
loc_82C93304:
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r5,r30
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82c9321c
	if (!ctx.cr6.eq) goto loc_82C9321C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9331C:
	// stw r5,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r5.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9332C:
	// subf r11,r5,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c9331c
	if (!ctx.cr6.lt) goto loc_82C9331C;
loc_82C93338:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C93344:
	// subf r11,r5,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c9331c
	if (!ctx.cr6.lt) goto loc_82C9331C;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9335C:
	// subf r11,r5,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r5.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c9331c
	if (!ctx.cr6.lt) goto loc_82C9331C;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C93374:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c93028
	ctx.lr = 0x82C93384;
	sub_82C93028(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9331c
	if (ctx.cr6.eq) goto loc_82C9331C;
	// addi r10,r5,2
	ctx.r10.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c93110
	if (ctx.cr6.eq) goto loc_82C93110;
	// subf r9,r10,r30
	ctx.r9.s64 = ctx.r30.s64 - ctx.r10.s64;
loc_82C9339C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c933b8
	if (!ctx.cr6.eq) goto loc_82C933B8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c933c0
	goto loc_82C933C0;
loc_82C933B8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C933C0;
	sub_82C8DAE8(ctx, base);
loc_82C933C0:
	// cmplwi cr6,r3,15
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 15, ctx.xer);
	// bgt cr6,0x82c93428
	if (ctx.cr6.gt) goto loc_82C93428;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,13280
	ctx.r12.s64 = ctx.r12.s64 + 13280;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C93534;
	case 1:
		goto loc_82C93534;
	case 2:
		goto loc_82C93428;
	case 3:
		goto loc_82C93428;
	case 4:
		goto loc_82C93428;
	case 5:
		goto loc_82C93420;
	case 6:
		goto loc_82C93444;
	case 7:
		goto loc_82C93458;
	case 8:
		goto loc_82C93534;
	case 9:
		goto loc_82C93428;
	case 10:
		goto loc_82C93428;
	case 11:
		goto loc_82C93428;
	case 12:
		goto loc_82C93428;
	case 13:
		goto loc_82C93428;
	case 14:
		goto loc_82C93428;
	case 15:
		goto loc_82C9346C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13344(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13344);
	// lwz r22,13380(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13380);
	// lwz r22,13400(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13400);
	// lwz r22,13620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13620);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13352(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13352);
	// lwz r22,13420(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13420);
loc_82C93420:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c93338
	if (ctx.cr6.lt) goto loc_82C93338;
loc_82C93428:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C93430:
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82c9339c
	if (!ctx.cr6.eq) goto loc_82C9339C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C93444:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c93338
	if (ctx.cr6.lt) goto loc_82C93338;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c93430
	goto loc_82C93430;
loc_82C93458:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c93338
	if (ctx.cr6.lt) goto loc_82C93338;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c93430
	goto loc_82C93430;
loc_82C9346C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c93110
	if (ctx.cr6.eq) goto loc_82C93110;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c93430
	if (!ctx.cr6.eq) goto loc_82C93430;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// bne cr6,0x82c93430
	if (!ctx.cr6.eq) goto loc_82C93430;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C934A8:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c93028
	ctx.lr = 0x82C934B8;
	sub_82C93028(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9331c
	if (ctx.cr6.eq) goto loc_82C9331C;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// cmplw cr6,r5,r30
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c93110
	if (ctx.cr6.eq) goto loc_82C93110;
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9331c
	if (!ctx.cr6.eq) goto loc_82C9331C;
	// lbz r11,1(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// bne cr6,0x82c9331c
	if (!ctx.cr6.eq) goto loc_82C9331C;
	// addi r11,r5,2
	ctx.r11.s64 = ctx.r5.s64 + 2;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C934F8:
	// subf r11,r10,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c93534
	if (!ctx.cr6.lt) goto loc_82C93534;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C93510:
	// subf r11,r10,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c93534
	if (!ctx.cr6.lt) goto loc_82C93534;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C93528:
	// subf r11,r10,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c93338
	if (ctx.cr6.lt) goto loc_82C93338;
loc_82C93534:
	// stw r10,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
}

__attribute__((alias("__imp__sub_82C93544"))) PPC_WEAK_FUNC(sub_82C93544);
PPC_FUNC_IMPL(__imp__sub_82C93544) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C93548"))) PPC_WEAK_FUNC(sub_82C93548);
PPC_FUNC_IMPL(__imp__sub_82C93548) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c93578
	if (!ctx.cr6.eq) goto loc_82C93578;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93578:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c935ac
	if (ctx.cr6.eq) goto loc_82C935AC;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c935a8
	if (!ctx.cr6.eq) goto loc_82C935A8;
loc_82C93594:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C935A8:
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C935AC:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c935c8
	if (!ctx.cr6.eq) goto loc_82C935C8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c935d0
	goto loc_82C935D0;
loc_82C935C8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C935D0;
	sub_82C8DAE8(ctx, base);
loc_82C935D0:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c93758
	if (ctx.cr6.gt) goto loc_82C93758;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,13808
	ctx.r12.s64 = ctx.r12.s64 + 13808;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C93740;
	case 1:
		goto loc_82C93740;
	case 2:
		goto loc_82C93758;
	case 3:
		goto loc_82C93758;
	case 4:
		goto loc_82C9361C;
	case 5:
		goto loc_82C936F8;
	case 6:
		goto loc_82C93718;
	case 7:
		goto loc_82C9372C;
	case 8:
		goto loc_82C93740;
	case 9:
		goto loc_82C93688;
	case 10:
		goto loc_82C936DC;
	default:
		__builtin_unreachable();
	}
	// lwz r22,14144(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14144);
	// lwz r22,14144(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14144);
	// lwz r22,14168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14168);
	// lwz r22,14168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14168);
	// lwz r22,13852(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13852);
	// lwz r22,14072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14072);
	// lwz r22,14104(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14104);
	// lwz r22,14124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14124);
	// lwz r22,14144(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14144);
	// lwz r22,13960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 13960);
	// lwz r22,14044(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14044);
loc_82C9361C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93594
	if (ctx.cr6.eq) goto loc_82C93594;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9375c
	if (!ctx.cr6.eq) goto loc_82C9375C;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c9375c
	if (!ctx.cr6.eq) goto loc_82C9375C;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93594
	if (ctx.cr6.eq) goto loc_82C93594;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c93680
	if (!ctx.cr6.eq) goto loc_82C93680;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c93680
	if (!ctx.cr6.eq) goto loc_82C93680;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,40
	ctx.r3.s64 = 40;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93680:
	// addi r10,r11,-2
	ctx.r10.s64 = ctx.r11.s64 + -2;
	// b 0x82c9375c
	goto loc_82C9375C;
loc_82C93688:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93594
	if (ctx.cr6.eq) goto loc_82C93594;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c936b0
	if (!ctx.cr6.eq) goto loc_82C936B0;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c936b8
	goto loc_82C936B8;
loc_82C936B0:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C936B8;
	sub_82C8DAE8(ctx, base);
loc_82C936B8:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c936c4
	if (!ctx.cr6.eq) goto loc_82C936C4;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C936C4:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C936DC:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C936F8:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c93758
	if (!ctx.cr6.lt) goto loc_82C93758;
loc_82C93704:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93718:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c93704
	if (ctx.cr6.lt) goto loc_82C93704;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c9375c
	goto loc_82C9375C;
loc_82C9372C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c93704
	if (ctx.cr6.lt) goto loc_82C93704;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c9375c
	goto loc_82C9375C;
loc_82C93740:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93758:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C9375C:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c937f0
	if (ctx.cr6.eq) goto loc_82C937F0;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C93768:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c93784
	if (!ctx.cr6.eq) goto loc_82C93784;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9378c
	goto loc_82C9378C;
loc_82C93784:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C9378C;
	sub_82C8DAE8(ctx, base);
loc_82C9378C:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c937e0
	if (ctx.cr6.gt) goto loc_82C937E0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,14252
	ctx.r12.s64 = ctx.r12.s64 + 14252;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C937F0;
	case 1:
		goto loc_82C937F0;
	case 2:
		goto loc_82C937E0;
	case 3:
		goto loc_82C937E0;
	case 4:
		goto loc_82C937F0;
	case 5:
		goto loc_82C937D8;
	case 6:
		goto loc_82C93808;
	case 7:
		goto loc_82C9381C;
	case 8:
		goto loc_82C937F0;
	case 9:
		goto loc_82C937F0;
	case 10:
		goto loc_82C937F0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,14320(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14320(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14304);
	// lwz r22,14304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14304);
	// lwz r22,14320(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14296(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14296);
	// lwz r22,14344(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14344);
	// lwz r22,14364(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14364);
	// lwz r22,14320(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14320(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
	// lwz r22,14320(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14320);
loc_82C937D8:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c937f0
	if (ctx.cr6.lt) goto loc_82C937F0;
loc_82C937E0:
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C937E8:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c93768
	if (!ctx.cr6.eq) goto loc_82C93768;
loc_82C937F0:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93808:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c937f0
	if (ctx.cr6.lt) goto loc_82C937F0;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c937e8
	goto loc_82C937E8;
loc_82C9381C:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c937f0
	if (ctx.cr6.lt) goto loc_82C937F0;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c937e8
	goto loc_82C937E8;
}

__attribute__((alias("__imp__sub_82C93830"))) PPC_WEAK_FUNC(sub_82C93830);
PPC_FUNC_IMPL(__imp__sub_82C93830) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9385c
	if (!ctx.cr6.eq) goto loc_82C9385C;
loc_82C93854:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C9385C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c93878
	if (!ctx.cr6.eq) goto loc_82C93878;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93884
	goto loc_82C93884;
loc_82C93878:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93884;
	sub_82C8DAE8(ctx, base);
loc_82C93884:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c93b40
	if (ctx.cr6.gt) goto loc_82C93B40;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,14516
	ctx.r12.s64 = ctx.r12.s64 + 14516;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C93A58;
	case 1:
		goto loc_82C93A6C;
	case 2:
		goto loc_82C93B2C;
	case 3:
		goto loc_82C93B40;
	case 4:
		goto loc_82C93B40;
	case 5:
		goto loc_82C93B40;
	case 6:
		goto loc_82C93B40;
	case 7:
		goto loc_82C93B40;
	case 8:
		goto loc_82C93B40;
	case 9:
		goto loc_82C93B40;
	case 10:
		goto loc_82C93B40;
	case 11:
		goto loc_82C93B40;
	case 12:
		goto loc_82C93B40;
	case 13:
		goto loc_82C93B40;
	case 14:
		goto loc_82C93B40;
	case 15:
		goto loc_82C93B40;
	case 16:
		goto loc_82C93B40;
	case 17:
		goto loc_82C93950;
	case 18:
		goto loc_82C93B40;
	case 19:
		goto loc_82C93950;
	case 20:
		goto loc_82C93B40;
	case 21:
		goto loc_82C93B40;
	case 22:
		goto loc_82C93B40;
	case 23:
		goto loc_82C93B40;
	case 24:
		goto loc_82C93918;
	default:
		__builtin_unreachable();
	}
	// lwz r22,14936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14936);
	// lwz r22,14956(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14956);
	// lwz r22,15148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15148);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14672);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14672);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14616(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14616);
loc_82C93918:
	// clrlwi r3,r7,24
	ctx.r3.u64 = ctx.r7.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r3,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r11.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c93b40
	if (ctx.cr6.eq) goto loc_82C93B40;
loc_82C93950:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93854
	if (ctx.cr6.eq) goto loc_82C93854;
loc_82C9395C:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c93978
	if (!ctx.cr6.eq) goto loc_82C93978;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93984
	goto loc_82C93984;
loc_82C93978:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93984;
	sub_82C8DAE8(ctx, base);
loc_82C93984:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c93b40
	if (ctx.cr6.gt) goto loc_82C93B40;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,14760
	ctx.r12.s64 = ctx.r12.s64 + 14760;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C93A58;
	case 1:
		goto loc_82C93A6C;
	case 2:
		goto loc_82C93B2C;
	case 3:
		goto loc_82C93B40;
	case 4:
		goto loc_82C93A80;
	case 5:
		goto loc_82C93A80;
	case 6:
		goto loc_82C93B1C;
	case 7:
		goto loc_82C93B40;
	case 8:
		goto loc_82C93B40;
	case 9:
		goto loc_82C93B40;
	case 10:
		goto loc_82C93B40;
	case 11:
		goto loc_82C93B40;
	case 12:
		goto loc_82C93B40;
	case 13:
		goto loc_82C93B40;
	case 14:
		goto loc_82C93B40;
	case 15:
		goto loc_82C93B40;
	case 16:
		goto loc_82C93A80;
	case 17:
		goto loc_82C93A44;
	case 18:
		goto loc_82C93A44;
	case 19:
		goto loc_82C93A44;
	case 20:
		goto loc_82C93A44;
	case 21:
		goto loc_82C93A44;
	case 22:
		goto loc_82C93A44;
	case 23:
		goto loc_82C93B40;
	case 24:
		goto loc_82C93A0C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,14936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14936);
	// lwz r22,14956(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14956);
	// lwz r22,15148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15148);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14976);
	// lwz r22,14976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14976);
	// lwz r22,15132(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15132);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14976);
	// lwz r22,14916(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,14916(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14916);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,14860(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 14860);
loc_82C93A0C:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r8,1536
	ctx.r4.s64 = ctx.r8.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r31,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c93b40
	if (ctx.cr6.eq) goto loc_82C93B40;
loc_82C93A44:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9395c
	if (!ctx.cr6.eq) goto loc_82C9395C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93A58:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c93b40
	if (!ctx.cr6.lt) goto loc_82C93B40;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93A6C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c93b40
	if (!ctx.cr6.lt) goto loc_82C93B40;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93A80:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93854
	if (ctx.cr6.eq) goto loc_82C93854;
loc_82C93A8C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c93aa8
	if (!ctx.cr6.eq) goto loc_82C93AA8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93ab0
	goto loc_82C93AB0;
loc_82C93AA8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93AB0;
	sub_82C8DAE8(ctx, base);
loc_82C93AB0:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,12
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 12, ctx.xer);
	// bgt cr6,0x82c93b40
	if (ctx.cr6.gt) goto loc_82C93B40;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,15060
	ctx.r12.s64 = ctx.r12.s64 + 15060;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C93B08;
	case 1:
		goto loc_82C93B08;
	case 2:
		goto loc_82C93B1C;
	case 3:
		goto loc_82C93B40;
	case 4:
		goto loc_82C93B40;
	case 5:
		goto loc_82C93B40;
	case 6:
		goto loc_82C93B40;
	case 7:
		goto loc_82C93B40;
	case 8:
		goto loc_82C93B40;
	case 9:
		goto loc_82C93B40;
	case 10:
		goto loc_82C93B40;
	case 11:
		goto loc_82C93B40;
	case 12:
		goto loc_82C93B08;
	default:
		__builtin_unreachable();
	}
	// lwz r22,15112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15112);
	// lwz r22,15112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15112);
	// lwz r22,15132(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15132);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15168(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15168);
	// lwz r22,15112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15112);
loc_82C93B08:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c93a8c
	if (!ctx.cr6.eq) goto loc_82C93A8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93B1C:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,5
	ctx.r3.s64 = 5;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93B2C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c93b40
	if (!ctx.cr6.lt) goto loc_82C93B40;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93b48
	goto loc_82C93B48;
loc_82C93B40:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C93B48:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C93B60"))) PPC_WEAK_FUNC(sub_82C93B60);
PPC_FUNC_IMPL(__imp__sub_82C93B60) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93c04
	if (ctx.cr6.eq) goto loc_82C93C04;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c93b98
	if (!ctx.cr6.eq) goto loc_82C93B98;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93ba0
	goto loc_82C93BA0;
loc_82C93B98:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93BA0;
	sub_82C8DAE8(ctx, base);
loc_82C93BA0:
	// cmpwi cr6,r3,24
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 24, ctx.xer);
	// blt cr6,0x82c93c34
	if (ctx.cr6.lt) goto loc_82C93C34;
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// bgt cr6,0x82c93c34
	if (ctx.cr6.gt) goto loc_82C93C34;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93c04
	if (ctx.cr6.eq) goto loc_82C93C04;
loc_82C93BBC:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c93bd8
	if (!ctx.cr6.eq) goto loc_82C93BD8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93be0
	goto loc_82C93BE0;
loc_82C93BD8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93BE0;
	sub_82C8DAE8(ctx, base);
loc_82C93BE0:
	// cmpwi cr6,r3,18
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 18, ctx.xer);
	// beq cr6,0x82c93c18
	if (ctx.cr6.eq) goto loc_82C93C18;
	// cmpwi cr6,r3,23
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 23, ctx.xer);
	// ble cr6,0x82c93c34
	if (!ctx.cr6.gt) goto loc_82C93C34;
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// bgt cr6,0x82c93c34
	if (ctx.cr6.gt) goto loc_82C93C34;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c93bbc
	if (!ctx.cr6.eq) goto loc_82C93BBC;
loc_82C93C04:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93C18:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,10
	ctx.r3.s64 = 10;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93C34:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C93C4C"))) PPC_WEAK_FUNC(sub_82C93C4C);
PPC_FUNC_IMPL(__imp__sub_82C93C4C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C93C50"))) PPC_WEAK_FUNC(sub_82C93C50);
PPC_FUNC_IMPL(__imp__sub_82C93C50) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93d30
	if (ctx.cr6.eq) goto loc_82C93D30;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// extsb r11,r3
	ctx.r11.s64 = ctx.r3.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c93cbc
	if (!ctx.cr6.eq) goto loc_82C93CBC;
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r8,120
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 120, ctx.xer);
	// bne cr6,0x82c93ca4
	if (!ctx.cr6.eq) goto loc_82C93CA4;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c93b60
	ctx.lr = 0x82C93C94;
	sub_82C93B60(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93CA4:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c93cbc
	if (!ctx.cr6.eq) goto loc_82C93CBC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93cc4
	goto loc_82C93CC4;
loc_82C93CBC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93CC4;
	sub_82C8DAE8(ctx, base);
loc_82C93CC4:
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// beq cr6,0x82c93ce4
	if (ctx.cr6.eq) goto loc_82C93CE4;
loc_82C93CCC:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93CE4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93d30
	if (ctx.cr6.eq) goto loc_82C93D30;
loc_82C93CF0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c93d0c
	if (!ctx.cr6.eq) goto loc_82C93D0C;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93d14
	goto loc_82C93D14;
loc_82C93D0C:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93D14;
	sub_82C8DAE8(ctx, base);
loc_82C93D14:
	// cmpwi cr6,r3,18
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 18, ctx.xer);
	// beq cr6,0x82c93d44
	if (ctx.cr6.eq) goto loc_82C93D44;
	// cmpwi cr6,r3,25
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 25, ctx.xer);
	// bne cr6,0x82c93ccc
	if (!ctx.cr6.eq) goto loc_82C93CCC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c93cf0
	if (!ctx.cr6.eq) goto loc_82C93CF0;
loc_82C93D30:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C93D44:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,10
	ctx.r3.s64 = 10;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C93D60"))) PPC_WEAK_FUNC(sub_82C93D60);
PPC_FUNC_IMPL(__imp__sub_82C93D60) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c93d8c
	if (!ctx.cr6.eq) goto loc_82C93D8C;
loc_82C93D84:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93D8C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c93da8
	if (!ctx.cr6.eq) goto loc_82C93DA8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93db4
	goto loc_82C93DB4;
loc_82C93DA8:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93DB4;
	sub_82C8DAE8(ctx, base);
loc_82C93DB4:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c93fe4
	if (ctx.cr6.gt) goto loc_82C93FE4;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,15844
	ctx.r12.s64 = ctx.r12.s64 + 15844;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C93F88;
	case 1:
		goto loc_82C93F9C;
	case 2:
		goto loc_82C93FB0;
	case 3:
		goto loc_82C93FE4;
	case 4:
		goto loc_82C93FE4;
	case 5:
		goto loc_82C93FE4;
	case 6:
		goto loc_82C93FE4;
	case 7:
		goto loc_82C93FE4;
	case 8:
		goto loc_82C93FE4;
	case 9:
		goto loc_82C93FE4;
	case 10:
		goto loc_82C93FE4;
	case 11:
		goto loc_82C93FE4;
	case 12:
		goto loc_82C93FE4;
	case 13:
		goto loc_82C93FE4;
	case 14:
		goto loc_82C93FD4;
	case 15:
		goto loc_82C93FE4;
	case 16:
		goto loc_82C93FE4;
	case 17:
		goto loc_82C93E80;
	case 18:
		goto loc_82C93FE4;
	case 19:
		goto loc_82C93E80;
	case 20:
		goto loc_82C93FE4;
	case 21:
		goto loc_82C93FE4;
	case 22:
		goto loc_82C93FE4;
	case 23:
		goto loc_82C93FE4;
	case 24:
		goto loc_82C93E48;
	default:
		__builtin_unreachable();
	}
	// lwz r22,16264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16264);
	// lwz r22,16284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16284);
	// lwz r22,16304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16304);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16340(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16340);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16000);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16000);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,15944(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15944);
loc_82C93E48:
	// clrlwi r3,r7,24
	ctx.r3.u64 = ctx.r7.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r3,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r11.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c93fe4
	if (ctx.cr6.eq) goto loc_82C93FE4;
loc_82C93E80:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c93d84
	if (ctx.cr6.eq) goto loc_82C93D84;
loc_82C93E8C:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c93ea8
	if (!ctx.cr6.eq) goto loc_82C93EA8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c93eb4
	goto loc_82C93EB4;
loc_82C93EA8:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C93EB4;
	sub_82C8DAE8(ctx, base);
loc_82C93EB4:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c93fe4
	if (ctx.cr6.gt) goto loc_82C93FE4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,16088
	ctx.r12.s64 = ctx.r12.s64 + 16088;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C93F88;
	case 1:
		goto loc_82C93F9C;
	case 2:
		goto loc_82C93FB0;
	case 3:
		goto loc_82C93FE4;
	case 4:
		goto loc_82C93FE4;
	case 5:
		goto loc_82C93FE4;
	case 6:
		goto loc_82C93FE4;
	case 7:
		goto loc_82C93FE4;
	case 8:
		goto loc_82C93FE4;
	case 9:
		goto loc_82C93FE4;
	case 10:
		goto loc_82C93FE4;
	case 11:
		goto loc_82C93FE4;
	case 12:
		goto loc_82C93FE4;
	case 13:
		goto loc_82C93FC4;
	case 14:
		goto loc_82C93FE4;
	case 15:
		goto loc_82C93FE4;
	case 16:
		goto loc_82C93FE4;
	case 17:
		goto loc_82C93F74;
	case 18:
		goto loc_82C93FE4;
	case 19:
		goto loc_82C93F74;
	case 20:
		goto loc_82C93F74;
	case 21:
		goto loc_82C93F74;
	case 22:
		goto loc_82C93F74;
	case 23:
		goto loc_82C93FE4;
	case 24:
		goto loc_82C93F3C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,16264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16264);
	// lwz r22,16284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16284);
	// lwz r22,16304(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16304);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16324(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16324);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16244(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16244(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16244(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16244(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16244(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16244);
	// lwz r22,16356(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16356);
	// lwz r22,16188(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16188);
loc_82C93F3C:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r8,1536
	ctx.r4.s64 = ctx.r8.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r31,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c93fe4
	if (ctx.cr6.eq) goto loc_82C93FE4;
loc_82C93F74:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c93e8c
	if (!ctx.cr6.eq) goto loc_82C93E8C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93F88:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c93fe4
	if (!ctx.cr6.lt) goto loc_82C93FE4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93F9C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c93fe4
	if (!ctx.cr6.lt) goto loc_82C93FE4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93FB0:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c93fe4
	if (!ctx.cr6.lt) goto loc_82C93FE4;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93FC4:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,9
	ctx.r3.s64 = 9;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93FD4:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c93c50
	ctx.lr = 0x82C93FE0;
	sub_82C93C50(ctx, base);
	// b 0x82c93fec
	goto loc_82C93FEC;
loc_82C93FE4:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C93FEC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C94004"))) PPC_WEAK_FUNC(sub_82C94004);
PPC_FUNC_IMPL(__imp__sub_82C94004) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C94008"))) PPC_WEAK_FUNC(sub_82C94008);
PPC_FUNC_IMPL(__imp__sub_82C94008) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C94010;
	sub_82CA2BE0(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r27,1
	ctx.r27.s64 = 1;
	// addi r29,r11,-4144
	ctx.r29.s64 = ctx.r11.s64 + -4144;
loc_82C94038:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c94054
	if (!ctx.cr6.eq) goto loc_82C94054;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94060
	goto loc_82C94060;
loc_82C94054:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94060;
	sub_82C8DAE8(ctx, base);
loc_82C94060:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c94268
	if (ctx.cr6.gt) goto loc_82C94268;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,16516
	ctx.r12.s64 = ctx.r12.s64 + 16516;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94550;
	case 1:
		goto loc_82C94568;
	case 2:
		goto loc_82C94580;
	case 3:
		goto loc_82C94268;
	case 4:
		goto loc_82C94218;
	case 5:
		goto loc_82C94218;
	case 6:
		goto loc_82C94268;
	case 7:
		goto loc_82C94268;
	case 8:
		goto loc_82C94268;
	case 9:
		goto loc_82C94278;
	case 10:
		goto loc_82C94268;
	case 11:
		goto loc_82C94268;
	case 12:
		goto loc_82C94268;
	case 13:
		goto loc_82C94268;
	case 14:
		goto loc_82C94268;
	case 15:
		goto loc_82C94268;
	case 16:
		goto loc_82C94218;
	case 17:
		goto loc_82C94538;
	case 18:
		goto loc_82C9411C;
	case 19:
		goto loc_82C94538;
	case 20:
		goto loc_82C94538;
	case 21:
		goto loc_82C94538;
	case 22:
		goto loc_82C94538;
	case 23:
		goto loc_82C94268;
	case 24:
		goto loc_82C940E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17744);
	// lwz r22,17768(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17768);
	// lwz r22,17792(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17792);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,16920(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16920);
	// lwz r22,16920(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16920);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17016(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17016);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,16920(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16920);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,16668(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16668);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,16616(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16616);
loc_82C940E8:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r7,r29,1536
	ctx.r7.s64 = ctx.r29.s64 + 1536;
	// rlwinm r9,r8,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r6,r8,27
	ctx.r6.u64 = ctx.r8.u32 & 0x1F;
	// slw r4,r27,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r27.u32 << (ctx.r6.u8 & 0x3F));
	// lbzx r3,r11,r7
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r29
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r29.u32);
	// and r7,r8,r4
	ctx.r7.u64 = ctx.r8.u64 & ctx.r4.u64;
	// b 0x82c94530
	goto loc_82C94530;
loc_82C9411C:
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// bne cr6,0x82c94268
	if (!ctx.cr6.eq) goto loc_82C94268;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// mr r28,r27
	ctx.r28.u64 = ctx.r27.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c94150
	if (!ctx.cr6.eq) goto loc_82C94150;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9415c
	goto loc_82C9415C;
loc_82C94150:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C9415C;
	sub_82C8DAE8(ctx, base);
loc_82C9415C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c94268
	if (ctx.cr6.gt) goto loc_82C94268;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,16768
	ctx.r12.s64 = ctx.r12.s64 + 16768;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94550;
	case 1:
		goto loc_82C94568;
	case 2:
		goto loc_82C94580;
	case 3:
		goto loc_82C94268;
	case 4:
		goto loc_82C94268;
	case 5:
		goto loc_82C94268;
	case 6:
		goto loc_82C94268;
	case 7:
		goto loc_82C94268;
	case 8:
		goto loc_82C94268;
	case 9:
		goto loc_82C94268;
	case 10:
		goto loc_82C94268;
	case 11:
		goto loc_82C94268;
	case 12:
		goto loc_82C94268;
	case 13:
		goto loc_82C94268;
	case 14:
		goto loc_82C94268;
	case 15:
		goto loc_82C94268;
	case 16:
		goto loc_82C94268;
	case 17:
		goto loc_82C94538;
	case 18:
		goto loc_82C94268;
	case 19:
		goto loc_82C94538;
	case 20:
		goto loc_82C94268;
	case 21:
		goto loc_82C94268;
	case 22:
		goto loc_82C94268;
	case 23:
		goto loc_82C94268;
	case 24:
		goto loc_82C941E4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17744);
	// lwz r22,17768(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17768);
	// lwz r22,17792(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17792);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,16868(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 16868);
loc_82C941E4:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r7,r29,1280
	ctx.r7.s64 = ctx.r29.s64 + 1280;
	// rlwinm r9,r8,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r6,r8,27
	ctx.r6.u64 = ctx.r8.u32 & 0x1F;
	// slw r4,r27,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r27.u32 << (ctx.r6.u8 & 0x3F));
	// lbzx r3,r11,r7
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r29
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r29.u32);
	// and r7,r8,r4
	ctx.r7.u64 = ctx.r8.u64 & ctx.r4.u64;
	// b 0x82c94530
	goto loc_82C94530;
loc_82C94218:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94240
	if (!ctx.cr6.eq) goto loc_82C94240;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94248
	goto loc_82C94248;
loc_82C94240:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94248;
	sub_82C8DAE8(ctx, base);
loc_82C94248:
	// cmpwi cr6,r3,14
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 14, ctx.xer);
	// beq cr6,0x82c94278
	if (ctx.cr6.eq) goto loc_82C94278;
	// cmpwi cr6,r3,9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 9, ctx.xer);
	// blt cr6,0x82c94268
	if (ctx.cr6.lt) goto loc_82C94268;
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// ble cr6,0x82c94218
	if (!ctx.cr6.gt) goto loc_82C94218;
	// cmpwi cr6,r3,21
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 21, ctx.xer);
	// beq cr6,0x82c94218
	if (ctx.cr6.eq) goto loc_82C94218;
loc_82C94268:
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C94278:
	// li r28,0
	ctx.r28.s64 = 0;
loc_82C9427C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c942a4
	if (!ctx.cr6.eq) goto loc_82C942A4;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r31,76(r11)
	ctx.r31.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c942b0
	goto loc_82C942B0;
loc_82C942A4:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C942AC;
	sub_82C8DAE8(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
loc_82C942B0:
	// cmpwi cr6,r31,12
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 12, ctx.xer);
	// beq cr6,0x82c942e8
	if (ctx.cr6.eq) goto loc_82C942E8;
	// cmpwi cr6,r31,13
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 13, ctx.xer);
	// beq cr6,0x82c942e8
	if (ctx.cr6.eq) goto loc_82C942E8;
	// cmpwi cr6,r31,9
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 9, ctx.xer);
	// blt cr6,0x82c94268
	if (ctx.cr6.lt) goto loc_82C94268;
	// cmpwi cr6,r31,10
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 10, ctx.xer);
	// ble cr6,0x82c9427c
	if (!ctx.cr6.gt) goto loc_82C9427C;
	// cmpwi cr6,r31,21
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 21, ctx.xer);
	// beq cr6,0x82c9427c
	if (ctx.cr6.eq) goto loc_82C9427C;
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C942E8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C942EC:
	// stw r10,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r10.u32);
loc_82C942F0:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94314
	if (!ctx.cr6.eq) goto loc_82C94314;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9431c
	goto loc_82C9431C;
loc_82C94314:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C9431C;
	sub_82C8DAE8(ctx, base);
loc_82C9431C:
	// cmpw cr6,r3,r31
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r31.s32, ctx.xer);
	// beq cr6,0x82c943c0
	if (ctx.cr6.eq) goto loc_82C943C0;
	// cmplwi cr6,r3,8
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 8, ctx.xer);
	// bgt cr6,0x82c942e8
	if (ctx.cr6.gt) goto loc_82C942E8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,17220
	ctx.r12.s64 = ctx.r12.s64 + 17220;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C94268;
	case 1:
		goto loc_82C94268;
	case 2:
		goto loc_82C94268;
	case 3:
		goto loc_82C943A0;
	case 4:
		goto loc_82C942E8;
	case 5:
		goto loc_82C94368;
	case 6:
		goto loc_82C94378;
	case 7:
		goto loc_82C9438C;
	case 8:
		goto loc_82C94268;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17312);
	// lwz r22,17128(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17128);
	// lwz r22,17256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17256);
	// lwz r22,17272(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17272);
	// lwz r22,17292(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17292);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
loc_82C94368:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// blt cr6,0x82c9455c
	if (ctx.cr6.lt) goto loc_82C9455C;
	// b 0x82c942e8
	goto loc_82C942E8;
loc_82C94378:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c9455c
	if (ctx.cr6.lt) goto loc_82C9455C;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c942ec
	goto loc_82C942EC;
loc_82C9438C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c9455c
	if (ctx.cr6.lt) goto loc_82C9455C;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c942ec
	goto loc_82C942EC;
loc_82C943A0:
	// addi r6,r1,172
	ctx.r6.s64 = ctx.r1.s64 + 172;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c93d60
	ctx.lr = 0x82C943B0;
	sub_82C93D60(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// ble cr6,0x82c945f4
	if (!ctx.cr6.gt) goto loc_82C945F4;
	// lwz r10,172(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// b 0x82c942f0
	goto loc_82C942F0;
loc_82C943C0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c943e8
	if (!ctx.cr6.eq) goto loc_82C943E8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c943f0
	goto loc_82C943F0;
loc_82C943E8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C943F0;
	sub_82C8DAE8(ctx, base);
loc_82C943F0:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,12
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 12, ctx.xer);
	// bgt cr6,0x82c94268
	if (ctx.cr6.gt) goto loc_82C94268;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,17428
	ctx.r12.s64 = ctx.r12.s64 + 17428;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94448;
	case 1:
		goto loc_82C94448;
	case 2:
		goto loc_82C945E0;
	case 3:
		goto loc_82C94268;
	case 4:
		goto loc_82C94268;
	case 5:
		goto loc_82C94268;
	case 6:
		goto loc_82C94268;
	case 7:
		goto loc_82C94268;
	case 8:
		goto loc_82C94598;
	case 9:
		goto loc_82C94268;
	case 10:
		goto loc_82C94268;
	case 11:
		goto loc_82C94268;
	case 12:
		goto loc_82C94448;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17888(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17888);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17816(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17816);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
loc_82C94448:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94470
	if (!ctx.cr6.eq) goto loc_82C94470;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94478
	goto loc_82C94478;
loc_82C94470:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94478;
	sub_82C8DAE8(ctx, base);
loc_82C94478:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c94268
	if (ctx.cr6.gt) goto loc_82C94268;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,17564
	ctx.r12.s64 = ctx.r12.s64 + 17564;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94550;
	case 1:
		goto loc_82C94568;
	case 2:
		goto loc_82C94580;
	case 3:
		goto loc_82C94268;
	case 4:
		goto loc_82C94448;
	case 5:
		goto loc_82C94448;
	case 6:
		goto loc_82C945E0;
	case 7:
		goto loc_82C94268;
	case 8:
		goto loc_82C94268;
	case 9:
		goto loc_82C94268;
	case 10:
		goto loc_82C94268;
	case 11:
		goto loc_82C94268;
	case 12:
		goto loc_82C94598;
	case 13:
		goto loc_82C94268;
	case 14:
		goto loc_82C94268;
	case 15:
		goto loc_82C94268;
	case 16:
		goto loc_82C94448;
	case 17:
		goto loc_82C94538;
	case 18:
		goto loc_82C94268;
	case 19:
		goto loc_82C94538;
	case 20:
		goto loc_82C94268;
	case 21:
		goto loc_82C94268;
	case 22:
		goto loc_82C94268;
	case 23:
		goto loc_82C94268;
	case 24:
		goto loc_82C94500;
	default:
		__builtin_unreachable();
	}
	// lwz r22,17744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17744);
	// lwz r22,17768(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17768);
	// lwz r22,17792(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17792);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17888(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17888);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17816(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17816);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17480(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17480);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17720(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17720);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17000(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17000);
	// lwz r22,17664(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 17664);
loc_82C94500:
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r8,r29,1280
	ctx.r8.s64 = ctx.r29.s64 + 1280;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r6,r7,27
	ctx.r6.u64 = ctx.r7.u32 & 0x1F;
	// lbzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// slw r3,r27,r6
	ctx.r3.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r27.u32 << (ctx.r6.u8 & 0x3F));
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r29
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r29.u32);
	// and r7,r8,r3
	ctx.r7.u64 = ctx.r8.u64 & ctx.r3.u64;
loc_82C94530:
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c94268
	if (ctx.cr6.eq) goto loc_82C94268;
loc_82C94538:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94038
	if (!ctx.cr6.eq) goto loc_82C94038;
loc_82C94544:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82C94548:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C94550:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c94268
	if (!ctx.cr6.lt) goto loc_82C94268;
loc_82C9455C:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C94568:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c94268
	if (!ctx.cr6.lt) goto loc_82C94268;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C94580:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c94268
	if (!ctx.cr6.lt) goto loc_82C94268;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C94598:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94544
	if (ctx.cr6.eq) goto loc_82C94544;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c945d0
	if (!ctx.cr6.eq) goto loc_82C945D0;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c945d0
	if (!ctx.cr6.eq) goto loc_82C945D0;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,3
	ctx.r3.s64 = 3;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C945D0:
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C945E0:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C945F4:
	// bne cr6,0x82c94548
	if (!ctx.cr6.eq) goto loc_82C94548;
	// lwz r11,172(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
}

__attribute__((alias("__imp__sub_82C94608"))) PPC_WEAK_FUNC(sub_82C94608);
PPC_FUNC_IMPL(__imp__sub_82C94608) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94634
	if (!ctx.cr6.eq) goto loc_82C94634;
loc_82C9462C:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94634:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c94650
	if (!ctx.cr6.eq) goto loc_82C94650;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9465c
	goto loc_82C9465C;
loc_82C94650:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C9465C;
	sub_82C8DAE8(ctx, base);
loc_82C9465C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c94b74
	if (ctx.cr6.gt) goto loc_82C94B74;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r7,r9,-4144
	ctx.r7.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,18060
	ctx.r12.s64 = ctx.r12.s64 + 18060;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94904;
	case 1:
		goto loc_82C94918;
	case 2:
		goto loc_82C9492C;
	case 3:
		goto loc_82C94B74;
	case 4:
		goto loc_82C94B74;
	case 5:
		goto loc_82C94B74;
	case 6:
		goto loc_82C94B74;
	case 7:
		goto loc_82C94B74;
	case 8:
		goto loc_82C94B74;
	case 9:
		goto loc_82C94B74;
	case 10:
		goto loc_82C94B54;
	case 11:
		goto loc_82C94AA0;
	case 12:
		goto loc_82C94B64;
	case 13:
		goto loc_82C94B74;
	case 14:
		goto loc_82C94B74;
	case 15:
		goto loc_82C94B74;
	case 16:
		goto loc_82C94B74;
	case 17:
		goto loc_82C94728;
	case 18:
		goto loc_82C94B74;
	case 19:
		goto loc_82C94728;
	case 20:
		goto loc_82C94B74;
	case 21:
		goto loc_82C94B74;
	case 22:
		goto loc_82C94B74;
	case 23:
		goto loc_82C94B74;
	case 24:
		goto loc_82C946F0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,18692(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18692);
	// lwz r22,18712(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18712);
	// lwz r22,18732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18732);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19284);
	// lwz r22,19104(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19104);
	// lwz r22,19300(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19300);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18216(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18216);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18216(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18216);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18160(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18160);
loc_82C946F0:
	// clrlwi r3,r8,24
	ctx.r3.u64 = ctx.r8.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r9,r7,1280
	ctx.r9.s64 = ctx.r7.s64 + 1280;
	// rlwinm r11,r4,27,5,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r8,r4,27
	ctx.r8.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r8
	ctx.r4.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r8.u8 & 0x3F));
	// lbzx r3,r3,r9
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r9.u32);
	// rotlwi r9,r3,3
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r7
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// and r4,r8,r4
	ctx.r4.u64 = ctx.r8.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c94b74
	if (ctx.cr6.eq) goto loc_82C94B74;
loc_82C94728:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9462c
	if (ctx.cr6.eq) goto loc_82C9462C;
loc_82C94738:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c94754
	if (!ctx.cr6.eq) goto loc_82C94754;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94760
	goto loc_82C94760;
loc_82C94754:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94760;
	sub_82C8DAE8(ctx, base);
loc_82C94760:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c94b74
	if (ctx.cr6.gt) goto loc_82C94B74;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,18308
	ctx.r12.s64 = ctx.r12.s64 + 18308;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94904;
	case 1:
		goto loc_82C94918;
	case 2:
		goto loc_82C9492C;
	case 3:
		goto loc_82C94B74;
	case 4:
		goto loc_82C94940;
	case 5:
		goto loc_82C94940;
	case 6:
		goto loc_82C94A54;
	case 7:
		goto loc_82C94B74;
	case 8:
		goto loc_82C94B74;
	case 9:
		goto loc_82C94B74;
	case 10:
		goto loc_82C94B74;
	case 11:
		goto loc_82C94B74;
	case 12:
		goto loc_82C94A64;
	case 13:
		goto loc_82C94B74;
	case 14:
		goto loc_82C94B74;
	case 15:
		goto loc_82C94B74;
	case 16:
		goto loc_82C94940;
	case 17:
		goto loc_82C948F0;
	case 18:
		goto loc_82C947F0;
	case 19:
		goto loc_82C948F0;
	case 20:
		goto loc_82C948F0;
	case 21:
		goto loc_82C948F0;
	case 22:
		goto loc_82C948F0;
	case 23:
		goto loc_82C94B74;
	case 24:
		goto loc_82C947E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,18692(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18692);
	// lwz r22,18712(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18712);
	// lwz r22,18732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18732);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18752(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18752);
	// lwz r22,18752(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18752);
	// lwz r22,19028(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19028);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19044(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19044);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18752(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18752);
	// lwz r22,18672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,18416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18416);
	// lwz r22,18672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,18672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,18672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,18672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18408(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18408);
loc_82C947E8:
	// addi r3,r7,1536
	ctx.r3.s64 = ctx.r7.s64 + 1536;
	// b 0x82c948bc
	goto loc_82C948BC;
loc_82C947F0:
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne cr6,0x82c94b74
	if (!ctx.cr6.eq) goto loc_82C94B74;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// mr r8,r31
	ctx.r8.u64 = ctx.r31.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9462c
	if (ctx.cr6.eq) goto loc_82C9462C;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c94824
	if (!ctx.cr6.eq) goto loc_82C94824;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94830
	goto loc_82C94830;
loc_82C94824:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94830;
	sub_82C8DAE8(ctx, base);
loc_82C94830:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c94b74
	if (ctx.cr6.gt) goto loc_82C94B74;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,18516
	ctx.r12.s64 = ctx.r12.s64 + 18516;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94904;
	case 1:
		goto loc_82C94918;
	case 2:
		goto loc_82C9492C;
	case 3:
		goto loc_82C94B74;
	case 4:
		goto loc_82C94B74;
	case 5:
		goto loc_82C94B74;
	case 6:
		goto loc_82C94B74;
	case 7:
		goto loc_82C94B74;
	case 8:
		goto loc_82C94B74;
	case 9:
		goto loc_82C94B74;
	case 10:
		goto loc_82C94B74;
	case 11:
		goto loc_82C94B74;
	case 12:
		goto loc_82C94B74;
	case 13:
		goto loc_82C94B74;
	case 14:
		goto loc_82C94B74;
	case 15:
		goto loc_82C94B74;
	case 16:
		goto loc_82C94B74;
	case 17:
		goto loc_82C948F0;
	case 18:
		goto loc_82C94B74;
	case 19:
		goto loc_82C948F0;
	case 20:
		goto loc_82C94B74;
	case 21:
		goto loc_82C94B74;
	case 22:
		goto loc_82C94B74;
	case 23:
		goto loc_82C94B74;
	case 24:
		goto loc_82C948B8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,18692(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18692);
	// lwz r22,18712(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18712);
	// lwz r22,18732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18732);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18672(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18672);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18616(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18616);
loc_82C948B8:
	// addi r3,r7,1280
	ctx.r3.s64 = ctx.r7.s64 + 1280;
loc_82C948BC:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r4,r4,27
	ctx.r4.u64 = ctx.r4.u32 & 0x1F;
	// lbzx r3,r11,r3
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r3.u32);
	// slw r4,r31,r4
	ctx.r4.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r4.u8 & 0x3F));
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r9,r7
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// and r11,r3,r4
	ctx.r11.u64 = ctx.r3.u64 & ctx.r4.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c94b74
	if (ctx.cr6.eq) goto loc_82C94B74;
loc_82C948F0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94738
	if (!ctx.cr6.eq) goto loc_82C94738;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94904:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c94b74
	if (!ctx.cr6.lt) goto loc_82C94B74;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94918:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c94b74
	if (!ctx.cr6.lt) goto loc_82C94B74;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C9492C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c94b74
	if (!ctx.cr6.lt) goto loc_82C94B74;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94940:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9462c
	if (ctx.cr6.eq) goto loc_82C9462C;
loc_82C9494C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94968
	if (!ctx.cr6.eq) goto loc_82C94968;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94970
	goto loc_82C94970;
loc_82C94968:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94970;
	sub_82C8DAE8(ctx, base);
loc_82C94970:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c94b74
	if (ctx.cr6.gt) goto loc_82C94B74;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,18836
	ctx.r12.s64 = ctx.r12.s64 + 18836;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C94904;
	case 1:
		goto loc_82C94918;
	case 2:
		goto loc_82C9492C;
	case 3:
		goto loc_82C94B74;
	case 4:
		goto loc_82C949F8;
	case 5:
		goto loc_82C949F8;
	case 6:
		goto loc_82C94A54;
	case 7:
		goto loc_82C94B74;
	case 8:
		goto loc_82C94B74;
	case 9:
		goto loc_82C94B74;
	case 10:
		goto loc_82C94B74;
	case 11:
		goto loc_82C94B74;
	case 12:
		goto loc_82C94A64;
	case 13:
		goto loc_82C94B74;
	case 14:
		goto loc_82C94B74;
	case 15:
		goto loc_82C94B74;
	case 16:
		goto loc_82C949F8;
	case 17:
		goto loc_82C94A44;
	case 18:
		goto loc_82C94B74;
	case 19:
		goto loc_82C94A44;
	case 20:
		goto loc_82C94B74;
	case 21:
		goto loc_82C94B74;
	case 22:
		goto loc_82C94B74;
	case 23:
		goto loc_82C94B74;
	case 24:
		goto loc_82C94A0C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,18692(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18692);
	// lwz r22,18712(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18712);
	// lwz r22,18732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18732);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18936);
	// lwz r22,18936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18936);
	// lwz r22,19028(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19028);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19044(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19044);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18936);
	// lwz r22,19012(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19012);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19012(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19012);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,19316(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19316);
	// lwz r22,18956(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 18956);
loc_82C949F8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9494c
	if (!ctx.cr6.eq) goto loc_82C9494C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94A0C:
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r8,r7,1280
	ctx.r8.s64 = ctx.r7.s64 + 1280;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r3,r4,27
	ctx.r3.u64 = ctx.r4.u32 & 0x1F;
	// lbzx r11,r11,r8
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// slw r8,r31,r3
	ctx.r8.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r3.u8 & 0x3F));
	// rotlwi r11,r11,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r11.u32, 3);
	// add r4,r11,r9
	ctx.r4.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r3,r4,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r3,r7
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r7.u32);
	// and r9,r11,r8
	ctx.r9.u64 = ctx.r11.u64 & ctx.r8.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c94b74
	if (ctx.cr6.eq) goto loc_82C94B74;
loc_82C94A44:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c94008
	ctx.lr = 0x82C94A50;
	sub_82C94008(ctx, base);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94A54:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,2
	ctx.r3.s64 = 2;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94A64:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9462c
	if (ctx.cr6.eq) goto loc_82C9462C;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c94a98
	if (!ctx.cr6.eq) goto loc_82C94A98;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c94a98
	if (!ctx.cr6.eq) goto loc_82C94A98;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// li r3,4
	ctx.r3.s64 = 4;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94A98:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c94b78
	goto loc_82C94B78;
loc_82C94AA0:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9462c
	if (ctx.cr6.eq) goto loc_82C9462C;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94ac8
	if (!ctx.cr6.eq) goto loc_82C94AC8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94ad0
	goto loc_82C94AD0;
loc_82C94AC8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94AD0;
	sub_82C8DAE8(ctx, base);
loc_82C94AD0:
	// cmpwi cr6,r3,20
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 20, ctx.xer);
	// beq cr6,0x82c94af0
	if (ctx.cr6.eq) goto loc_82C94AF0;
	// cmpwi cr6,r3,27
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 27, ctx.xer);
	// bne cr6,0x82c94b74
	if (!ctx.cr6.eq) goto loc_82C94B74;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c92ba0
	ctx.lr = 0x82C94AEC;
	sub_82C92BA0(ctx, base);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94AF0:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// subf r10,r11,r5
	ctx.r10.s64 = ctx.r5.s64 - ctx.r11.s64;
	// cmpwi cr6,r10,12
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 12, ctx.xer);
	// blt cr6,0x82c9462c
	if (ctx.cr6.lt) goto loc_82C9462C;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r9,-4144
	ctx.r9.s64 = ctx.r9.s64 + -4144;
loc_82C94B0C:
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c94b48
	if (!ctx.cr6.eq) goto loc_82C94B48;
	// addi r8,r9,5488
	ctx.r8.s64 = ctx.r9.s64 + 5488;
	// lbz r7,1(r11)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// lbzx r5,r10,r8
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r8.u32);
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94b48
	if (!ctx.cr6.eq) goto loc_82C94B48;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// cmpwi cr6,r10,6
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 6, ctx.xer);
	// blt cr6,0x82c94b0c
	if (ctx.cr6.lt) goto loc_82C94B0C;
	// li r3,8
	ctx.r3.s64 = 8;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94B48:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94B54:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c930e8
	ctx.lr = 0x82C94B60;
	sub_82C930E8(ctx, base);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94B64:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c93830
	ctx.lr = 0x82C94B70;
	sub_82C93830(ctx, base);
	// b 0x82c94b7c
	goto loc_82C94B7C;
loc_82C94B74:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C94B78:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C94B7C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C94B94"))) PPC_WEAK_FUNC(sub_82C94B94);
PPC_FUNC_IMPL(__imp__sub_82C94B94) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C94B98"))) PPC_WEAK_FUNC(sub_82C94B98);
PPC_FUNC_IMPL(__imp__sub_82C94B98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94bd0
	if (!ctx.cr6.eq) goto loc_82C94BD0;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94BD0:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c94c08
	if (ctx.cr6.eq) goto loc_82C94C08;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c94c04
	if (!ctx.cr6.eq) goto loc_82C94C04;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94C04:
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C94C08:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94c24
	if (!ctx.cr6.eq) goto loc_82C94C24;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94c2c
	goto loc_82C94C2C;
loc_82C94C24:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94C2C;
	sub_82C8DAE8(ctx, base);
loc_82C94C2C:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c94e0c
	if (ctx.cr6.gt) goto loc_82C94E0C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,19532
	ctx.r12.s64 = ctx.r12.s64 + 19532;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C94E04;
	case 1:
		goto loc_82C94E04;
	case 2:
		goto loc_82C94C78;
	case 3:
		goto loc_82C94C98;
	case 4:
		goto loc_82C94D34;
	case 5:
		goto loc_82C94DB8;
	case 6:
		goto loc_82C94DDC;
	case 7:
		goto loc_82C94DF0;
	case 8:
		goto loc_82C94E04;
	case 9:
		goto loc_82C94CB8;
	case 10:
		goto loc_82C94D14;
	default:
		__builtin_unreachable();
	}
	// lwz r22,19972(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19972);
	// lwz r22,19972(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19972);
	// lwz r22,19576(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19576);
	// lwz r22,19608(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19608);
	// lwz r22,19764(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19764);
	// lwz r22,19896(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19896);
	// lwz r22,19932(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19932);
	// lwz r22,19952(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19952);
	// lwz r22,19972(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19972);
	// lwz r22,19640(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19640);
	// lwz r22,19732(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 19732);
loc_82C94C78:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c94608
	ctx.lr = 0x82C94C84;
	sub_82C94608(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94C98:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c93d60
	ctx.lr = 0x82C94CA4;
	sub_82C93D60(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94CB8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94cdc
	if (!ctx.cr6.eq) goto loc_82C94CDC;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94CDC:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94cf8
	if (!ctx.cr6.eq) goto loc_82C94CF8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94d00
	goto loc_82C94D00;
loc_82C94CF8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94D00;
	sub_82C8DAE8(ctx, base);
loc_82C94D00:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c94d0c
	if (!ctx.cr6.eq) goto loc_82C94D0C;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C94D0C:
	// li r3,7
	ctx.r3.s64 = 7;
	// b 0x82c94ea0
	goto loc_82C94EA0;
loc_82C94D14:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94D34:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94d58
	if (!ctx.cr6.eq) goto loc_82C94D58;
loc_82C94D40:
	// li r3,-5
	ctx.r3.s64 = -5;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94D58:
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c94e10
	if (!ctx.cr6.eq) goto loc_82C94E10;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c94e10
	if (!ctx.cr6.eq) goto loc_82C94E10;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94d40
	if (ctx.cr6.eq) goto loc_82C94D40;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c94db0
	if (!ctx.cr6.eq) goto loc_82C94DB0;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c94db0
	if (!ctx.cr6.eq) goto loc_82C94DB0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94DB0:
	// addi r10,r11,-2
	ctx.r10.s64 = ctx.r11.s64 + -2;
	// b 0x82c94e10
	goto loc_82C94E10;
loc_82C94DB8:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c94e0c
	if (!ctx.cr6.lt) goto loc_82C94E0C;
loc_82C94DC4:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94DDC:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// blt cr6,0x82c94dc4
	if (ctx.cr6.lt) goto loc_82C94DC4;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c94e10
	goto loc_82C94E10;
loc_82C94DF0:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// blt cr6,0x82c94dc4
	if (ctx.cr6.lt) goto loc_82C94DC4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c94e10
	goto loc_82C94E10;
loc_82C94E04:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c94ea0
	goto loc_82C94EA0;
loc_82C94E0C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C94E10:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94e9c
	if (ctx.cr6.eq) goto loc_82C94E9C;
	// addi r7,r10,4
	ctx.r7.s64 = ctx.r10.s64 + 4;
	// addi r8,r10,2
	ctx.r8.s64 = ctx.r10.s64 + 2;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C94E24:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c94e40
	if (!ctx.cr6.eq) goto loc_82C94E40;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94e48
	goto loc_82C94E48;
loc_82C94E40:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94E48;
	sub_82C8DAE8(ctx, base);
loc_82C94E48:
	// cmplwi cr6,r3,10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 10, ctx.xer);
	// bgt cr6,0x82c94f30
	if (ctx.cr6.gt) goto loc_82C94F30;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,20072
	ctx.r12.s64 = ctx.r12.s64 + 20072;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C94E9C;
	case 1:
		goto loc_82C94E9C;
	case 2:
		goto loc_82C94E9C;
	case 3:
		goto loc_82C94E9C;
	case 4:
		goto loc_82C94EF0;
	case 5:
		goto loc_82C94E94;
	case 6:
		goto loc_82C94EB8;
	case 7:
		goto loc_82C94ED4;
	case 8:
		goto loc_82C94E9C;
	case 9:
		goto loc_82C94E9C;
	case 10:
		goto loc_82C94E9C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,20124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20208(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20208);
	// lwz r22,20116(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20116);
	// lwz r22,20152(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20152);
	// lwz r22,20180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20180);
	// lwz r22,20124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
	// lwz r22,20124(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20124);
loc_82C94E94:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bge cr6,0x82c94f30
	if (!ctx.cr6.lt) goto loc_82C94F30;
loc_82C94E9C:
	// li r3,6
	ctx.r3.s64 = 6;
loc_82C94EA0:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C94EB8:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c94e9c
	if (ctx.cr6.lt) goto loc_82C94E9C;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// addi r8,r8,3
	ctx.r8.s64 = ctx.r8.s64 + 3;
	// addi r7,r7,3
	ctx.r7.s64 = ctx.r7.s64 + 3;
	// b 0x82c94f40
	goto loc_82C94F40;
loc_82C94ED4:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c94e9c
	if (ctx.cr6.lt) goto loc_82C94E9C;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// b 0x82c94f40
	goto loc_82C94F40;
loc_82C94EF0:
	// cmplw cr6,r8,r5
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94e9c
	if (ctx.cr6.eq) goto loc_82C94E9C;
	// lbz r11,0(r8)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c94f30
	if (!ctx.cr6.eq) goto loc_82C94F30;
	// lbz r11,3(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c94f30
	if (!ctx.cr6.eq) goto loc_82C94F30;
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c94e9c
	if (ctx.cr6.eq) goto loc_82C94E9C;
	// lbz r11,0(r7)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c94f30
	if (!ctx.cr6.eq) goto loc_82C94F30;
	// lbz r11,5(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 5);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// beq cr6,0x82c94f4c
	if (ctx.cr6.eq) goto loc_82C94F4C;
loc_82C94F30:
	// addi r7,r7,2
	ctx.r7.s64 = ctx.r7.s64 + 2;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C94F40:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94e24
	if (!ctx.cr6.eq) goto loc_82C94E24;
	// b 0x82c94e9c
	goto loc_82C94E9C;
loc_82C94F4C:
	// addi r11,r10,4
	ctx.r11.s64 = ctx.r10.s64 + 4;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C94F6C"))) PPC_WEAK_FUNC(sub_82C94F6C);
PPC_FUNC_IMPL(__imp__sub_82C94F6C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C94F70"))) PPC_WEAK_FUNC(sub_82C94F70);
PPC_FUNC_IMPL(__imp__sub_82C94F70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c94f9c
	if (!ctx.cr6.eq) goto loc_82C94F9C;
	// li r3,-22
	ctx.r3.s64 = -22;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C94F9C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c94fb8
	if (!ctx.cr6.eq) goto loc_82C94FB8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c94fc4
	goto loc_82C94FC4;
loc_82C94FB8:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C94FC4;
	sub_82C8DAE8(ctx, base);
loc_82C94FC4:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,25
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 25, ctx.xer);
	// bgt cr6,0x82c951f0
	if (ctx.cr6.gt) goto loc_82C951F0;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,20468
	ctx.r12.s64 = ctx.r12.s64 + 20468;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9519C;
	case 1:
		goto loc_82C951B0;
	case 2:
		goto loc_82C951C4;
	case 3:
		goto loc_82C951F0;
	case 4:
		goto loc_82C951E8;
	case 5:
		goto loc_82C951E8;
	case 6:
		goto loc_82C951F0;
	case 7:
		goto loc_82C951F0;
	case 8:
		goto loc_82C951F0;
	case 9:
		goto loc_82C951F0;
	case 10:
		goto loc_82C951F0;
	case 11:
		goto loc_82C951F0;
	case 12:
		goto loc_82C951F0;
	case 13:
		goto loc_82C951F0;
	case 14:
		goto loc_82C951F0;
	case 15:
		goto loc_82C951F0;
	case 16:
		goto loc_82C951E8;
	case 17:
		goto loc_82C95094;
	case 18:
		goto loc_82C951F0;
	case 19:
		goto loc_82C95094;
	case 20:
		goto loc_82C951F0;
	case 21:
		goto loc_82C951F0;
	case 22:
		goto loc_82C951F0;
	case 23:
		goto loc_82C951F0;
	case 24:
		goto loc_82C9505C;
	case 25:
		goto loc_82C951E8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,20892(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20892);
	// lwz r22,20912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20912);
	// lwz r22,20932(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20932);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20968);
	// lwz r22,20968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20968);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20968);
	// lwz r22,20628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20628);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20628);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20572(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20572);
	// lwz r22,20968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20968);
loc_82C9505C:
	// clrlwi r3,r7,24
	ctx.r3.u64 = ctx.r7.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r3,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r11.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c951f0
	if (ctx.cr6.eq) goto loc_82C951F0;
loc_82C95094:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c95194
	if (ctx.cr6.eq) goto loc_82C95194;
loc_82C950A0:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c950bc
	if (!ctx.cr6.eq) goto loc_82C950BC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c950c8
	goto loc_82C950C8;
loc_82C950BC:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C950C8;
	sub_82C8DAE8(ctx, base);
loc_82C950C8:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c951f0
	if (ctx.cr6.gt) goto loc_82C951F0;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,20716
	ctx.r12.s64 = ctx.r12.s64 + 20716;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9519C;
	case 1:
		goto loc_82C951B0;
	case 2:
		goto loc_82C951C4;
	case 3:
		goto loc_82C951F0;
	case 4:
		goto loc_82C951F0;
	case 5:
		goto loc_82C951F0;
	case 6:
		goto loc_82C951F0;
	case 7:
		goto loc_82C951F0;
	case 8:
		goto loc_82C951F0;
	case 9:
		goto loc_82C951F0;
	case 10:
		goto loc_82C951F0;
	case 11:
		goto loc_82C951F0;
	case 12:
		goto loc_82C951F0;
	case 13:
		goto loc_82C951D8;
	case 14:
		goto loc_82C951F0;
	case 15:
		goto loc_82C951F0;
	case 16:
		goto loc_82C951F0;
	case 17:
		goto loc_82C95188;
	case 18:
		goto loc_82C951F0;
	case 19:
		goto loc_82C95188;
	case 20:
		goto loc_82C95188;
	case 21:
		goto loc_82C95188;
	case 22:
		goto loc_82C95188;
	case 23:
		goto loc_82C951F0;
	case 24:
		goto loc_82C95150;
	default:
		__builtin_unreachable();
	}
	// lwz r22,20892(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20892);
	// lwz r22,20912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20912);
	// lwz r22,20932(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20932);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20952(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20952);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20872(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20872(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20872(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20872(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20872(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20872);
	// lwz r22,20976(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20976);
	// lwz r22,20816(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20816);
loc_82C95150:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r8,1536
	ctx.r4.s64 = ctx.r8.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r31,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c951f0
	if (ctx.cr6.eq) goto loc_82C951F0;
loc_82C95188:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c950a0
	if (!ctx.cr6.eq) goto loc_82C950A0;
loc_82C95194:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C9519C:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c951f0
	if (!ctx.cr6.lt) goto loc_82C951F0;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C951B0:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c951f0
	if (!ctx.cr6.lt) goto loc_82C951F0;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C951C4:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c951f0
	if (!ctx.cr6.lt) goto loc_82C951F0;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C951D8:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,28
	ctx.r3.s64 = 28;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// b 0x82c951f8
	goto loc_82C951F8;
loc_82C951E8:
	// li r3,22
	ctx.r3.s64 = 22;
	// b 0x82c951f4
	goto loc_82C951F4;
loc_82C951F0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C951F4:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C951F8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C95210"))) PPC_WEAK_FUNC(sub_82C95210);
PPC_FUNC_IMPL(__imp__sub_82C95210) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9523c
	if (!ctx.cr6.eq) goto loc_82C9523C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C9523C:
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c95258
	if (!ctx.cr6.eq) goto loc_82C95258;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95264
	goto loc_82C95264;
loc_82C95258:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95264;
	sub_82C8DAE8(ctx, base);
loc_82C95264:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c95498
	if (ctx.cr6.gt) goto loc_82C95498;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// li r31,1
	ctx.r31.s64 = 1;
	// addi r8,r9,-4144
	ctx.r8.s64 = ctx.r9.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,21140
	ctx.r12.s64 = ctx.r12.s64 + 21140;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C95454;
	case 1:
		goto loc_82C95468;
	case 2:
		goto loc_82C95484;
	case 3:
		goto loc_82C95498;
	case 4:
		goto loc_82C95498;
	case 5:
		goto loc_82C95498;
	case 6:
		goto loc_82C95498;
	case 7:
		goto loc_82C95498;
	case 8:
		goto loc_82C95498;
	case 9:
		goto loc_82C95498;
	case 10:
		goto loc_82C95498;
	case 11:
		goto loc_82C95498;
	case 12:
		goto loc_82C95498;
	case 13:
		goto loc_82C95498;
	case 14:
		goto loc_82C95498;
	case 15:
		goto loc_82C95498;
	case 16:
		goto loc_82C95498;
	case 17:
		goto loc_82C95330;
	case 18:
		goto loc_82C95498;
	case 19:
		goto loc_82C95330;
	case 20:
		goto loc_82C95498;
	case 21:
		goto loc_82C95498;
	case 22:
		goto loc_82C95498;
	case 23:
		goto loc_82C95498;
	case 24:
		goto loc_82C952F8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,21588(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21588);
	// lwz r22,21608(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21608);
	// lwz r22,21636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21636);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21296(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21296);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21296(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21296);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21240(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21240);
loc_82C952F8:
	// clrlwi r3,r7,24
	ctx.r3.u64 = ctx.r7.u32 & 0xFF;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r11,r8,1280
	ctx.r11.s64 = ctx.r8.s64 + 1280;
	// rlwinm r9,r4,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r7,r4,27
	ctx.r7.u64 = ctx.r4.u32 & 0x1F;
	// slw r4,r31,r7
	ctx.r4.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r7.u8 & 0x3F));
	// lbzx r3,r3,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r11.u32);
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// and r4,r7,r4
	ctx.r4.u64 = ctx.r7.u64 & ctx.r4.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c95498
	if (ctx.cr6.eq) goto loc_82C95498;
loc_82C95330:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9544c
	if (ctx.cr6.eq) goto loc_82C9544C;
loc_82C9533C:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c95358
	if (!ctx.cr6.eq) goto loc_82C95358;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95364
	goto loc_82C95364;
loc_82C95358:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95364;
	sub_82C8DAE8(ctx, base);
loc_82C95364:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 31, ctx.xer);
	// bgt cr6,0x82c95498
	if (ctx.cr6.gt) goto loc_82C95498;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,21384
	ctx.r12.s64 = ctx.r12.s64 + 21384;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C95454;
	case 1:
		goto loc_82C95468;
	case 2:
		goto loc_82C95484;
	case 3:
		goto loc_82C95498;
	case 4:
		goto loc_82C9547C;
	case 5:
		goto loc_82C9547C;
	case 6:
		goto loc_82C9547C;
	case 7:
		goto loc_82C95498;
	case 8:
		goto loc_82C95498;
	case 9:
		goto loc_82C95498;
	case 10:
		goto loc_82C95498;
	case 11:
		goto loc_82C95498;
	case 12:
		goto loc_82C95498;
	case 13:
		goto loc_82C95498;
	case 14:
		goto loc_82C95498;
	case 15:
		goto loc_82C95498;
	case 16:
		goto loc_82C9547C;
	case 17:
		goto loc_82C95440;
	case 18:
		goto loc_82C95498;
	case 19:
		goto loc_82C95440;
	case 20:
		goto loc_82C95440;
	case 21:
		goto loc_82C95440;
	case 22:
		goto loc_82C95440;
	case 23:
		goto loc_82C95498;
	case 24:
		goto loc_82C95408;
	case 25:
		goto loc_82C9547C;
	case 26:
		goto loc_82C95498;
	case 27:
		goto loc_82C9547C;
	case 28:
		goto loc_82C95498;
	case 29:
		goto loc_82C95498;
	case 30:
		goto loc_82C95498;
	case 31:
		goto loc_82C9547C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,21588(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21588);
	// lwz r22,21608(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21608);
	// lwz r22,21636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21636);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21568);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21512(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21512);
	// lwz r22,21628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21656);
	// lwz r22,21628(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21628);
loc_82C95408:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r8,1536
	ctx.r4.s64 = ctx.r8.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r31,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r31.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r8
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c95498
	if (ctx.cr6.eq) goto loc_82C95498;
loc_82C95440:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9533c
	if (!ctx.cr6.eq) goto loc_82C9533C;
loc_82C9544C:
	// li r3,-20
	ctx.r3.s64 = -20;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C95454:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c95498
	if (!ctx.cr6.lt) goto loc_82C95498;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C95468:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c95498
	if (!ctx.cr6.lt) goto loc_82C95498;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C9547C:
	// li r3,20
	ctx.r3.s64 = 20;
	// b 0x82c9549c
	goto loc_82C9549C;
loc_82C95484:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c95498
	if (!ctx.cr6.lt) goto loc_82C95498;
	// li r3,-2
	ctx.r3.s64 = -2;
	// b 0x82c954a0
	goto loc_82C954A0;
loc_82C95498:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C9549C:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C954A0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C954B8"))) PPC_WEAK_FUNC(sub_82C954B8);
PPC_FUNC_IMPL(__imp__sub_82C954B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r8,r4
	ctx.r8.u64 = ctx.r4.u64;
	// cmplw cr6,r5,r6
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, ctx.xer);
	// beq cr6,0x82c9556c
	if (ctx.cr6.eq) goto loc_82C9556C;
	// subf r10,r5,r6
	ctx.r10.s64 = ctx.r6.s64 - ctx.r5.s64;
loc_82C954D8:
	// lbz r3,0(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c954f4
	if (!ctx.cr6.eq) goto loc_82C954F4;
	// lbz r11,1(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c954fc
	goto loc_82C954FC;
loc_82C954F4:
	// lbz r4,1(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C954FC;
	sub_82C8DAE8(ctx, base);
loc_82C954FC:
	// cmplwi cr6,r3,13
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 13, ctx.xer);
	// bgt cr6,0x82c9555c
	if (ctx.cr6.gt) goto loc_82C9555C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,21788
	ctx.r12.s64 = ctx.r12.s64 + 21788;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C955E8;
	case 1:
		goto loc_82C955E8;
	case 2:
		goto loc_82C9555C;
	case 3:
		goto loc_82C9555C;
	case 4:
		goto loc_82C9555C;
	case 5:
		goto loc_82C95554;
	case 6:
		goto loc_82C95580;
	case 7:
		goto loc_82C95594;
	case 8:
		goto loc_82C955E8;
	case 9:
		goto loc_82C9555C;
	case 10:
		goto loc_82C9555C;
	case 11:
		goto loc_82C9555C;
	case 12:
		goto loc_82C955A8;
	case 13:
		goto loc_82C955A8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,21992(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21992);
	// lwz r22,21992(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21992);
	// lwz r22,21852(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21852(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21852(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21844(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21844);
	// lwz r22,21888(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21888);
	// lwz r22,21908(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21908);
	// lwz r22,21992(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21992);
	// lwz r22,21852(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21852(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21852(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21852);
	// lwz r22,21928(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21928);
	// lwz r22,21928(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21928);
loc_82C95554:
	// cmpwi cr6,r10,2
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 2, ctx.xer);
	// blt cr6,0x82c955d4
	if (ctx.cr6.lt) goto loc_82C955D4;
loc_82C9555C:
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
loc_82C95564:
	// cmplw cr6,r5,r6
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82c954d8
	if (!ctx.cr6.eq) goto loc_82C954D8;
loc_82C9556C:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C95580:
	// cmpwi cr6,r10,3
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 3, ctx.xer);
	// blt cr6,0x82c955d4
	if (ctx.cr6.lt) goto loc_82C955D4;
	// addi r5,r5,3
	ctx.r5.s64 = ctx.r5.s64 + 3;
	// addi r10,r10,-3
	ctx.r10.s64 = ctx.r10.s64 + -3;
	// b 0x82c95564
	goto loc_82C95564;
loc_82C95594:
	// cmpwi cr6,r10,4
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 4, ctx.xer);
	// blt cr6,0x82c955d4
	if (ctx.cr6.lt) goto loc_82C955D4;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// b 0x82c95564
	goto loc_82C95564;
loc_82C955A8:
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// cmpw cr6,r3,r9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82c95564
	if (!ctx.cr6.eq) goto loc_82C95564;
	// cmplw cr6,r5,r6
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82c95600
	if (!ctx.cr6.eq) goto loc_82C95600;
	// li r3,-27
	ctx.r3.s64 = -27;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C955D4:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C955E8:
	// stw r5,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r5.u32);
loc_82C955EC:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C95600:
	// stw r5,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r5.u32);
	// lbz r3,0(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c95620
	if (!ctx.cr6.eq) goto loc_82C95620;
	// lbz r11,1(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95628
	goto loc_82C95628;
loc_82C95620:
	// lbz r4,1(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95628;
	sub_82C8DAE8(ctx, base);
loc_82C95628:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,21
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 21, ctx.xer);
	// bgt cr6,0x82c955ec
	if (ctx.cr6.gt) goto loc_82C955EC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,22092
	ctx.r12.s64 = ctx.r12.s64 + 22092;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C956A4;
	case 1:
		goto loc_82C956A4;
	case 2:
		goto loc_82C956A4;
	case 3:
		goto loc_82C955EC;
	case 4:
		goto loc_82C955EC;
	case 5:
		goto loc_82C955EC;
	case 6:
		goto loc_82C955EC;
	case 7:
		goto loc_82C955EC;
	case 8:
		goto loc_82C955EC;
	case 9:
		goto loc_82C955EC;
	case 10:
		goto loc_82C955EC;
	case 11:
		goto loc_82C956A4;
	case 12:
		goto loc_82C956A4;
	case 13:
		goto loc_82C955EC;
	case 14:
		goto loc_82C955EC;
	case 15:
		goto loc_82C955EC;
	case 16:
		goto loc_82C955EC;
	case 17:
		goto loc_82C955EC;
	case 18:
		goto loc_82C955EC;
	case 19:
		goto loc_82C955EC;
	case 20:
		goto loc_82C955EC;
	case 21:
		goto loc_82C956A4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,22180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,22180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,22180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,22180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,22180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,21996(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21996);
	// lwz r22,22180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22180);
loc_82C956A4:
	// li r3,27
	ctx.r3.s64 = 27;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C956B8"))) PPC_WEAK_FUNC(sub_82C956B8);
PPC_FUNC_IMPL(__imp__sub_82C956B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C956C0;
	sub_82CA2BEC(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c956e0
	if (!ctx.cr6.eq) goto loc_82C956E0;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C956E0:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c9570c
	if (ctx.cr6.eq) goto loc_82C9570C;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c95708
	if (!ctx.cr6.eq) goto loc_82C95708;
loc_82C956FC:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95708:
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C9570C:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c95728
	if (!ctx.cr6.eq) goto loc_82C95728;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95734
	goto loc_82C95734;
loc_82C95728:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95734;
	sub_82C8DAE8(ctx, base);
loc_82C95734:
	// addi r9,r3,-2
	ctx.r9.s64 = ctx.r3.s64 + -2;
	// cmplwi cr6,r9,34
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 34, ctx.xer);
	// bgt cr6,0x82c95ef8
	if (ctx.cr6.gt) goto loc_82C95EF8;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// li r30,1
	ctx.r30.s64 = 1;
	// addi r31,r11,-4144
	ctx.r31.s64 = ctx.r11.s64 + -4144;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,22372
	ctx.r12.s64 = ctx.r12.s64 + 22372;
	// rlwinm r0,r9,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_82C95830;
	case 1:
		goto loc_82C95EF8;
	case 2:
		goto loc_82C959F0;
	case 3:
		goto loc_82C95BD4;
	case 4:
		goto loc_82C95BEC;
	case 5:
		goto loc_82C95C04;
	case 6:
		goto loc_82C95EF8;
	case 7:
		goto loc_82C95924;
	case 8:
		goto loc_82C95940;
	case 9:
		goto loc_82C95BAC;
	case 10:
		goto loc_82C957F0;
	case 11:
		goto loc_82C95810;
	case 12:
		goto loc_82C95EF8;
	case 13:
		goto loc_82C95EF8;
	case 14:
		goto loc_82C95EF8;
	case 15:
		goto loc_82C95EF8;
	case 16:
		goto loc_82C95EF8;
	case 17:
		goto loc_82C95BC0;
	case 18:
		goto loc_82C959DC;
	case 19:
		goto loc_82C95940;
	case 20:
		goto loc_82C95C54;
	case 21:
		goto loc_82C95C90;
	case 22:
		goto loc_82C95C54;
	case 23:
		goto loc_82C95C90;
	case 24:
		goto loc_82C95C90;
	case 25:
		goto loc_82C95C90;
	case 26:
		goto loc_82C95EF8;
	case 27:
		goto loc_82C95C1C;
	case 28:
		goto loc_82C959B4;
	case 29:
		goto loc_82C95A68;
	case 30:
		goto loc_82C95A7C;
	case 31:
		goto loc_82C95EF8;
	case 32:
		goto loc_82C95EF8;
	case 33:
		goto loc_82C959C8;
	case 34:
		goto loc_82C95B98;
	default:
		__builtin_unreachable();
	}
	// lwz r22,22576(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22576);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23024(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23024);
	// lwz r22,23508(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23508);
	// lwz r22,23532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23532);
	// lwz r22,23556(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23556);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22820(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22820);
	// lwz r22,22848(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22848);
	// lwz r22,23468(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23468);
	// lwz r22,22512(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22512);
	// lwz r22,22544(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22544);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23488(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23488);
	// lwz r22,23004(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23004);
	// lwz r22,22848(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22848);
	// lwz r22,23636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23636);
	// lwz r22,23696(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23696);
	// lwz r22,23636(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23636);
	// lwz r22,23696(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23696);
	// lwz r22,23696(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23696);
	// lwz r22,23696(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23696);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23580(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23580);
	// lwz r22,22964(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22964);
	// lwz r22,23144(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23144);
	// lwz r22,23164(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23164);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22984(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22984);
	// lwz r22,23448(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23448);
loc_82C957F0:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,12
	ctx.r3.s64 = 12;
	// bl 0x82c954b8
	ctx.lr = 0x82C95808;
	sub_82C954B8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95810:
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// addi r5,r10,2
	ctx.r5.s64 = ctx.r10.s64 + 2;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,13
	ctx.r3.s64 = 13;
	// bl 0x82c954b8
	ctx.lr = 0x82C95828;
	sub_82C954B8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95830:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c956fc
	if (ctx.cr6.eq) goto loc_82C956FC;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c95858
	if (!ctx.cr6.eq) goto loc_82C95858;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95860
	goto loc_82C95860;
loc_82C95858:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95860;
	sub_82C8DAE8(ctx, base);
loc_82C95860:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c95ef8
	if (ctx.cr6.gt) goto loc_82C95EF8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,22660
	ctx.r12.s64 = ctx.r12.s64 + 22660;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C95910;
	case 1:
		goto loc_82C95910;
	case 2:
		goto loc_82C95910;
	case 3:
		goto loc_82C95EF8;
	case 4:
		goto loc_82C95EF8;
	case 5:
		goto loc_82C95EF8;
	case 6:
		goto loc_82C95EF8;
	case 7:
		goto loc_82C95EF8;
	case 8:
		goto loc_82C95EF8;
	case 9:
		goto loc_82C95EF8;
	case 10:
		goto loc_82C958FC;
	case 11:
		goto loc_82C958E8;
	case 12:
		goto loc_82C95EF8;
	case 13:
		goto loc_82C95EF8;
	case 14:
		goto loc_82C95EF8;
	case 15:
		goto loc_82C95EF8;
	case 16:
		goto loc_82C95EF8;
	case 17:
		goto loc_82C95910;
	case 18:
		goto loc_82C95EF8;
	case 19:
		goto loc_82C95910;
	case 20:
		goto loc_82C95EF8;
	case 21:
		goto loc_82C95EF8;
	case 22:
		goto loc_82C95EF8;
	case 23:
		goto loc_82C95EF8;
	case 24:
		goto loc_82C95910;
	default:
		__builtin_unreachable();
	}
	// lwz r22,22800(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,22800(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,22800(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22780(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22780);
	// lwz r22,22760(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22760);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22800(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22800(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,22800(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 22800);
loc_82C958E8:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c92db0
	ctx.lr = 0x82C958F4;
	sub_82C92DB0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C958FC:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c930e8
	ctx.lr = 0x82C95908;
	sub_82C930E8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95910:
	// addi r11,r10,-2
	ctx.r11.s64 = ctx.r10.s64 + -2;
	// li r3,29
	ctx.r3.s64 = 29;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95924:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c95940
	if (!ctx.cr6.eq) goto loc_82C95940;
	// stw r5,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r5.u32);
	// li r3,-15
	ctx.r3.s64 = -15;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95940:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c959a4
	if (ctx.cr6.eq) goto loc_82C959A4;
loc_82C9594C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c95968
	if (!ctx.cr6.eq) goto loc_82C95968;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95970
	goto loc_82C95970;
loc_82C95968:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95970;
	sub_82C8DAE8(ctx, base);
loc_82C95970:
	// cmpwi cr6,r3,9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 9, ctx.xer);
	// beq cr6,0x82c9598c
	if (ctx.cr6.eq) goto loc_82C9598C;
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// beq cr6,0x82c95998
	if (ctx.cr6.eq) goto loc_82C95998;
	// cmpwi cr6,r3,21
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 21, ctx.xer);
	// bne cr6,0x82c959a4
	if (!ctx.cr6.eq) goto loc_82C959A4;
	// b 0x82c95998
	goto loc_82C95998;
loc_82C9598C:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c959a4
	if (ctx.cr6.eq) goto loc_82C959A4;
loc_82C95998:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9594c
	if (!ctx.cr6.eq) goto loc_82C9594C;
loc_82C959A4:
	// li r3,15
	ctx.r3.s64 = 15;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C959B4:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c94f70
	ctx.lr = 0x82C959C0;
	sub_82C94F70(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C959C8:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,38
	ctx.r3.s64 = 38;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C959DC:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,25
	ctx.r3.s64 = 25;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C959F0:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c95a08
	if (!ctx.cr6.eq) goto loc_82C95A08;
	// li r3,-26
	ctx.r3.s64 = -26;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95A08:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c95a58
	if (!ctx.cr6.eq) goto loc_82C95A58;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,93
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 93, ctx.xer);
	// bne cr6,0x82c95a58
	if (!ctx.cr6.eq) goto loc_82C95A58;
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c956fc
	if (ctx.cr6.eq) goto loc_82C956FC;
	// lbz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c95a58
	if (!ctx.cr6.eq) goto loc_82C95A58;
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r10,62
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 62, ctx.xer);
	// bne cr6,0x82c95a58
	if (!ctx.cr6.eq) goto loc_82C95A58;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// li r3,34
	ctx.r3.s64 = 34;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95A58:
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// li r3,26
	ctx.r3.s64 = 26;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95A68:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,23
	ctx.r3.s64 = 23;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95A7C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c95a94
	if (!ctx.cr6.eq) goto loc_82C95A94;
	// li r3,-24
	ctx.r3.s64 = -24;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95A94:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c95ab0
	if (!ctx.cr6.eq) goto loc_82C95AB0;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95ab8
	goto loc_82C95AB8;
loc_82C95AB0:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95AB8;
	sub_82C8DAE8(ctx, base);
loc_82C95AB8:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 27, ctx.xer);
	// bgt cr6,0x82c95ef8
	if (ctx.cr6.gt) goto loc_82C95EF8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,23260
	ctx.r12.s64 = ctx.r12.s64 + 23260;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C95B88;
	case 1:
		goto loc_82C95B88;
	case 2:
		goto loc_82C95B88;
	case 3:
		goto loc_82C95EF8;
	case 4:
		goto loc_82C95EF8;
	case 5:
		goto loc_82C95EF8;
	case 6:
		goto loc_82C95B60;
	case 7:
		goto loc_82C95EF8;
	case 8:
		goto loc_82C95EF8;
	case 9:
		goto loc_82C95EF8;
	case 10:
		goto loc_82C95EF8;
	case 11:
		goto loc_82C95EF8;
	case 12:
		goto loc_82C95B88;
	case 13:
		goto loc_82C95EF8;
	case 14:
		goto loc_82C95EF8;
	case 15:
		goto loc_82C95EF8;
	case 16:
		goto loc_82C95EF8;
	case 17:
		goto loc_82C95EF8;
	case 18:
		goto loc_82C95EF8;
	case 19:
		goto loc_82C95EF8;
	case 20:
		goto loc_82C95EF8;
	case 21:
		goto loc_82C95EF8;
	case 22:
		goto loc_82C95EF8;
	case 23:
		goto loc_82C95B88;
	case 24:
		goto loc_82C95B4C;
	case 25:
		goto loc_82C95B74;
	case 26:
		goto loc_82C95B88;
	case 27:
		goto loc_82C95B88;
	default:
		__builtin_unreachable();
	}
	// lwz r22,23432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,23432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,23432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23392(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23392);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,23432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,23372(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23372);
	// lwz r22,23412(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23412);
	// lwz r22,23432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
	// lwz r22,23432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23432);
loc_82C95B4C:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,36
	ctx.r3.s64 = 36;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95B60:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,35
	ctx.r3.s64 = 35;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95B74:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,37
	ctx.r3.s64 = 37;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95B88:
	// li r3,24
	ctx.r3.s64 = 24;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95B98:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,21
	ctx.r3.s64 = 21;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95BAC:
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,17
	ctx.r3.s64 = 17;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95BC0:
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c95210
	ctx.lr = 0x82C95BCC;
	sub_82C95210(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95BD4:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bge cr6,0x82c95ef8
	if (!ctx.cr6.lt) goto loc_82C95EF8;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95BEC:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bge cr6,0x82c95ef8
	if (!ctx.cr6.lt) goto loc_82C95EF8;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95C04:
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bge cr6,0x82c95ef8
	if (!ctx.cr6.lt) goto loc_82C95EF8;
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95C1C:
	// clrlwi r11,r8,24
	ctx.r11.u64 = ctx.r8.u32 & 0xFF;
	// lbz r9,1(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r7,r31,1280
	ctx.r7.s64 = ctx.r31.s64 + 1280;
	// clrlwi r4,r9,27
	ctx.r4.u64 = ctx.r9.u32 & 0x1F;
	// rlwinm r8,r9,27,5,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x7FFFFFF;
	// slw r3,r30,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r30.u32 << (ctx.r4.u8 & 0x3F));
	// lbzx r9,r11,r7
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r7.u32);
	// rotlwi r9,r9,3
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 3);
	// add r8,r9,r8
	ctx.r8.u64 = ctx.r9.u64 + ctx.r8.u64;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r7,r31
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r31.u32);
	// and r3,r4,r3
	ctx.r3.u64 = ctx.r4.u64 & ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c95c5c
	if (ctx.cr6.eq) goto loc_82C95C5C;
loc_82C95C54:
	// li r8,18
	ctx.r8.s64 = 18;
	// b 0x82c95c94
	goto loc_82C95C94;
loc_82C95C5C:
	// addi r8,r31,1536
	ctx.r8.s64 = ctx.r31.s64 + 1536;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r4,r7,27
	ctx.r4.u64 = ctx.r7.u32 & 0x1F;
	// lbzx r3,r11,r8
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r8.u32);
	// slw r8,r30,r4
	ctx.r8.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r30.u32 << (ctx.r4.u8 & 0x3F));
	// rotlwi r11,r3,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r3.u32, 3);
	// add r7,r11,r9
	ctx.r7.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r4,r7,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r4,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r31.u32);
	// and r11,r3,r8
	ctx.r11.u64 = ctx.r3.u64 & ctx.r8.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c95ef8
	if (ctx.cr6.eq) goto loc_82C95EF8;
loc_82C95C90:
	// li r8,19
	ctx.r8.s64 = 19;
loc_82C95C94:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c95d8c
	if (ctx.cr6.eq) goto loc_82C95D8C;
loc_82C95CA0:
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c95cbc
	if (!ctx.cr6.eq) goto loc_82C95CBC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95cc8
	goto loc_82C95CC8;
loc_82C95CBC:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95CC8;
	sub_82C8DAE8(ctx, base);
loc_82C95CC8:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 31, ctx.xer);
	// bgt cr6,0x82c95ef8
	if (ctx.cr6.gt) goto loc_82C95EF8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,23788
	ctx.r12.s64 = ctx.r12.s64 + 23788;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C95BD4;
	case 1:
		goto loc_82C95BEC;
	case 2:
		goto loc_82C95C04;
	case 3:
		goto loc_82C95EF8;
	case 4:
		goto loc_82C95E94;
	case 5:
		goto loc_82C95E94;
	case 6:
		goto loc_82C95E94;
	case 7:
		goto loc_82C95EF8;
	case 8:
		goto loc_82C95EF8;
	case 9:
		goto loc_82C95EF8;
	case 10:
		goto loc_82C95EDC;
	case 11:
		goto loc_82C95EF8;
	case 12:
		goto loc_82C95EF8;
	case 13:
		goto loc_82C95EF8;
	case 14:
		goto loc_82C95EF8;
	case 15:
		goto loc_82C95E94;
	case 16:
		goto loc_82C95E94;
	case 17:
		goto loc_82C95E8C;
	case 18:
		goto loc_82C95D6C;
	case 19:
		goto loc_82C95E8C;
	case 20:
		goto loc_82C95E8C;
	case 21:
		goto loc_82C95E8C;
	case 22:
		goto loc_82C95E8C;
	case 23:
		goto loc_82C95EF8;
	case 24:
		goto loc_82C95E54;
	case 25:
		goto loc_82C95E94;
	case 26:
		goto loc_82C95EF8;
	case 27:
		goto loc_82C95E94;
	case 28:
		goto loc_82C95EC0;
	case 29:
		goto loc_82C95EA4;
	case 30:
		goto loc_82C95E94;
	case 31:
		goto loc_82C95E94;
	default:
		__builtin_unreachable();
	}
	// lwz r22,23508(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23508);
	// lwz r22,23532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23532);
	// lwz r22,23556(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23556);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24284);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,23916(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23916);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24148);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24312(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24312);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24256(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24256);
	// lwz r22,24228(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24228);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
	// lwz r22,24212(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24212);
loc_82C95D6C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmpwi cr6,r8,18
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 18, ctx.xer);
	// beq cr6,0x82c95d98
	if (ctx.cr6.eq) goto loc_82C95D98;
	// cmpwi cr6,r8,41
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 41, ctx.xer);
	// bne cr6,0x82c95d84
	if (!ctx.cr6.eq) goto loc_82C95D84;
loc_82C95D80:
	// li r8,19
	ctx.r8.s64 = 19;
loc_82C95D84:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c95ca0
	if (!ctx.cr6.eq) goto loc_82C95CA0;
loc_82C95D8C:
	// neg r3,r8
	ctx.r3.s64 = -ctx.r8.s64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95D98:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c956fc
	if (ctx.cr6.eq) goto loc_82C956FC;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// li r8,41
	ctx.r8.s64 = 41;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82c95dc0
	if (!ctx.cr6.eq) goto loc_82C95DC0;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95dcc
	goto loc_82C95DCC;
loc_82C95DC0:
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95DCC;
	sub_82C8DAE8(ctx, base);
loc_82C95DCC:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c95d80
	if (ctx.cr6.gt) goto loc_82C95D80;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,24048
	ctx.r12.s64 = ctx.r12.s64 + 24048;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C95BD4;
	case 1:
		goto loc_82C95BEC;
	case 2:
		goto loc_82C95C04;
	case 3:
		goto loc_82C95D80;
	case 4:
		goto loc_82C95D80;
	case 5:
		goto loc_82C95D80;
	case 6:
		goto loc_82C95D80;
	case 7:
		goto loc_82C95D80;
	case 8:
		goto loc_82C95D80;
	case 9:
		goto loc_82C95D80;
	case 10:
		goto loc_82C95D80;
	case 11:
		goto loc_82C95D80;
	case 12:
		goto loc_82C95D80;
	case 13:
		goto loc_82C95D80;
	case 14:
		goto loc_82C95D80;
	case 15:
		goto loc_82C95D80;
	case 16:
		goto loc_82C95D80;
	case 17:
		goto loc_82C95E8C;
	case 18:
		goto loc_82C95D80;
	case 19:
		goto loc_82C95E8C;
	case 20:
		goto loc_82C95E8C;
	case 21:
		goto loc_82C95E8C;
	case 22:
		goto loc_82C95E8C;
	case 23:
		goto loc_82C95D80;
	case 24:
		goto loc_82C95E54;
	default:
		__builtin_unreachable();
	}
	// lwz r22,23508(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23508);
	// lwz r22,23532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23532);
	// lwz r22,23556(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23556);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,24204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24204);
	// lwz r22,23936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23936);
	// lwz r22,24148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24148);
loc_82C95E54:
	// clrlwi r11,r9,24
	ctx.r11.u64 = ctx.r9.u32 & 0xFF;
	// lbz r7,1(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r4,r31,1536
	ctx.r4.s64 = ctx.r31.s64 + 1536;
	// clrlwi r3,r7,27
	ctx.r3.u64 = ctx.r7.u32 & 0x1F;
	// rlwinm r9,r7,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// slw r7,r30,r3
	ctx.r7.u64 = ctx.r3.u8 & 0x20 ? 0 : (ctx.r30.u32 << (ctx.r3.u8 & 0x3F));
	// lbzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r4.u32);
	// rotlwi r11,r4,3
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r11,r9
	ctx.r3.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r31
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	// and r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 & ctx.r7.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c95ef8
	if (ctx.cr6.eq) goto loc_82C95EF8;
loc_82C95E8C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c95d84
	goto loc_82C95D84;
loc_82C95E94:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95EA4:
	// cmpwi cr6,r8,19
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 19, ctx.xer);
	// beq cr6,0x82c95ef8
	if (ctx.cr6.eq) goto loc_82C95EF8;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,32
	ctx.r3.s64 = 32;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95EC0:
	// cmpwi cr6,r8,19
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 19, ctx.xer);
	// beq cr6,0x82c95ef8
	if (ctx.cr6.eq) goto loc_82C95EF8;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,31
	ctx.r3.s64 = 31;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95EDC:
	// cmpwi cr6,r8,19
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 19, ctx.xer);
	// beq cr6,0x82c95ef8
	if (ctx.cr6.eq) goto loc_82C95EF8;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,30
	ctx.r3.s64 = 30;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C95EF8:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
}

__attribute__((alias("__imp__sub_82C95F08"))) PPC_WEAK_FUNC(sub_82C95F08);
PPC_FUNC_IMPL(__imp__sub_82C95F08) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c95f38
	if (!ctx.cr6.eq) goto loc_82C95F38;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C95F38:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C95F3C:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c95f58
	if (!ctx.cr6.eq) goto loc_82C95F58;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c95f60
	goto loc_82C95F60;
loc_82C95F58:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C95F60;
	sub_82C8DAE8(ctx, base);
loc_82C95F60:
	// addi r11,r3,-2
	ctx.r11.s64 = ctx.r3.s64 + -2;
	// cmplwi cr6,r11,19
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 19, ctx.xer);
	// bgt cr6,0x82c95fe4
	if (ctx.cr6.gt) goto loc_82C95FE4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,24452
	ctx.r12.s64 = ctx.r12.s64 + 24452;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9602C;
	case 1:
		goto loc_82C96008;
	case 2:
		goto loc_82C95FE4;
	case 3:
		goto loc_82C95FE4;
	case 4:
		goto loc_82C95FD4;
	case 5:
		goto loc_82C95FDC;
	case 6:
		goto loc_82C95FE4;
	case 7:
		goto loc_82C96068;
	case 8:
		goto loc_82C96044;
	case 9:
		goto loc_82C95FE4;
	case 10:
		goto loc_82C95FE4;
	case 11:
		goto loc_82C95FE4;
	case 12:
		goto loc_82C95FE4;
	case 13:
		goto loc_82C95FE4;
	case 14:
		goto loc_82C95FE4;
	case 15:
		goto loc_82C95FE4;
	case 16:
		goto loc_82C95FE4;
	case 17:
		goto loc_82C95FE4;
	case 18:
		goto loc_82C95FE4;
	case 19:
		goto loc_82C960D8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,24620(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24620);
	// lwz r22,24584(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24584);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24532);
	// lwz r22,24540(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24540);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24680(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24680);
	// lwz r22,24644(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24644);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24548);
	// lwz r22,24792(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24792);
loc_82C95FD4:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c95fe8
	goto loc_82C95FE8;
loc_82C95FDC:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c95fe8
	goto loc_82C95FE8;
loc_82C95FE4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C95FE8:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c95f3c
	if (!ctx.cr6.eq) goto loc_82C95F3C;
loc_82C95FF0:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96008:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c95ff0
	if (!ctx.cr6.eq) goto loc_82C95FF0;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c93d60
	ctx.lr = 0x82C9601C;
	sub_82C93D60(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C9602C:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96044:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c95ff0
	if (!ctx.cr6.eq) goto loc_82C95FF0;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96068:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c95ff0
	if (!ctx.cr6.eq) goto loc_82C95FF0;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c96090
	if (!ctx.cr6.eq) goto loc_82C96090;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96090:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c960ac
	if (!ctx.cr6.eq) goto loc_82C960AC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c960b4
	goto loc_82C960B4;
loc_82C960AC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C960B4;
	sub_82C8DAE8(ctx, base);
loc_82C960B4:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c960c0
	if (!ctx.cr6.eq) goto loc_82C960C0;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C960C0:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C960D8:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c95ff0
	if (!ctx.cr6.eq) goto loc_82C95FF0;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,39
	ctx.r3.s64 = 39;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C960FC"))) PPC_WEAK_FUNC(sub_82C960FC);
PPC_FUNC_IMPL(__imp__sub_82C960FC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C96100"))) PPC_WEAK_FUNC(sub_82C96100);
PPC_FUNC_IMPL(__imp__sub_82C96100) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c96130
	if (!ctx.cr6.eq) goto loc_82C96130;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96130:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C96134:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c96150
	if (!ctx.cr6.eq) goto loc_82C96150;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96158
	goto loc_82C96158;
loc_82C96150:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96158;
	sub_82C8DAE8(ctx, base);
loc_82C96158:
	// addi r11,r3,-3
	ctx.r11.s64 = ctx.r3.s64 + -3;
	// cmplwi cr6,r11,27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 27, ctx.xer);
	// bgt cr6,0x82c961fc
	if (ctx.cr6.gt) goto loc_82C961FC;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,24956
	ctx.r12.s64 = ctx.r12.s64 + 24956;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C96220;
	case 1:
		goto loc_82C961FC;
	case 2:
		goto loc_82C961FC;
	case 3:
		goto loc_82C961EC;
	case 4:
		goto loc_82C961F4;
	case 5:
		goto loc_82C961FC;
	case 6:
		goto loc_82C96298;
	case 7:
		goto loc_82C96274;
	case 8:
		goto loc_82C961FC;
	case 9:
		goto loc_82C961FC;
	case 10:
		goto loc_82C961FC;
	case 11:
		goto loc_82C961FC;
	case 12:
		goto loc_82C961FC;
	case 13:
		goto loc_82C961FC;
	case 14:
		goto loc_82C961FC;
	case 15:
		goto loc_82C961FC;
	case 16:
		goto loc_82C961FC;
	case 17:
		goto loc_82C961FC;
	case 18:
		goto loc_82C961FC;
	case 19:
		goto loc_82C961FC;
	case 20:
		goto loc_82C961FC;
	case 21:
		goto loc_82C961FC;
	case 22:
		goto loc_82C961FC;
	case 23:
		goto loc_82C961FC;
	case 24:
		goto loc_82C961FC;
	case 25:
		goto loc_82C961FC;
	case 26:
		goto loc_82C961FC;
	case 27:
		goto loc_82C96244;
	default:
		__builtin_unreachable();
	}
	// lwz r22,25120(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25120);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25068(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25068);
	// lwz r22,25076(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25076);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25240(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25240);
	// lwz r22,25204(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25204);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25084);
	// lwz r22,25156(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25156);
loc_82C961EC:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c96200
	goto loc_82C96200;
loc_82C961F4:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c96200
	goto loc_82C96200;
loc_82C961FC:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C96200:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c96134
	if (!ctx.cr6.eq) goto loc_82C96134;
loc_82C96208:
	// li r3,6
	ctx.r3.s64 = 6;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
loc_82C96210:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96220:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c96208
	if (!ctx.cr6.eq) goto loc_82C96208;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c93d60
	ctx.lr = 0x82C96234;
	sub_82C93D60(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96244:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c96208
	if (!ctx.cr6.eq) goto loc_82C96208;
	// addi r4,r10,2
	ctx.r4.s64 = ctx.r10.s64 + 2;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// bl 0x82c94f70
	ctx.lr = 0x82C96258;
	sub_82C94F70(ctx, base);
	// cmpwi cr6,r3,22
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 22, ctx.xer);
	// bne cr6,0x82c96210
	if (!ctx.cr6.eq) goto loc_82C96210;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96274:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c96208
	if (!ctx.cr6.eq) goto loc_82C96208;
	// addi r11,r10,2
	ctx.r11.s64 = ctx.r10.s64 + 2;
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96298:
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c96208
	if (!ctx.cr6.eq) goto loc_82C96208;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c962c0
	if (!ctx.cr6.eq) goto loc_82C962C0;
	// li r3,-3
	ctx.r3.s64 = -3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C962C0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c962dc
	if (!ctx.cr6.eq) goto loc_82C962DC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c962e4
	goto loc_82C962E4;
loc_82C962DC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C962E4;
	sub_82C8DAE8(ctx, base);
loc_82C962E4:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c962f0
	if (!ctx.cr6.eq) goto loc_82C962F0;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C962F0:
	// li r3,7
	ctx.r3.s64 = 7;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96308"))) PPC_WEAK_FUNC(sub_82C96308);
PPC_FUNC_IMPL(__imp__sub_82C96308) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// subf r11,r10,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r10.s64;
	// li r8,0
	ctx.r8.s64 = 0;
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82c96338
	if (ctx.cr6.eq) goto loc_82C96338;
	// rlwinm r11,r11,0,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C96338:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c963c4
	if (ctx.cr6.eq) goto loc_82C963C4;
	// subf r9,r10,r5
	ctx.r9.s64 = ctx.r5.s64 - ctx.r10.s64;
loc_82C96344:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c96360
	if (!ctx.cr6.eq) goto loc_82C96360;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96368
	goto loc_82C96368;
loc_82C96360:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96368;
	sub_82C8DAE8(ctx, base);
loc_82C96368:
	// cmplwi cr6,r3,8
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 8, ctx.xer);
	// bgt cr6,0x82c963b4
	if (ctx.cr6.gt) goto loc_82C963B4;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,25480
	ctx.r12.s64 = ctx.r12.s64 + 25480;
	// rlwinm r0,r3,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82C964D4;
	case 1:
		goto loc_82C964D4;
	case 2:
		goto loc_82C96400;
	case 3:
		goto loc_82C963B4;
	case 4:
		goto loc_82C96458;
	case 5:
		goto loc_82C963AC;
	case 6:
		goto loc_82C963D8;
	case 7:
		goto loc_82C963EC;
	case 8:
		goto loc_82C964D4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,25812(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25812);
	// lwz r22,25812(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25812);
	// lwz r22,25600(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25600);
	// lwz r22,25524(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25524);
	// lwz r22,25688(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25688);
	// lwz r22,25516(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25516);
	// lwz r22,25560(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25560);
	// lwz r22,25580(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25580);
	// lwz r22,25812(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25812);
loc_82C963AC:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// blt cr6,0x82c964c0
	if (ctx.cr6.lt) goto loc_82C964C0;
loc_82C963B4:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
loc_82C963BC:
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c96344
	if (!ctx.cr6.eq) goto loc_82C96344;
loc_82C963C4:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C963D8:
	// cmpwi cr6,r9,3
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 3, ctx.xer);
	// blt cr6,0x82c964c0
	if (ctx.cr6.lt) goto loc_82C964C0;
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// b 0x82c963bc
	goto loc_82C963BC;
loc_82C963EC:
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x82c964c0
	if (ctx.cr6.lt) goto loc_82C964C0;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// b 0x82c963bc
	goto loc_82C963BC;
loc_82C96400:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c963c4
	if (ctx.cr6.eq) goto loc_82C963C4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,33
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 33, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c963c4
	if (ctx.cr6.eq) goto loc_82C963C4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,91
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 91, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// b 0x82c963b4
	goto loc_82C963B4;
loc_82C96458:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c963c4
	if (ctx.cr6.eq) goto loc_82C963C4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,93
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 93, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c963c4
	if (ctx.cr6.eq) goto loc_82C963C4;
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// cmplwi cr6,r11,62
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 62, ctx.xer);
	// bne cr6,0x82c963bc
	if (!ctx.cr6.eq) goto loc_82C963BC;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r9,r9,-2
	ctx.r9.s64 = ctx.r9.s64 + -2;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x82c964ec
	if (ctx.cr6.eq) goto loc_82C964EC;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// b 0x82c963bc
	goto loc_82C963BC;
loc_82C964C0:
	// li r3,-2
	ctx.r3.s64 = -2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C964D4:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C964EC:
	// li r3,42
	ctx.r3.s64 = 42;
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96504"))) PPC_WEAK_FUNC(sub_82C96504);
PPC_FUNC_IMPL(__imp__sub_82C96504) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C96508"))) PPC_WEAK_FUNC(sub_82C96508);
PPC_FUNC_IMPL(__imp__sub_82C96508) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r10,r4,2
	ctx.r10.s64 = ctx.r4.s64 + 2;
	// addi r7,r5,-2
	ctx.r7.s64 = ctx.r5.s64 + -2;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r7
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x82c9664c
	if (ctx.cr6.eq) goto loc_82C9664C;
loc_82C96528:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// extsb r9,r3
	ctx.r9.s64 = ctx.r3.s8;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c96548
	if (!ctx.cr6.eq) goto loc_82C96548;
	// add r11,r4,r8
	ctx.r11.u64 = ctx.r4.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9654c
	goto loc_82C9654C;
loc_82C96548:
	// bl 0x82c8dae8
	ctx.lr = 0x82C9654C;
	sub_82C8DAE8(ctx, base);
loc_82C9654C:
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 26, ctx.xer);
	// bgt cr6,0x82c96624
	if (ctx.cr6.gt) goto loc_82C96624;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,25968
	ctx.r12.s64 = ctx.r12.s64 + 25968;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C96640;
	case 1:
		goto loc_82C96640;
	case 2:
		goto loc_82C96624;
	case 3:
		goto loc_82C96624;
	case 4:
		goto loc_82C96640;
	case 5:
		goto loc_82C96640;
	case 6:
		goto loc_82C96640;
	case 7:
		goto loc_82C96640;
	case 8:
		goto loc_82C96640;
	case 9:
		goto loc_82C96640;
	case 10:
		goto loc_82C96640;
	case 11:
		goto loc_82C96624;
	case 12:
		goto loc_82C965DC;
	case 13:
		goto loc_82C96608;
	case 14:
		goto loc_82C96640;
	case 15:
		goto loc_82C96640;
	case 16:
		goto loc_82C96640;
	case 17:
		goto loc_82C96608;
	case 18:
		goto loc_82C96640;
	case 19:
		goto loc_82C96624;
	case 20:
		goto loc_82C96624;
	case 21:
		goto loc_82C96640;
	case 22:
		goto loc_82C96640;
	case 23:
		goto loc_82C96640;
	case 24:
		goto loc_82C96640;
	case 25:
		goto loc_82C96640;
	case 26:
		goto loc_82C96640;
	default:
		__builtin_unreachable();
	}
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26076(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26076);
	// lwz r22,26120(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26120);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26120(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26120);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26148);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
	// lwz r22,26176(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26176);
loc_82C965DC:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c96640
	if (!ctx.cr6.eq) goto loc_82C96640;
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 9, ctx.xer);
	// bne cr6,0x82c96640
	if (!ctx.cr6.eq) goto loc_82C96640;
loc_82C965F0:
	// stw r10,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r10.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96608:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// beq cr6,0x82c96618
	if (ctx.cr6.eq) goto loc_82C96618;
	// li r11,-1
	ctx.r11.s64 = -1;
loc_82C96618:
	// rlwinm r11,r11,0,0,24
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c96640
	if (ctx.cr6.eq) goto loc_82C96640;
loc_82C96624:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c965f0
	if (!ctx.cr6.eq) goto loc_82C965F0;
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,36
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 36, ctx.xer);
	// beq cr6,0x82c96640
	if (ctx.cr6.eq) goto loc_82C96640;
	// cmpwi cr6,r11,64
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 64, ctx.xer);
	// bne cr6,0x82c965f0
	if (!ctx.cr6.eq) goto loc_82C965F0;
loc_82C96640:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplw cr6,r10,r7
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, ctx.xer);
	// bne cr6,0x82c96528
	if (!ctx.cr6.eq) goto loc_82C96528;
loc_82C9664C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96660"))) PPC_WEAK_FUNC(sub_82C96660);
PPC_FUNC_IMPL(__imp__sub_82C96660) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C96668;
	sub_82CA2BE4(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r27,0
	ctx.r27.s64 = 0;
	// addi r8,r4,2
	ctx.r8.s64 = ctx.r4.s64 + 2;
	// li r29,1
	ctx.r29.s64 = 1;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// mr r30,r27
	ctx.r30.u64 = ctx.r27.u64;
	// addi r31,r8,2
	ctx.r31.s64 = ctx.r8.s64 + 2;
loc_82C9668C:
	// lbz r3,0(r8)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// lbz r4,1(r8)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// extsb r10,r3
	ctx.r10.s64 = ctx.r3.s8;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c966ac
	if (!ctx.cr6.eq) goto loc_82C966AC;
	// add r11,r4,r28
	ctx.r11.u64 = ctx.r4.u64 + ctx.r28.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c966b0
	goto loc_82C966B0;
loc_82C966AC:
	// bl 0x82c8dae8
	ctx.lr = 0x82C966B0;
	sub_82C8DAE8(ctx, base);
loc_82C966B0:
	// addi r11,r3,-3
	ctx.r11.s64 = ctx.r3.s64 + -3;
	// cmplwi cr6,r11,26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 26, ctx.xer);
	// bgt cr6,0x82c96958
	if (ctx.cr6.gt) goto loc_82C96958;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,26324
	ctx.r12.s64 = ctx.r12.s64 + 26324;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C96938;
	case 1:
		goto loc_82C96958;
	case 2:
		goto loc_82C96740;
	case 3:
		goto loc_82C96768;
	case 4:
		goto loc_82C96798;
	case 5:
		goto loc_82C96958;
	case 6:
		goto loc_82C96918;
	case 7:
		goto loc_82C96918;
	case 8:
		goto loc_82C96950;
	case 9:
		goto loc_82C967C8;
	case 10:
		goto loc_82C9681C;
	case 11:
		goto loc_82C96958;
	case 12:
		goto loc_82C96958;
	case 13:
		goto loc_82C96958;
	case 14:
		goto loc_82C96950;
	case 15:
		goto loc_82C96958;
	case 16:
		goto loc_82C96958;
	case 17:
		goto loc_82C96958;
	case 18:
		goto loc_82C96870;
	case 19:
		goto loc_82C96740;
	case 20:
		goto loc_82C96958;
	case 21:
		goto loc_82C96740;
	case 22:
		goto loc_82C96958;
	case 23:
		goto loc_82C96958;
	case 24:
		goto loc_82C96958;
	case 25:
		goto loc_82C96958;
	case 26:
		goto loc_82C96740;
	default:
		__builtin_unreachable();
	}
	// lwz r22,26936(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26936);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26432);
	// lwz r22,26472(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26472);
	// lwz r22,26520(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26520);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26904(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26904);
	// lwz r22,26904(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26904);
	// lwz r22,26960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26960);
	// lwz r22,26568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26568);
	// lwz r22,26652(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26652);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26960);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26736(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26736);
	// lwz r22,26432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26432);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26432);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26968);
	// lwz r22,26432(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26432);
loc_82C96740:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c96958
	if (!ctx.cr6.eq) goto loc_82C96958;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c96758
	if (!ctx.cr6.lt) goto loc_82C96758;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r29.u8);
loc_82C96758:
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96768:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c96784
	if (!ctx.cr6.eq) goto loc_82C96784;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c96780
	if (!ctx.cr6.lt) goto loc_82C96780;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r29.u8);
loc_82C96780:
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
loc_82C96784:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96798:
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c967b4
	if (!ctx.cr6.eq) goto loc_82C967B4;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c967b0
	if (!ctx.cr6.lt) goto loc_82C967B0;
	// stw r8,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r8.u32);
	// stb r29,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r29.u8);
loc_82C967B0:
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
loc_82C967B4:
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C967C8:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// beq cr6,0x82c967f0
	if (ctx.cr6.eq) goto loc_82C967F0;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c967dc
	if (!ctx.cr6.lt) goto loc_82C967DC;
	// stw r31,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r31.u32);
loc_82C967DC:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r30,12
	ctx.r30.s64 = 12;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C967F0:
	// cmpwi cr6,r30,12
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 12, ctx.xer);
	// bne cr6,0x82c96958
	if (!ctx.cr6.eq) goto loc_82C96958;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c96808
	if (!ctx.cr6.lt) goto loc_82C96808;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
loc_82C96808:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C9681C:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// beq cr6,0x82c96844
	if (ctx.cr6.eq) goto loc_82C96844;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c96830
	if (!ctx.cr6.lt) goto loc_82C96830;
	// stw r31,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r31.u32);
loc_82C96830:
	// li r9,2
	ctx.r9.s64 = 2;
	// li r30,13
	ctx.r30.s64 = 13;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96844:
	// cmpwi cr6,r30,13
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 13, ctx.xer);
	// bne cr6,0x82c96958
	if (!ctx.cr6.eq) goto loc_82C96958;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c96808
	if (!ctx.cr6.lt) goto loc_82C96808;
	// stw r8,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r8.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,16
	ctx.r6.s64 = ctx.r6.s64 + 16;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96870:
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82c96888
	if (!ctx.cr6.eq) goto loc_82C96888;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96888:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c96958
	if (!ctx.cr6.eq) goto loc_82C96958;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c96958
	if (!ctx.cr6.lt) goto loc_82C96958;
	// lbz r11,12(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c96958
	if (ctx.cr6.eq) goto loc_82C96958;
	// lwz r11,4(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82c96908
	if (ctx.cr6.eq) goto loc_82C96908;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c96908
	if (!ctx.cr6.eq) goto loc_82C96908;
	// extsb r11,r4
	ctx.r11.s64 = ctx.r4.s8;
	// cmpwi cr6,r11,32
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 32, ctx.xer);
	// bne cr6,0x82c96908
	if (!ctx.cr6.eq) goto loc_82C96908;
	// lbz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r31.u32 + 0);
	// extsb r11,r3
	ctx.r11.s64 = ctx.r3.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c968f8
	if (!ctx.cr6.eq) goto loc_82C968F8;
	// lbz r10,3(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 3);
	// cmplwi cr6,r10,32
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 32, ctx.xer);
	// beq cr6,0x82c96908
	if (ctx.cr6.eq) goto loc_82C96908;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c968f8
	if (!ctx.cr6.eq) goto loc_82C968F8;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// add r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 + ctx.r28.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96900
	goto loc_82C96900;
loc_82C968F8:
	// lbz r4,3(r8)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r8.u32 + 3);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96900;
	sub_82C8DAE8(ctx, base);
loc_82C96900:
	// cmpw cr6,r3,r30
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r30.s32, ctx.xer);
	// bne cr6,0x82c96958
	if (!ctx.cr6.eq) goto loc_82C96958;
loc_82C96908:
	// stb r27,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r27.u8);
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96918:
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82c96930
	if (!ctx.cr6.eq) goto loc_82C96930;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96930:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c96958
	if (!ctx.cr6.eq) goto loc_82C96958;
loc_82C96938:
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bge cr6,0x82c96958
	if (!ctx.cr6.lt) goto loc_82C96958;
	// stb r27,12(r6)
	PPC_STORE_U8(ctx.r6.u32 + 12, ctx.r27.u8);
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96950:
	// cmpwi cr6,r9,2
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 2, ctx.xer);
	// bne cr6,0x82c96964
	if (!ctx.cr6.eq) goto loc_82C96964;
loc_82C96958:
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// b 0x82c9668c
	goto loc_82C9668C;
loc_82C96964:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
}

__attribute__((alias("__imp__sub_82C96970"))) PPC_WEAK_FUNC(sub_82C96970);
PPC_FUNC_IMPL(__imp__sub_82C96970) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// subf r11,r4,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// srawi r10,r11,1
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x1) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 1;
	// addze r11,r10
	temp.s64 = ctx.r10.s64 + ctx.xer.ca;
	ctx.xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r11.s64 = temp.s64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82c96abc
	if (ctx.cr6.eq) goto loc_82C96ABC;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82c96a68
	if (ctx.cr6.eq) goto loc_82C96A68;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,97
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 97, ctx.xer);
	// beq cr6,0x82c96a10
	if (ctx.cr6.eq) goto loc_82C96A10;
	// cmpwi cr6,r11,113
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 113, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,117
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 117, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,111
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 111, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,3(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r11,116
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 116, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// li r3,34
	ctx.r3.s64 = 34;
	// blr 
	return;
loc_82C96A10:
	// lbz r10,2(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,112
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 112, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,111
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 111, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,3(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r11,115
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 115, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// li r3,39
	ctx.r3.s64 = 39;
	// blr 
	return;
loc_82C96A68:
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,97
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 97, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 1);
	// cmplwi cr6,r10,109
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 109, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,3(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 3);
	// cmplwi cr6,r11,112
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 112, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// li r3,38
	ctx.r3.s64 = 38;
	// blr 
	return;
loc_82C96ABC:
	// lbz r11,2(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,3(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// cmplwi cr6,r11,116
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 116, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// lbz r11,1(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,103
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 103, ctx.xer);
	// beq cr6,0x82c96b00
	if (ctx.cr6.eq) goto loc_82C96B00;
	// cmpwi cr6,r11,108
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 108, ctx.xer);
	// bne cr6,0x82c96b08
	if (!ctx.cr6.eq) goto loc_82C96B08;
	// li r3,60
	ctx.r3.s64 = 60;
	// blr 
	return;
loc_82C96B00:
	// li r3,62
	ctx.r3.s64 = 62;
	// blr 
	return;
loc_82C96B08:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96B10"))) PPC_WEAK_FUNC(sub_82C96B10);
PPC_FUNC_IMPL(__imp__sub_82C96B10) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C96B24:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r9,r10,1
	ctx.r9.s64 = ctx.r10.s64 + 1;
	// extsb r8,r3
	ctx.r8.s64 = ctx.r3.s8;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne cr6,0x82c96b48
	if (!ctx.cr6.eq) goto loc_82C96B48;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96b50
	goto loc_82C96B50;
loc_82C96B48:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96B50;
	sub_82C8DAE8(ctx, base);
loc_82C96B50:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c96c8c
	if (ctx.cr6.gt) goto loc_82C96C8C;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,27508
	ctx.r12.s64 = ctx.r12.s64 + 27508;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C96C08;
	case 1:
		goto loc_82C96BF0;
	case 2:
		goto loc_82C96BD8;
	case 3:
		goto loc_82C96C8C;
	case 4:
		goto loc_82C96C8C;
	case 5:
		goto loc_82C96C8C;
	case 6:
		goto loc_82C96C8C;
	case 7:
		goto loc_82C96C8C;
	case 8:
		goto loc_82C96C8C;
	case 9:
		goto loc_82C96C8C;
	case 10:
		goto loc_82C96C8C;
	case 11:
		goto loc_82C96C8C;
	case 12:
		goto loc_82C96C8C;
	case 13:
		goto loc_82C96C8C;
	case 14:
		goto loc_82C96C8C;
	case 15:
		goto loc_82C96C8C;
	case 16:
		goto loc_82C96C8C;
	case 17:
		goto loc_82C96C4C;
	case 18:
		goto loc_82C96C4C;
	case 19:
		goto loc_82C96C4C;
	case 20:
		goto loc_82C96C4C;
	case 21:
		goto loc_82C96C4C;
	case 22:
		goto loc_82C96C4C;
	case 23:
		goto loc_82C96C8C;
	case 24:
		goto loc_82C96C4C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,27656(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27656);
	// lwz r22,27632(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27632);
	// lwz r22,27608(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27608);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27724(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27724(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
	// lwz r22,27788(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27788);
	// lwz r22,27724(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27724);
loc_82C96BD8:
	// lbz r11,0(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
	// cmpw cr6,r8,r9
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r9.s32, ctx.xer);
	// bne cr6,0x82c96c38
	if (!ctx.cr6.eq) goto loc_82C96C38;
loc_82C96BF0:
	// lbz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lbz r9,0(r5)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x82c96c38
	if (!ctx.cr6.eq) goto loc_82C96C38;
loc_82C96C08:
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r11,r10,1
	ctx.r11.s64 = ctx.r10.s64 + 1;
	// lbz r6,0(r5)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r9,r5,1
	ctx.r9.s64 = ctx.r5.s64 + 1;
	// cmplw cr6,r8,r6
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82c96c38
	if (!ctx.cr6.eq) goto loc_82C96C38;
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// lbz r6,0(r9)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r5,r9,1
	ctx.r5.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r8,r6
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, ctx.xer);
	// beq cr6,0x82c96b24
	if (ctx.cr6.eq) goto loc_82C96B24;
loc_82C96C38:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96C4C:
	// lbz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// addi r11,r5,1
	ctx.r11.s64 = ctx.r5.s64 + 1;
	// extsb r6,r10
	ctx.r6.s64 = ctx.r10.s8;
	// cmpw cr6,r6,r8
	ctx.cr6.compare<int32_t>(ctx.r6.s32, ctx.r8.s32, ctx.xer);
	// bne cr6,0x82c96c38
	if (!ctx.cr6.eq) goto loc_82C96C38;
	// lbz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// addi r10,r9,1
	ctx.r10.s64 = ctx.r9.s64 + 1;
	// lbz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r5,r11,1
	ctx.r5.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r6,r8
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x82c96b24
	if (ctx.cr6.eq) goto loc_82C96B24;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96C8C:
	// lbz r3,0(r5)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r5.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c96ca8
	if (!ctx.cr6.eq) goto loc_82C96CA8;
	// lbz r11,1(r5)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// add r11,r11,r7
	ctx.r11.u64 = ctx.r11.u64 + ctx.r7.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96cb0
	goto loc_82C96CB0;
loc_82C96CA8:
	// lbz r4,1(r5)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r5.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96CB0;
	sub_82C8DAE8(ctx, base);
loc_82C96CB0:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c96d38
	if (ctx.cr6.gt) goto loc_82C96D38;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,27860
	ctx.r12.s64 = ctx.r12.s64 + 27860;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C96C38;
	case 1:
		goto loc_82C96C38;
	case 2:
		goto loc_82C96C38;
	case 3:
		goto loc_82C96D38;
	case 4:
		goto loc_82C96D38;
	case 5:
		goto loc_82C96D38;
	case 6:
		goto loc_82C96D38;
	case 7:
		goto loc_82C96D38;
	case 8:
		goto loc_82C96D38;
	case 9:
		goto loc_82C96D38;
	case 10:
		goto loc_82C96D38;
	case 11:
		goto loc_82C96D38;
	case 12:
		goto loc_82C96D38;
	case 13:
		goto loc_82C96D38;
	case 14:
		goto loc_82C96D38;
	case 15:
		goto loc_82C96D38;
	case 16:
		goto loc_82C96D38;
	case 17:
		goto loc_82C96C38;
	case 18:
		goto loc_82C96C38;
	case 19:
		goto loc_82C96C38;
	case 20:
		goto loc_82C96C38;
	case 21:
		goto loc_82C96C38;
	case 22:
		goto loc_82C96C38;
	case 23:
		goto loc_82C96D38;
	case 24:
		goto loc_82C96C38;
	default:
		__builtin_unreachable();
	}
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
	// lwz r22,27960(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	// lwz r22,27704(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27704);
loc_82C96D38:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96D4C"))) PPC_WEAK_FUNC(sub_82C96D4C);
PPC_FUNC_IMPL(__imp__sub_82C96D4C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C96D50"))) PPC_WEAK_FUNC(sub_82C96D50);
PPC_FUNC_IMPL(__imp__sub_82C96D50) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c96d9c
	if (ctx.cr6.eq) goto loc_82C96D9C;
loc_82C96D60:
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c96dac
	if (ctx.cr6.eq) goto loc_82C96DAC;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c96dac
	if (!ctx.cr6.eq) goto loc_82C96DAC;
	// lbz r10,1(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// cmpw cr6,r9,r11
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82c96dac
	if (!ctx.cr6.eq) goto loc_82C96DAC;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r4,r4,2
	ctx.r4.s64 = ctx.r4.s64 + 2;
	// lbz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c96d60
	if (!ctx.cr6.eq) goto loc_82C96D60;
loc_82C96D9C:
	// subf r11,r4,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r4.s64;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r3,r10,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// blr 
	return;
loc_82C96DAC:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96DB4"))) PPC_WEAK_FUNC(sub_82C96DB4);
PPC_FUNC_IMPL(__imp__sub_82C96DB4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C96DB8"))) PPC_WEAK_FUNC(sub_82C96DB8);
PPC_FUNC_IMPL(__imp__sub_82C96DB8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
loc_82C96DD0:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c96dec
	if (!ctx.cr6.eq) goto loc_82C96DEC;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96df4
	goto loc_82C96DF4;
loc_82C96DEC:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96DF4;
	sub_82C8DAE8(ctx, base);
loc_82C96DF4:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 24, ctx.xer);
	// bgt cr6,0x82c96e94
	if (ctx.cr6.gt) goto loc_82C96E94;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,28184
	ctx.r12.s64 = ctx.r12.s64 + 28184;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C96E7C;
	case 1:
		goto loc_82C96E84;
	case 2:
		goto loc_82C96E8C;
	case 3:
		goto loc_82C96E94;
	case 4:
		goto loc_82C96E94;
	case 5:
		goto loc_82C96E94;
	case 6:
		goto loc_82C96E94;
	case 7:
		goto loc_82C96E94;
	case 8:
		goto loc_82C96E94;
	case 9:
		goto loc_82C96E94;
	case 10:
		goto loc_82C96E94;
	case 11:
		goto loc_82C96E94;
	case 12:
		goto loc_82C96E94;
	case 13:
		goto loc_82C96E94;
	case 14:
		goto loc_82C96E94;
	case 15:
		goto loc_82C96E94;
	case 16:
		goto loc_82C96E94;
	case 17:
		goto loc_82C96E7C;
	case 18:
		goto loc_82C96E7C;
	case 19:
		goto loc_82C96E7C;
	case 20:
		goto loc_82C96E7C;
	case 21:
		goto loc_82C96E7C;
	case 22:
		goto loc_82C96E7C;
	case 23:
		goto loc_82C96E94;
	case 24:
		goto loc_82C96E7C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28292(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28292);
	// lwz r22,28300(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28300);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
	// lwz r22,28308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28308);
	// lwz r22,28284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28284);
loc_82C96E7C:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c96dd0
	goto loc_82C96DD0;
loc_82C96E84:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c96dd0
	goto loc_82C96DD0;
loc_82C96E8C:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c96dd0
	goto loc_82C96DD0;
loc_82C96E94:
	// subf r3,r8,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r8.s64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96EA8"))) PPC_WEAK_FUNC(sub_82C96EA8);
PPC_FUNC_IMPL(__imp__sub_82C96EA8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_82C96EBC:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c96ed8
	if (!ctx.cr6.eq) goto loc_82C96ED8;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96ee0
	goto loc_82C96EE0;
loc_82C96ED8:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96EE0;
	sub_82C8DAE8(ctx, base);
loc_82C96EE0:
	// cmpwi cr6,r3,9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 9, ctx.xer);
	// blt cr6,0x82c96f00
	if (ctx.cr6.lt) goto loc_82C96F00;
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// ble cr6,0x82c96ef8
	if (!ctx.cr6.gt) goto loc_82C96EF8;
	// cmpwi cr6,r3,21
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 21, ctx.xer);
	// bne cr6,0x82c96f00
	if (!ctx.cr6.eq) goto loc_82C96F00;
loc_82C96EF8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// b 0x82c96ebc
	goto loc_82C96EBC;
loc_82C96F00:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C96F14"))) PPC_WEAK_FUNC(sub_82C96F14);
PPC_FUNC_IMPL(__imp__sub_82C96F14) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C96F18"))) PPC_WEAK_FUNC(sub_82C96F18);
PPC_FUNC_IMPL(__imp__sub_82C96F18) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c96fd0
	if (ctx.cr6.eq) goto loc_82C96FD0;
	// li r9,-1
	ctx.r9.s64 = -1;
loc_82C96F38:
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c96f54
	if (!ctx.cr6.eq) goto loc_82C96F54;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c96f5c
	goto loc_82C96F5C;
loc_82C96F54:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C96F5C;
	sub_82C8DAE8(ctx, base);
loc_82C96F5C:
	// addi r11,r3,-5
	ctx.r11.s64 = ctx.r3.s64 + -5;
	// cmplwi cr6,r11,5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 5, ctx.xer);
	// bgt cr6,0x82c96fb8
	if (ctx.cr6.gt) goto loc_82C96FB8;
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,28544
	ctx.r12.s64 = ctx.r12.s64 + 28544;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C96FB8;
	case 1:
		goto loc_82C96F98;
	case 2:
		goto loc_82C96FA0;
	case 3:
		goto loc_82C96FB8;
	case 4:
		goto loc_82C96FE0;
	case 5:
		goto loc_82C96FA8;
	default:
		__builtin_unreachable();
	}
	// lwz r22,28600(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28600);
	// lwz r22,28568(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28568);
	// lwz r22,28576(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28576);
	// lwz r22,28600(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28600);
	// lwz r22,28640(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28640);
	// lwz r22,28584(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28584);
loc_82C96F98:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// b 0x82c96fbc
	goto loc_82C96FBC;
loc_82C96FA0:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// b 0x82c96fbc
	goto loc_82C96FBC;
loc_82C96FA8:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// stw r9,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r9.u32);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
loc_82C96FB8:
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C96FBC:
	// lwz r11,4(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r11.u32);
	// bne cr6,0x82c96f38
	if (!ctx.cr6.eq) goto loc_82C96F38;
loc_82C96FD0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C96FE0:
	// lwz r11,0(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// beq cr6,0x82c97028
	if (ctx.cr6.eq) goto loc_82C97028;
	// lbz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c97014
	if (!ctx.cr6.eq) goto loc_82C97014;
	// lbz r11,1(r10)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lbz r3,76(r11)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r11.u32 + 76);
	// b 0x82c9701c
	goto loc_82C9701C;
loc_82C97014:
	// lbz r4,1(r10)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// bl 0x82c8dae8
	ctx.lr = 0x82C9701C;
	sub_82C8DAE8(ctx, base);
loc_82C9701C:
	// cmpwi cr6,r3,10
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 10, ctx.xer);
	// bne cr6,0x82c97028
	if (!ctx.cr6.eq) goto loc_82C97028;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
loc_82C97028:
	// stw r9,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r9.u32);
	// b 0x82c96fbc
	goto loc_82C96FBC;
}

__attribute__((alias("__imp__sub_82C97030"))) PPC_WEAK_FUNC(sub_82C97030);
PPC_FUNC_IMPL(__imp__sub_82C97030) {
	PPC_FUNC_PROLOGUE();
loc_82C97030:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// lbz r9,0(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// extsb r11,r10
	ctx.r11.s64 = ctx.r10.s8;
	// cmpwi cr6,r11,97
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 97, ctx.xer);
	// blt cr6,0x82c9705c
	if (ctx.cr6.lt) goto loc_82C9705C;
	// cmpwi cr6,r11,122
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 122, ctx.xer);
	// bgt cr6,0x82c9705c
	if (ctx.cr6.gt) goto loc_82C9705C;
	// addi r11,r11,-32
	ctx.r11.s64 = ctx.r11.s64 + -32;
	// extsb r10,r11
	ctx.r10.s64 = ctx.r11.s8;
loc_82C9705C:
	// extsb r11,r9
	ctx.r11.s64 = ctx.r9.s8;
	// cmpwi cr6,r11,97
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 97, ctx.xer);
	// blt cr6,0x82c97078
	if (ctx.cr6.lt) goto loc_82C97078;
	// cmpwi cr6,r11,122
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 122, ctx.xer);
	// bgt cr6,0x82c97078
	if (ctx.cr6.gt) goto loc_82C97078;
	// addi r11,r11,-32
	ctx.r11.s64 = ctx.r11.s64 + -32;
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
loc_82C97078:
	// extsb r11,r10
	ctx.r11.s64 = ctx.r10.s8;
	// extsb r10,r9
	ctx.r10.s64 = ctx.r9.s8;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bne cr6,0x82c97098
	if (!ctx.cr6.eq) goto loc_82C97098;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c97030
	if (!ctx.cr6.eq) goto loc_82C97030;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82C97098:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C970A0"))) PPC_WEAK_FUNC(sub_82C970A0);
PPC_FUNC_IMPL(__imp__sub_82C970A0) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r3,r11,-1976
	ctx.r3.s64 = ctx.r11.s64 + -1976;
	// b 0x82c8d750
	sub_82C8D750(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C970AC"))) PPC_WEAK_FUNC(sub_82C970AC);
PPC_FUNC_IMPL(__imp__sub_82C970AC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C970B0"))) PPC_WEAK_FUNC(sub_82C970B0);
PPC_FUNC_IMPL(__imp__sub_82C970B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// stw r4,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r4.u32);
	// lwz r10,60(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 60);
	// addi r7,r1,81
	ctx.r7.s64 = ctx.r1.s64 + 81;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C970E0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// cmplw cr6,r8,r9
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x82c97104
	if (!ctx.cr6.eq) goto loc_82C97104;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C97104:
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9711C"))) PPC_WEAK_FUNC(sub_82C9711C);
PPC_FUNC_IMPL(__imp__sub_82C9711C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C97120"))) PPC_WEAK_FUNC(sub_82C97120);
PPC_FUNC_IMPL(__imp__sub_82C97120) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r3,-9
	ctx.r11.s64 = ctx.r3.s64 + -9;
	// cmplwi cr6,r11,23
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 23, ctx.xer);
	// bgt cr6,0x82c971ac
	if (ctx.cr6.gt) {
		sub_82C971AC(ctx, base);
		return;
	}
	// lis r12,-32055
	ctx.r12.s64 = -2100756480;
	// addi r12,r12,28996
	ctx.r12.s64 = ctx.r12.s64 + 28996;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		// ERROR: 0x82C971A4
		return;
	case 1:
		// ERROR: 0x82C971A4
		return;
	case 2:
		// ERROR: 0x82C971AC
		return;
	case 3:
		// ERROR: 0x82C971AC
		return;
	case 4:
		// ERROR: 0x82C971A4
		return;
	case 5:
		// ERROR: 0x82C971AC
		return;
	case 6:
		// ERROR: 0x82C971AC
		return;
	case 7:
		// ERROR: 0x82C971AC
		return;
	case 8:
		// ERROR: 0x82C971AC
		return;
	case 9:
		// ERROR: 0x82C971AC
		return;
	case 10:
		// ERROR: 0x82C971AC
		return;
	case 11:
		// ERROR: 0x82C971AC
		return;
	case 12:
		// ERROR: 0x82C971AC
		return;
	case 13:
		// ERROR: 0x82C971AC
		return;
	case 14:
		// ERROR: 0x82C971AC
		return;
	case 15:
		// ERROR: 0x82C971AC
		return;
	case 16:
		// ERROR: 0x82C971AC
		return;
	case 17:
		// ERROR: 0x82C971AC
		return;
	case 18:
		// ERROR: 0x82C971AC
		return;
	case 19:
		// ERROR: 0x82C971AC
		return;
	case 20:
		// ERROR: 0x82C971AC
		return;
	case 21:
		// ERROR: 0x82C971AC
		return;
	case 22:
		// ERROR: 0x82C971AC
		return;
	case 23:
		// ERROR: 0x82C971A4
		return;
	default:
		__builtin_unreachable();
	}
}

__attribute__((alias("__imp__sub_82C97144"))) PPC_WEAK_FUNC(sub_82C97144);
PPC_FUNC_IMPL(__imp__sub_82C97144) {
	PPC_FUNC_PROLOGUE();
	// lwz r22,29092(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29092);
	// lwz r22,29092(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29092);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29092(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29092);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29100);
	// lwz r22,29092(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29092);
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C971AC"))) PPC_WEAK_FUNC(sub_82C971AC);
PPC_FUNC_IMPL(__imp__sub_82C971AC) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C971B4"))) PPC_WEAK_FUNC(sub_82C971B4);
PPC_FUNC_IMPL(__imp__sub_82C971B4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C971B8"))) PPC_WEAK_FUNC(sub_82C971B8);
PPC_FUNC_IMPL(__imp__sub_82C971B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bdc
	ctx.lr = 0x82C971C0;
	sub_82CA2BDC(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// mr r26,r8
	ctx.r26.u64 = ctx.r8.u64;
	// mr r25,r9
	ctx.r25.u64 = ctx.r9.u64;
	// cmplw cr6,r30,r29
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r29.u32, ctx.xer);
	// bne cr6,0x82c971fc
	if (!ctx.cr6.eq) goto loc_82C971FC;
loc_82C971E8:
	// li r11,0
	ctx.r11.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c2c
	// ERROR 82CA2C2C
	return;
loc_82C971FC:
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c970b0
	ctx.lr = 0x82C9720C;
	sub_82C970B0(ctx, base);
	// bl 0x82c97120
	ctx.lr = 0x82C97210;
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c97444
	if (ctx.cr6.eq) goto loc_82C97444;
loc_82C97218:
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lwz r9,60(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// addi r7,r1,81
	ctx.r7.s64 = ctx.r1.s64 + 81;
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// stw r30,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r30.u32);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C9724C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// cmplw cr6,r7,r8
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r8.u32, ctx.xer);
	// bne cr6,0x82c97264
	if (!ctx.cr6.eq) goto loc_82C97264;
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82c9726c
	goto loc_82C9726C;
loc_82C97264:
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
loc_82C9726C:
	// bl 0x82c97120
	ctx.lr = 0x82C97270;
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c97218
	if (!ctx.cr6.eq) goto loc_82C97218;
	// cmplw cr6,r30,r29
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x82c971e8
	if (ctx.cr6.eq) goto loc_82C971E8;
	// stw r30,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r30.u32);
loc_82C97284:
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lwz r10,60(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// stw r30,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r30.u32);
	// addi r7,r1,81
	ctx.r7.s64 = ctx.r1.s64 + 81;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C972B0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// cmplw cr6,r8,r9
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82c97444
	if (ctx.cr6.eq) goto loc_82C97444;
	// lbz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// extsb r3,r11
	ctx.r3.s64 = ctx.r11.s8;
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// beq cr6,0x82c97444
	if (ctx.cr6.eq) goto loc_82C97444;
	// cmpwi cr6,r3,61
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 61, ctx.xer);
	// beq cr6,0x82c972f0
	if (ctx.cr6.eq) goto loc_82C972F0;
	// bl 0x82c97120
	ctx.lr = 0x82C972DC;
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c972f8
	if (!ctx.cr6.eq) goto loc_82C972F8;
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// b 0x82c97284
	goto loc_82C97284;
loc_82C972F0:
	// stw r30,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r30.u32);
	// b 0x82c9732c
	goto loc_82C9732C;
loc_82C972F8:
	// stw r30,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r30.u32);
loc_82C972FC:
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82c970b0
	ctx.lr = 0x82C97314;
	sub_82C970B0(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// bl 0x82c97120
	ctx.lr = 0x82C9731C;
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c972fc
	if (!ctx.cr6.eq) goto loc_82C972FC;
	// cmpwi cr6,r10,61
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 61, ctx.xer);
	// bne cr6,0x82c97444
	if (!ctx.cr6.eq) goto loc_82C97444;
loc_82C9732C:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82c97444
	if (ctx.cr6.eq) goto loc_82C97444;
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82c970b0
	ctx.lr = 0x82C97350;
	sub_82C970B0(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// bl 0x82c97120
	ctx.lr = 0x82C97358;
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c97388
	if (ctx.cr6.eq) goto loc_82C97388;
loc_82C97360:
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82c970b0
	ctx.lr = 0x82C97378;
	sub_82C970B0(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// bl 0x82c97120
	ctx.lr = 0x82C97380;
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c97360
	if (!ctx.cr6.eq) goto loc_82C97360;
loc_82C97388:
	// cmpwi cr6,r10,34
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 34, ctx.xer);
	// beq cr6,0x82c97398
	if (ctx.cr6.eq) goto loc_82C97398;
	// cmpwi cr6,r10,39
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 39, ctx.xer);
	// bne cr6,0x82c97444
	if (!ctx.cr6.eq) goto loc_82C97444;
loc_82C97398:
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mr r28,r10
	ctx.r28.u64 = ctx.r10.u64;
	// stw r30,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r30.u32);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82c970b0
	ctx.lr = 0x82C973B8;
	sub_82C970B0(ctx, base);
	// extsb r28,r28
	ctx.r28.s64 = ctx.r28.s8;
	// cmpw cr6,r3,r28
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r28.s32, ctx.xer);
	// beq cr6,0x82c9742c
	if (ctx.cr6.eq) goto loc_82C9742C;
loc_82C973C4:
	// cmpwi cr6,r3,97
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 97, ctx.xer);
	// blt cr6,0x82c973d4
	if (ctx.cr6.lt) goto loc_82C973D4;
	// cmpwi cr6,r3,122
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 122, ctx.xer);
	// ble cr6,0x82c9740c
	if (!ctx.cr6.gt) goto loc_82C9740C;
loc_82C973D4:
	// cmpwi cr6,r3,65
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 65, ctx.xer);
	// blt cr6,0x82c973e4
	if (ctx.cr6.lt) goto loc_82C973E4;
	// cmpwi cr6,r3,90
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 90, ctx.xer);
	// ble cr6,0x82c9740c
	if (!ctx.cr6.gt) goto loc_82C9740C;
loc_82C973E4:
	// cmpwi cr6,r3,48
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 48, ctx.xer);
	// blt cr6,0x82c973f4
	if (ctx.cr6.lt) goto loc_82C973F4;
	// cmpwi cr6,r3,57
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 57, ctx.xer);
	// ble cr6,0x82c9740c
	if (!ctx.cr6.gt) goto loc_82C9740C;
loc_82C973F4:
	// cmpwi cr6,r3,46
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 46, ctx.xer);
	// beq cr6,0x82c9740c
	if (ctx.cr6.eq) goto loc_82C9740C;
	// cmpwi cr6,r3,45
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 45, ctx.xer);
	// beq cr6,0x82c9740c
	if (ctx.cr6.eq) goto loc_82C9740C;
	// cmpwi cr6,r3,95
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 95, ctx.xer);
	// bne cr6,0x82c97444
	if (!ctx.cr6.eq) goto loc_82C97444;
loc_82C9740C:
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// add r30,r11,r30
	ctx.r30.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82c970b0
	ctx.lr = 0x82C97424;
	sub_82C970B0(ctx, base);
	// cmpw cr6,r3,r28
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r28.s32, ctx.xer);
	// bne cr6,0x82c973c4
	if (!ctx.cr6.eq) goto loc_82C973C4;
loc_82C9742C:
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// li r3,1
	ctx.r3.s64 = 1;
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// stw r11,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r11.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c2c
	// ERROR 82CA2C2C
	return;
loc_82C97444:
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r30.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c2c
	// ERROR 82CA2C2C
	return;
}

__attribute__((alias("__imp__sub_82C97454"))) PPC_WEAK_FUNC(sub_82C97454);
PPC_FUNC_IMPL(__imp__sub_82C97454) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C97458"))) PPC_WEAK_FUNC(sub_82C97458);
PPC_FUNC_IMPL(__imp__sub_82C97458) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bd0
	ctx.lr = 0x82C97460;
	sub_82CA2BD0(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r24,0
	ctx.r24.s64 = 0;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// stw r24,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r24.u32);
	// mr r28,r10
	ctx.r28.u64 = ctx.r10.u64;
	// mr r22,r8
	ctx.r22.u64 = ctx.r8.u64;
	// stw r24,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r24.u32);
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// stw r24,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r24.u32);
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r29,r9
	ctx.r29.u64 = ctx.r9.u64;
	// addi r9,r1,236
	ctx.r9.s64 = ctx.r1.s64 + 236;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r11,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// subf r27,r8,r7
	ctx.r27.s64 = ctx.r7.s64 - ctx.r8.s64;
	// add r4,r11,r6
	ctx.r4.u64 = ctx.r11.u64 + ctx.r6.u64;
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// stw r4,236(r1)
	PPC_STORE_U32(ctx.r1.u32 + 236, ctx.r4.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// bl 0x82c971b8
	ctx.lr = 0x82C974C4;
	sub_82C971B8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c97778
	if (ctx.cr6.eq) goto loc_82C97778;
	// lwz r30,80(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c97778
	if (ctx.cr6.eq) goto loc_82C97778;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r26,r11,2860
	ctx.r26.s64 = ctx.r11.s64 + 2860;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r6,r26,-36
	ctx.r6.s64 = ctx.r26.s64 + -36;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C974FC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c9751c
	if (!ctx.cr6.eq) goto loc_82C9751C;
	// cmpwi cr6,r23,0
	ctx.cr6.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// bne cr6,0x82c97580
	if (!ctx.cr6.eq) goto loc_82C97580;
loc_82C9750C:
	// stw r30,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r30.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	// ERROR 82CA2C20
	return;
loc_82C9751C:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82c9752c
	if (ctx.cr6.eq) goto loc_82C9752C;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
loc_82C9752C:
	// lwz r4,236(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82c9753c
	if (ctx.cr6.eq) goto loc_82C9753C;
	// stw r4,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r4.u32);
loc_82C9753C:
	// addi r9,r1,236
	ctx.r9.s64 = ctx.r1.s64 + 236;
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c971b8
	ctx.lr = 0x82C97558;
	sub_82C971B8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c97778
	if (ctx.cr6.eq) goto loc_82C97778;
	// lwz r30,80(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82c97580
	if (!ctx.cr6.eq) goto loc_82C97580;
	// cmpwi cr6,r23,0
	ctx.cr6.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// bne cr6,0x82c97778
	if (!ctx.cr6.eq) goto loc_82C97778;
loc_82C97574:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	// ERROR 82CA2C20
	return;
loc_82C97580:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// addi r6,r26,-28
	ctx.r6.s64 = ctx.r26.s64 + -28;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9759C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c97664
	if (ctx.cr6.eq) goto loc_82C97664;
	// lwz r28,88(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82c970b0
	ctx.lr = 0x82C975B8;
	sub_82C970B0(ctx, base);
	// cmpwi cr6,r3,97
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 97, ctx.xer);
	// blt cr6,0x82c975c8
	if (ctx.cr6.lt) goto loc_82C975C8;
	// cmpwi cr6,r3,122
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 122, ctx.xer);
	// ble cr6,0x82c975d8
	if (!ctx.cr6.gt) goto loc_82C975D8;
loc_82C975C8:
	// cmpwi cr6,r3,65
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 65, ctx.xer);
	// blt cr6,0x82c97654
	if (ctx.cr6.lt) goto loc_82C97654;
	// cmpwi cr6,r3,90
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 90, ctx.xer);
	// bgt cr6,0x82c97654
	if (ctx.cr6.gt) goto loc_82C97654;
loc_82C975D8:
	// lwz r11,276(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c975e8
	if (ctx.cr6.eq) goto loc_82C975E8;
	// stw r28,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r28.u32);
loc_82C975E8:
	// lwz r29,284(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// lwz r30,236(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82c97614
	if (ctx.cr6.eq) goto loc_82C97614;
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// subf r5,r11,r30
	ctx.r5.s64 = ctx.r30.s64 - ctx.r11.s64;
	// mtctr r25
	ctx.ctr.u64 = ctx.r25.u64;
	// bctrl 
	ctx.lr = 0x82C97610;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r3.u32);
loc_82C97614:
	// addi r9,r1,236
	ctx.r9.s64 = ctx.r1.s64 + 236;
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c971b8
	ctx.lr = 0x82C97634;
	sub_82C971B8(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c97778
	if (ctx.cr6.eq) goto loc_82C97778;
	// lwz r30,80(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82c97664
	if (!ctx.cr6.eq) goto loc_82C97664;
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	// ERROR 82CA2C20
	return;
loc_82C97654:
	// stw r28,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r28.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	// ERROR 82CA2C20
	return;
loc_82C97664:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// addi r6,r26,-16
	ctx.r6.s64 = ctx.r26.s64 + -16;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C97680;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9750c
	if (ctx.cr6.eq) goto loc_82C9750C;
	// cmpwi cr6,r23,0
	ctx.cr6.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// bne cr6,0x82c9750c
	if (!ctx.cr6.eq) goto loc_82C9750C;
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// addi r6,r26,-4
	ctx.r6.s64 = ctx.r26.s64 + -4;
	// lwz r30,236(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r29,88(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// subf r5,r11,r30
	ctx.r5.s64 = ctx.r30.s64 - ctx.r11.s64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C976B8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c976d8
	if (ctx.cr6.eq) goto loc_82C976D8;
	// lwz r11,292(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c97710
	if (ctx.cr6.eq) goto loc_82C97710;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// b 0x82c97710
	goto loc_82C97710;
loc_82C976D8:
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// subf r5,r11,r30
	ctx.r5.s64 = ctx.r30.s64 - ctx.r11.s64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C976F8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c97768
	if (ctx.cr6.eq) goto loc_82C97768;
	// lwz r11,292(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c97710
	if (ctx.cr6.eq) goto loc_82C97710;
	// stw r24,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r24.u32);
loc_82C97710:
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c970b0
	ctx.lr = 0x82C97720;
	sub_82C970B0(ctx, base);
	// bl 0x82c97120
	ctx.lr = 0x82C97724;
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c97750
	if (ctx.cr6.eq) goto loc_82C97750;
loc_82C9772C:
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// add r30,r30,r11
	ctx.r30.u64 = ctx.r30.u64 + ctx.r11.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82c970b0
	ctx.lr = 0x82C97744;
	sub_82C970B0(ctx, base);
	// bl 0x82c97120
	ctx.lr = 0x82C97748;
	sub_82C97120(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c9772c
	if (!ctx.cr6.eq) goto loc_82C9772C;
loc_82C97750:
	// cmplw cr6,r30,r27
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82c97574
	if (ctx.cr6.eq) goto loc_82C97574;
	// stw r30,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r30.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	// ERROR 82CA2C20
	return;
loc_82C97768:
	// stw r29,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r29.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	// ERROR 82CA2C20
	return;
loc_82C97778:
	// lwz r11,236(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r22)
	PPC_STORE_U32(ctx.r22.u32 + 0, ctx.r11.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c20
	// ERROR 82CA2C20
	return;
}

__attribute__((alias("__imp__sub_82C9778C"))) PPC_WEAK_FUNC(sub_82C9778C);
PPC_FUNC_IMPL(__imp__sub_82C9778C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C97790"))) PPC_WEAK_FUNC(sub_82C97790);
PPC_FUNC_IMPL(__imp__sub_82C97790) {
	PPC_FUNC_PROLOGUE();
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt cr6,0x82c97870
	if (ctx.cr6.lt) goto loc_82C97870;
	// cmpwi cr6,r3,128
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 128, ctx.xer);
	// bge cr6,0x82c977b0
	if (!ctx.cr6.lt) goto loc_82C977B0;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,0(r4)
	PPC_STORE_U8(ctx.r4.u32 + 0, ctx.r11.u8);
	// blr 
	return;
loc_82C977B0:
	// cmpwi cr6,r3,2048
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 2048, ctx.xer);
	// bge cr6,0x82c977e4
	if (!ctx.cr6.lt) goto loc_82C977E4;
	// lis r11,511
	ctx.r11.s64 = 33488896;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// srawi r8,r3,6
	ctx.xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x3F) != 0);
	ctx.r8.s64 = ctx.r3.s32 >> 6;
	// ori r9,r11,65535
	ctx.r9.u64 = ctx.r11.u64 | 65535;
	// li r7,-64
	ctx.r7.s64 = -64;
	// rlwimi r10,r9,7,0,25
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 7) & 0xFFFFFFC0) | (ctx.r10.u64 & 0xFFFFFFFF0000003F);
	// or r6,r8,r7
	ctx.r6.u64 = ctx.r8.u64 | ctx.r7.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// stb r10,1(r4)
	PPC_STORE_U8(ctx.r4.u32 + 1, ctx.r10.u8);
	// stb r6,0(r4)
	PPC_STORE_U8(ctx.r4.u32 + 0, ctx.r6.u8);
	// blr 
	return;
loc_82C977E4:
	// lis r11,1
	ctx.r11.s64 = 65536;
	// cmpw cr6,r3,r11
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r11.s32, ctx.xer);
	// bge cr6,0x82c97824
	if (!ctx.cr6.lt) goto loc_82C97824;
	// lis r11,511
	ctx.r11.s64 = 33488896;
	// srawi r10,r3,12
	ctx.xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0xFFF) != 0);
	ctx.r10.s64 = ctx.r3.s32 >> 12;
	// ori r11,r11,65535
	ctx.r11.u64 = ctx.r11.u64 | 65535;
	// srawi r9,r3,6
	ctx.xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x3F) != 0);
	ctx.r9.s64 = ctx.r3.s32 >> 6;
	// li r8,-32
	ctx.r8.s64 = -32;
	// rlwimi r3,r11,7,0,25
	ctx.r3.u64 = (__builtin_rotateleft32(ctx.r11.u32, 7) & 0xFFFFFFC0) | (ctx.r3.u64 & 0xFFFFFFFF0000003F);
	// rlwimi r9,r11,7,0,25
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 7) & 0xFFFFFFC0) | (ctx.r9.u64 & 0xFFFFFFFF0000003F);
	// or r7,r10,r8
	ctx.r7.u64 = ctx.r10.u64 | ctx.r8.u64;
	// stb r3,2(r4)
	PPC_STORE_U8(ctx.r4.u32 + 2, ctx.r3.u8);
	// li r3,3
	ctx.r3.s64 = 3;
	// stb r9,1(r4)
	PPC_STORE_U8(ctx.r4.u32 + 1, ctx.r9.u8);
	// stb r7,0(r4)
	PPC_STORE_U8(ctx.r4.u32 + 0, ctx.r7.u8);
	// blr 
	return;
loc_82C97824:
	// lis r11,17
	ctx.r11.s64 = 1114112;
	// cmpw cr6,r3,r11
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r11.s32, ctx.xer);
	// bge cr6,0x82c97870
	if (!ctx.cr6.lt) goto loc_82C97870;
	// lis r11,511
	ctx.r11.s64 = 33488896;
	// srawi r10,r3,18
	ctx.xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x3FFFF) != 0);
	ctx.r10.s64 = ctx.r3.s32 >> 18;
	// srawi r9,r3,12
	ctx.xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0xFFF) != 0);
	ctx.r9.s64 = ctx.r3.s32 >> 12;
	// ori r11,r11,65535
	ctx.r11.u64 = ctx.r11.u64 | 65535;
	// srawi r8,r3,6
	ctx.xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x3F) != 0);
	ctx.r8.s64 = ctx.r3.s32 >> 6;
	// li r7,-16
	ctx.r7.s64 = -16;
	// rlwimi r3,r11,7,0,25
	ctx.r3.u64 = (__builtin_rotateleft32(ctx.r11.u32, 7) & 0xFFFFFFC0) | (ctx.r3.u64 & 0xFFFFFFFF0000003F);
	// rlwimi r9,r11,7,0,25
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r11.u32, 7) & 0xFFFFFFC0) | (ctx.r9.u64 & 0xFFFFFFFF0000003F);
	// rlwimi r8,r11,7,0,25
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r11.u32, 7) & 0xFFFFFFC0) | (ctx.r8.u64 & 0xFFFFFFFF0000003F);
	// stb r3,3(r4)
	PPC_STORE_U8(ctx.r4.u32 + 3, ctx.r3.u8);
	// or r6,r10,r7
	ctx.r6.u64 = ctx.r10.u64 | ctx.r7.u64;
	// stb r9,1(r4)
	PPC_STORE_U8(ctx.r4.u32 + 1, ctx.r9.u8);
	// li r3,4
	ctx.r3.s64 = 4;
	// stb r8,2(r4)
	PPC_STORE_U8(ctx.r4.u32 + 2, ctx.r8.u8);
	// stb r6,0(r4)
	PPC_STORE_U8(ctx.r4.u32 + 0, ctx.r6.u8);
	// blr 
	return;
loc_82C97870:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C97878"))) PPC_WEAK_FUNC(sub_82C97878);
PPC_FUNC_IMPL(__imp__sub_82C97878) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r3,372(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 372);
	// lwz r10,368(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 368);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C97898;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// rlwinm r9,r3,0,0,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFF0000;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82c978b8
	if (ctx.cr6.eq) goto loc_82C978B8;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C978B8:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// srawi r9,r3,8
	ctx.xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0xFF) != 0);
	ctx.r9.s64 = ctx.r3.s32 >> 8;
	// addi r11,r11,-4144
	ctx.r11.s64 = ctx.r11.s64 + -4144;
	// srawi r8,r3,5
	ctx.xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	ctx.r8.s64 = ctx.r3.s32 >> 5;
	// addi r7,r11,1536
	ctx.r7.s64 = ctx.r11.s64 + 1536;
	// clrlwi r10,r8,29
	ctx.r10.u64 = ctx.r8.u32 & 0x7;
	// clrlwi r6,r3,27
	ctx.r6.u64 = ctx.r3.u32 & 0x1F;
	// li r5,1
	ctx.r5.s64 = 1;
	// lbzx r4,r9,r7
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r7.u32);
	// slw r3,r5,r6
	ctx.r3.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r5.u32 << (ctx.r6.u8 & 0x3F));
	// rotlwi r9,r4,3
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// and r3,r8,r3
	ctx.r3.u64 = ctx.r8.u64 & ctx.r3.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C97904"))) PPC_WEAK_FUNC(sub_82C97904);
PPC_FUNC_IMPL(__imp__sub_82C97904) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C97908"))) PPC_WEAK_FUNC(sub_82C97908);
PPC_FUNC_IMPL(__imp__sub_82C97908) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r3,372(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 372);
	// lwz r10,368(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 368);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C97928;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// rlwinm r9,r3,0,0,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFF0000;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82c97948
	if (ctx.cr6.eq) goto loc_82C97948;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C97948:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// srawi r9,r3,8
	ctx.xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0xFF) != 0);
	ctx.r9.s64 = ctx.r3.s32 >> 8;
	// addi r11,r11,-4144
	ctx.r11.s64 = ctx.r11.s64 + -4144;
	// srawi r8,r3,5
	ctx.xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	ctx.r8.s64 = ctx.r3.s32 >> 5;
	// addi r7,r11,1280
	ctx.r7.s64 = ctx.r11.s64 + 1280;
	// clrlwi r10,r8,29
	ctx.r10.u64 = ctx.r8.u32 & 0x7;
	// clrlwi r6,r3,27
	ctx.r6.u64 = ctx.r3.u32 & 0x1F;
	// li r5,1
	ctx.r5.s64 = 1;
	// lbzx r4,r9,r7
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r7.u32);
	// slw r3,r5,r6
	ctx.r3.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r5.u32 << (ctx.r6.u8 & 0x3F));
	// rotlwi r9,r4,3
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// and r3,r8,r3
	ctx.r3.u64 = ctx.r8.u64 & ctx.r3.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C97994"))) PPC_WEAK_FUNC(sub_82C97994);
PPC_FUNC_IMPL(__imp__sub_82C97994) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C97998"))) PPC_WEAK_FUNC(sub_82C97998);
PPC_FUNC_IMPL(__imp__sub_82C97998) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r3,372(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 372);
	// lwz r10,368(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 368);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C979B8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// rlwinm r9,r3,0,0,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFF0000;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne cr6,0x82c97a1c
	if (!ctx.cr6.eq) goto loc_82C97A1C;
	// srawi r11,r3,8
	ctx.xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0xFF) != 0);
	ctx.r11.s64 = ctx.r3.s32 >> 8;
	// cmpwi cr6,r11,223
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 223, ctx.xer);
	// bgt cr6,0x82c979f8
	if (ctx.cr6.gt) goto loc_82C979F8;
	// cmpwi cr6,r11,216
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 216, ctx.xer);
	// bge cr6,0x82c97a1c
	if (!ctx.cr6.lt) goto loc_82C97A1C;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c97a10
	if (!ctx.cr6.eq) goto loc_82C97A10;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// addi r11,r11,-504
	ctx.r11.s64 = ctx.r11.s64 + -504;
	// addi r10,r11,76
	ctx.r10.s64 = ctx.r11.s64 + 76;
	// lbzx r9,r3,r10
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + ctx.r10.u32);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// b 0x82c97a0c
	goto loc_82C97A0C;
loc_82C979F8:
	// cmpwi cr6,r11,255
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 255, ctx.xer);
	// bne cr6,0x82c97a10
	if (!ctx.cr6.eq) goto loc_82C97A10;
	// cmplwi cr6,r3,65534
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 65534, ctx.xer);
	// beq cr6,0x82c97a1c
	if (ctx.cr6.eq) goto loc_82C97A1C;
	// cmplwi cr6,r3,65535
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 65535, ctx.xer);
loc_82C97A0C:
	// beq cr6,0x82c97a1c
	if (ctx.cr6.eq) goto loc_82C97A1C;
loc_82C97A10:
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// bge cr6,0x82c97a20
	if (!ctx.cr6.lt) goto loc_82C97A20;
loc_82C97A1C:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82C97A20:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C97A30"))) PPC_WEAK_FUNC(sub_82C97A30);
PPC_FUNC_IMPL(__imp__sub_82C97A30) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C97A38;
	sub_82CA2BE0(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplw cr6,r11,r27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82c97b1c
	if (ctx.cr6.eq) goto loc_82C97B1C;
loc_82C97A5C:
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// addi r11,r11,222
	ctx.r11.s64 = ctx.r11.s64 + 222;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// extsb r3,r10
	ctx.r3.s64 = ctx.r10.s8;
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c97ad4
	if (!ctx.cr6.eq) goto loc_82C97AD4;
	// lwz r3,372(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 372);
	// addi r26,r1,80
	ctx.r26.s64 = ctx.r1.s64 + 80;
	// lwz r11,368(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 368);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C97A98;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// bl 0x82c97790
	ctx.lr = 0x82C97AA0;
	sub_82C97790(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// subf r9,r10,r28
	ctx.r9.s64 = ctx.r28.s64 - ctx.r10.s64;
	// cmpw cr6,r3,r9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r9.s32, ctx.xer);
	// bgt cr6,0x82c97b1c
	if (ctx.cr6.gt) goto loc_82C97B1C;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r9,r9,r29
	ctx.r9.u64 = ctx.r9.u64 + ctx.r29.u64;
	// lbz r9,76(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 76);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// addi r8,r10,-3
	ctx.r8.s64 = ctx.r10.s64 + -3;
	// stw r8,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r8.u32);
	// b 0x82c97aec
	goto loc_82C97AEC;
loc_82C97AD4:
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// subf r9,r10,r28
	ctx.r9.s64 = ctx.r28.s64 - ctx.r10.s64;
	// cmpw cr6,r3,r9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r9.s32, ctx.xer);
	// bgt cr6,0x82c97b1c
	if (ctx.cr6.gt) goto loc_82C97B1C;
	// addi r10,r4,1
	ctx.r10.s64 = ctx.r4.s64 + 1;
	// stw r10,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r10.u32);
loc_82C97AEC:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// addic. r3,r3,-1
	ctx.xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stb r10,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r10.u8);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// stw r8,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r8.u32);
	// bne 0x82c97aec
	if (!ctx.cr0.eq) goto loc_82C97AEC;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplw cr6,r11,r27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r27.u32, ctx.xer);
	// bne cr6,0x82c97a5c
	if (!ctx.cr6.eq) goto loc_82C97A5C;
loc_82C97B1C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
}

__attribute__((alias("__imp__sub_82C97B24"))) PPC_WEAK_FUNC(sub_82C97B24);
PPC_FUNC_IMPL(__imp__sub_82C97B24) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C97B28"))) PPC_WEAK_FUNC(sub_82C97B28);
PPC_FUNC_IMPL(__imp__sub_82C97B28) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C97B30;
	sub_82CA2BE4(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c97bd8
	if (ctx.cr6.eq) goto loc_82C97BD8;
loc_82C97B54:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplw cr6,r11,r27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82c97bd8
	if (ctx.cr6.eq) goto loc_82C97BD8;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// addi r11,r11,188
	ctx.r11.s64 = ctx.r11.s64 + 188;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r10,r10,r30
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + ctx.r30.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c97bb0
	if (!ctx.cr6.eq) goto loc_82C97BB0;
	// lwz r3,372(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 372);
	// lwz r11,368(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 368);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C97B8C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// clrlwi r10,r3,16
	ctx.r10.u64 = ctx.r3.u32 & 0xFFFF;
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// add r9,r9,r30
	ctx.r9.u64 = ctx.r9.u64 + ctx.r30.u64;
	// lbz r9,76(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 76);
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// addi r8,r11,-3
	ctx.r8.s64 = ctx.r11.s64 + -3;
	// stw r8,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r8.u32);
	// b 0x82c97bb8
	goto loc_82C97BB8;
loc_82C97BB0:
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
loc_82C97BB8:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// sth r10,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r10.u16);
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// stw r10,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r10.u32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r9,r28
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c97b54
	if (!ctx.cr6.eq) goto loc_82C97B54;
loc_82C97BD8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
}

__attribute__((alias("__imp__sub_82C97BE0"))) PPC_WEAK_FUNC(sub_82C97BE0);
PPC_FUNC_IMPL(__imp__sub_82C97BE0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bc0
	ctx.lr = 0x82C97BE8;
	sub_82CA2BC0(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r24,r10,-4144
	ctx.r24.s64 = ctx.r10.s64 + -4144;
	// mr r18,r6
	ctx.r18.u64 = ctx.r6.u64;
	// addi r9,r24,3640
	ctx.r9.s64 = ctx.r24.s64 + 3640;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// li r10,368
	ctx.r10.s64 = 368;
	// subf r9,r28,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r28.s64;
loc_82C97C0C:
	// lbzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r11.u32);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stb r8,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r8.u8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// bne 0x82c97c0c
	if (!ctx.cr0.eq) goto loc_82C97C0C;
	// li r23,0
	ctx.r23.s64 = 0;
	// mr r9,r4
	ctx.r9.u64 = ctx.r4.u64;
	// mr r11,r23
	ctx.r11.u64 = ctx.r23.u64;
loc_82C97C2C:
	// addi r10,r24,3640
	ctx.r10.s64 = ctx.r24.s64 + 3640;
	// addi r10,r10,76
	ctx.r10.s64 = ctx.r10.s64 + 76;
	// lbzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r10,28
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 28, ctx.xer);
	// beq cr6,0x82c97c54
	if (ctx.cr6.eq) goto loc_82C97C54;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c97c54
	if (ctx.cr6.eq) goto loc_82C97C54;
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82c97cb0
	if (!ctx.cr6.eq) goto loc_82C97CB0;
loc_82C97C54:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmpwi cr6,r11,128
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 128, ctx.xer);
	// blt cr6,0x82c97c2c
	if (ctx.cr6.lt) goto loc_82C97C2C;
	// lis r11,0
	ctx.r11.s64 = 0;
	// mr r29,r23
	ctx.r29.u64 = ctx.r23.u64;
	// mr r22,r4
	ctx.r22.u64 = ctx.r4.u64;
	// addi r27,r28,376
	ctx.r27.s64 = ctx.r28.s64 + 376;
	// addi r30,r28,888
	ctx.r30.s64 = ctx.r28.s64 + 888;
	// li r26,1
	ctx.r26.s64 = 1;
	// ori r25,r11,65535
	ctx.r25.u64 = ctx.r11.u64 | 65535;
	// li r19,22
	ctx.r19.s64 = 22;
	// li r20,26
	ctx.r20.s64 = 26;
	// li r21,28
	ctx.r21.s64 = 28;
loc_82C97C8C:
	// lwz r31,0(r22)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// cmpwi cr6,r31,-1
	ctx.cr6.compare<int32_t>(ctx.r31.s32, -1, ctx.xer);
	// bne cr6,0x82c97cbc
	if (!ctx.cr6.eq) goto loc_82C97CBC;
	// add r11,r29,r28
	ctx.r11.u64 = ctx.r29.u64 + ctx.r28.u64;
	// stb r26,76(r11)
	PPC_STORE_U8(ctx.r11.u32 + 76, ctx.r26.u8);
	// sth r25,0(r27)
	PPC_STORE_U16(ctx.r27.u32 + 0, ctx.r25.u16);
	// stb r26,0(r30)
	PPC_STORE_U8(ctx.r30.u32 + 0, ctx.r26.u8);
	// stb r23,1(r30)
	PPC_STORE_U8(ctx.r30.u32 + 1, ctx.r23.u8);
	// b 0x82c97e24
	goto loc_82C97E24;
loc_82C97CB0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c10
	// ERROR 82CA2C10
	return;
loc_82C97CBC:
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bge cr6,0x82c97ce4
	if (!ctx.cr6.lt) goto loc_82C97CE4;
	// cmpwi cr6,r31,-4
	ctx.cr6.compare<int32_t>(ctx.r31.s32, -4, ctx.xer);
	// blt cr6,0x82c97cb0
	if (ctx.cr6.lt) goto loc_82C97CB0;
	// add r10,r29,r28
	ctx.r10.u64 = ctx.r29.u64 + ctx.r28.u64;
	// subfic r11,r31,3
	ctx.xer.ca = ctx.r31.u32 <= 3;
	ctx.r11.s64 = 3 - ctx.r31.s64;
	// stb r11,76(r10)
	PPC_STORE_U8(ctx.r10.u32 + 76, ctx.r11.u8);
	// stb r23,0(r30)
	PPC_STORE_U8(ctx.r30.u32 + 0, ctx.r23.u8);
	// sth r23,0(r27)
	PPC_STORE_U16(ctx.r27.u32 + 0, ctx.r23.u16);
	// b 0x82c97e24
	goto loc_82C97E24;
loc_82C97CE4:
	// cmpwi cr6,r31,128
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 128, ctx.xer);
	// bge cr6,0x82c97d34
	if (!ctx.cr6.lt) goto loc_82C97D34;
	// addi r11,r24,3640
	ctx.r11.s64 = ctx.r24.s64 + 3640;
	// addi r11,r11,76
	ctx.r11.s64 = ctx.r11.s64 + 76;
	// lbzx r11,r31,r11
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + ctx.r11.u32);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// cmplwi cr6,r10,28
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 28, ctx.xer);
	// beq cr6,0x82c97d14
	if (ctx.cr6.eq) goto loc_82C97D14;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c97d14
	if (ctx.cr6.eq) goto loc_82C97D14;
	// cmpw cr6,r31,r29
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r29.s32, ctx.xer);
	// bne cr6,0x82c97cb0
	if (!ctx.cr6.eq) goto loc_82C97CB0;
loc_82C97D14:
	// add r10,r29,r28
	ctx.r10.u64 = ctx.r29.u64 + ctx.r28.u64;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// stb r11,76(r10)
	PPC_STORE_U8(ctx.r10.u32 + 76, ctx.r11.u8);
	// stb r26,0(r30)
	PPC_STORE_U8(ctx.r30.u32 + 0, ctx.r26.u8);
	// stb r31,1(r30)
	PPC_STORE_U8(ctx.r30.u32 + 1, ctx.r31.u8);
	// bne cr6,0x82c97e20
	if (!ctx.cr6.eq) goto loc_82C97E20;
	// mr r31,r25
	ctx.r31.u64 = ctx.r25.u64;
	// b 0x82c97e20
	goto loc_82C97E20;
loc_82C97D34:
	// srawi r8,r31,8
	ctx.xer.ca = (ctx.r31.s32 < 0) & ((ctx.r31.u32 & 0xFF) != 0);
	ctx.r8.s64 = ctx.r31.s32 >> 8;
	// cmpwi cr6,r8,223
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 223, ctx.xer);
	// bgt cr6,0x82c97dac
	if (ctx.cr6.gt) goto loc_82C97DAC;
	// cmpwi cr6,r8,216
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 216, ctx.xer);
	// bge cr6,0x82c97dc4
	if (!ctx.cr6.lt) goto loc_82C97DC4;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne cr6,0x82c97d64
	if (!ctx.cr6.eq) goto loc_82C97D64;
	// addi r11,r24,3640
	ctx.r11.s64 = ctx.r24.s64 + 3640;
	// addi r11,r11,76
	ctx.r11.s64 = ctx.r11.s64 + 76;
	// lbzx r10,r31,r11
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + ctx.r11.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c97dc4
	if (ctx.cr6.eq) goto loc_82C97DC4;
loc_82C97D64:
	// cmpw cr6,r31,r25
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r25.s32, ctx.xer);
	// bgt cr6,0x82c97cb0
	if (ctx.cr6.gt) goto loc_82C97CB0;
	// addi r9,r24,1280
	ctx.r9.s64 = ctx.r24.s64 + 1280;
	// srawi r7,r31,5
	ctx.xer.ca = (ctx.r31.s32 < 0) & ((ctx.r31.u32 & 0x1F) != 0);
	ctx.r7.s64 = ctx.r31.s32 >> 5;
	// clrlwi r6,r31,27
	ctx.r6.u64 = ctx.r31.u32 & 0x1F;
	// clrlwi r11,r7,29
	ctx.r11.u64 = ctx.r7.u32 & 0x7;
	// slw r10,r26,r6
	ctx.r10.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r26.u32 << (ctx.r6.u8 & 0x3F));
	// lbzx r4,r8,r9
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r9.u32);
	// rotlwi r9,r4,3
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r4.u32, 3);
	// add r3,r9,r11
	ctx.r3.u64 = ctx.r9.u64 + ctx.r11.u64;
	// rlwinm r9,r3,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r9,r24
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r24.u32);
	// and r6,r7,r10
	ctx.r6.u64 = ctx.r7.u64 & ctx.r10.u64;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82c97ddc
	if (ctx.cr6.eq) goto loc_82C97DDC;
	// add r11,r29,r28
	ctx.r11.u64 = ctx.r29.u64 + ctx.r28.u64;
	// stb r19,76(r11)
	PPC_STORE_U8(ctx.r11.u32 + 76, ctx.r19.u8);
	// b 0x82c97e10
	goto loc_82C97E10;
loc_82C97DAC:
	// cmpwi cr6,r8,255
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 255, ctx.xer);
	// bne cr6,0x82c97d64
	if (!ctx.cr6.eq) goto loc_82C97D64;
	// cmplwi cr6,r31,65534
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 65534, ctx.xer);
	// beq cr6,0x82c97dc4
	if (ctx.cr6.eq) goto loc_82C97DC4;
	// cmplwi cr6,r31,65535
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 65535, ctx.xer);
	// bne cr6,0x82c97d64
	if (!ctx.cr6.eq) goto loc_82C97D64;
loc_82C97DC4:
	// add r11,r29,r28
	ctx.r11.u64 = ctx.r29.u64 + ctx.r28.u64;
	// stb r23,76(r11)
	PPC_STORE_U8(ctx.r11.u32 + 76, ctx.r23.u8);
	// sth r25,0(r27)
	PPC_STORE_U16(ctx.r27.u32 + 0, ctx.r25.u16);
	// stb r26,0(r30)
	PPC_STORE_U8(ctx.r30.u32 + 0, ctx.r26.u8);
	// stb r23,1(r30)
	PPC_STORE_U8(ctx.r30.u32 + 1, ctx.r23.u8);
	// b 0x82c97e24
	goto loc_82C97E24;
loc_82C97DDC:
	// addi r9,r24,1536
	ctx.r9.s64 = ctx.r24.s64 + 1536;
	// lbzx r8,r8,r9
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r9.u32);
	// rotlwi r9,r8,3
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r8.u32, 3);
	// add r7,r9,r11
	ctx.r7.u64 = ctx.r9.u64 + ctx.r11.u64;
	// add r11,r29,r28
	ctx.r11.u64 = ctx.r29.u64 + ctx.r28.u64;
	// rlwinm r6,r7,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r6,r24
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r24.u32);
	// and r3,r4,r10
	ctx.r3.u64 = ctx.r4.u64 & ctx.r10.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c97e0c
	if (ctx.cr6.eq) goto loc_82C97E0C;
	// stb r20,76(r11)
	PPC_STORE_U8(ctx.r11.u32 + 76, ctx.r20.u8);
	// b 0x82c97e10
	goto loc_82C97E10;
loc_82C97E0C:
	// stb r21,76(r11)
	PPC_STORE_U8(ctx.r11.u32 + 76, ctx.r21.u8);
loc_82C97E10:
	// addi r4,r30,1
	ctx.r4.s64 = ctx.r30.s64 + 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c97790
	ctx.lr = 0x82C97E1C;
	sub_82C97790(ctx, base);
	// stb r3,0(r30)
	PPC_STORE_U8(ctx.r30.u32 + 0, ctx.r3.u8);
loc_82C97E20:
	// sth r31,0(r27)
	PPC_STORE_U16(ctx.r27.u32 + 0, ctx.r31.u16);
loc_82C97E24:
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r27,r27,2
	ctx.r27.s64 = ctx.r27.s64 + 2;
	// addi r22,r22,4
	ctx.r22.s64 = ctx.r22.s64 + 4;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmpwi cr6,r29,256
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 256, ctx.xer);
	// blt cr6,0x82c97c8c
	if (ctx.cr6.lt) goto loc_82C97C8C;
	// stw r18,372(r28)
	PPC_STORE_U32(ctx.r28.u32 + 372, ctx.r18.u32);
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// stw r5,368(r28)
	PPC_STORE_U32(ctx.r28.u32 + 368, ctx.r5.u32);
	// beq cr6,0x82c97eb8
	if (ctx.cr6.eq) goto loc_82C97EB8;
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// lis r10,-32055
	ctx.r10.s64 = -2100756480;
	// lis r9,-32055
	ctx.r9.s64 = -2100756480;
	// lis r8,-32055
	ctx.r8.s64 = -2100756480;
	// lis r7,-32055
	ctx.r7.s64 = -2100756480;
	// lis r6,-32055
	ctx.r6.s64 = -2100756480;
	// lis r5,-32055
	ctx.r5.s64 = -2100756480;
	// lis r4,-32055
	ctx.r4.s64 = -2100756480;
	// lis r3,-32055
	ctx.r3.s64 = -2100756480;
	// addi r11,r11,30840
	ctx.r11.s64 = ctx.r11.s64 + 30840;
	// addi r10,r10,30840
	ctx.r10.s64 = ctx.r10.s64 + 30840;
	// addi r9,r9,30840
	ctx.r9.s64 = ctx.r9.s64 + 30840;
	// stw r11,332(r28)
	PPC_STORE_U32(ctx.r28.u32 + 332, ctx.r11.u32);
	// addi r8,r8,30984
	ctx.r8.s64 = ctx.r8.s64 + 30984;
	// stw r10,336(r28)
	PPC_STORE_U32(ctx.r28.u32 + 336, ctx.r10.u32);
	// addi r7,r7,30984
	ctx.r7.s64 = ctx.r7.s64 + 30984;
	// stw r9,340(r28)
	PPC_STORE_U32(ctx.r28.u32 + 340, ctx.r9.u32);
	// addi r6,r6,30984
	ctx.r6.s64 = ctx.r6.s64 + 30984;
	// stw r8,344(r28)
	PPC_STORE_U32(ctx.r28.u32 + 344, ctx.r8.u32);
	// addi r5,r5,31128
	ctx.r5.s64 = ctx.r5.s64 + 31128;
	// stw r7,348(r28)
	PPC_STORE_U32(ctx.r28.u32 + 348, ctx.r7.u32);
	// addi r4,r4,31128
	ctx.r4.s64 = ctx.r4.s64 + 31128;
	// stw r6,352(r28)
	PPC_STORE_U32(ctx.r28.u32 + 352, ctx.r6.u32);
	// addi r3,r3,31128
	ctx.r3.s64 = ctx.r3.s64 + 31128;
	// stw r5,356(r28)
	PPC_STORE_U32(ctx.r28.u32 + 356, ctx.r5.u32);
	// stw r4,360(r28)
	PPC_STORE_U32(ctx.r28.u32 + 360, ctx.r4.u32);
	// stw r3,364(r28)
	PPC_STORE_U32(ctx.r28.u32 + 364, ctx.r3.u32);
loc_82C97EB8:
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// lis r10,-32055
	ctx.r10.s64 = -2100756480;
	// addi r9,r11,31280
	ctx.r9.s64 = ctx.r11.s64 + 31280;
	// addi r8,r10,31528
	ctx.r8.s64 = ctx.r10.s64 + 31528;
	// stw r9,60(r28)
	PPC_STORE_U32(ctx.r28.u32 + 60, ctx.r9.u32);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// stw r8,64(r28)
	PPC_STORE_U32(ctx.r28.u32 + 64, ctx.r8.u32);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c10
	// ERROR 82CA2C10
	return;
}

__attribute__((alias("__imp__sub_82C97EDC"))) PPC_WEAK_FUNC(sub_82C97EDC);
PPC_FUNC_IMPL(__imp__sub_82C97EDC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C97EE0"))) PPC_WEAK_FUNC(sub_82C97EE0);
PPC_FUNC_IMPL(__imp__sub_82C97EE0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// bne cr6,0x82c97f0c
	if (!ctx.cr6.eq) goto loc_82C97F0C;
	// li r3,6
	ctx.r3.s64 = 6;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C97F0C:
	// lis r11,-31953
	ctx.r11.s64 = -2094071808;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-5880
	ctx.r6.s64 = ctx.r11.s64 + -5880;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
loc_82C97F1C:
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// lwz r4,0(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// bl 0x82c97030
	ctx.lr = 0x82C97F28;
	sub_82C97030(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c97f58
	if (!ctx.cr6.eq) goto loc_82C97F58;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r11,r6,24
	ctx.r11.s64 = ctx.r6.s64 + 24;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// cmpw cr6,r8,r11
	ctx.cr6.compare<int32_t>(ctx.r8.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x82c97f1c
	if (ctx.cr6.lt) goto loc_82C97F1C;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82C97F58:
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C97F6C"))) PPC_WEAK_FUNC(sub_82C97F6C);
PPC_FUNC_IMPL(__imp__sub_82C97F6C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C97F70"))) PPC_WEAK_FUNC(sub_82C97F70);
PPC_FUNC_IMPL(__imp__sub_82C97F70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C97F78;
	sub_82CA2BEC(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// mr r6,r8
	ctx.r6.u64 = ctx.r8.u64;
	// cmplw cr6,r4,r5
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c97fa8
	if (!ctx.cr6.eq) goto loc_82C97FA8;
	// li r3,-4
	ctx.r3.s64 = -4;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C97FA8:
	// addi r11,r4,1
	ctx.r11.s64 = ctx.r4.s64 + 1;
	// lwz r7,76(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 76);
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c98020
	if (!ctx.cr6.eq) goto loc_82C98020;
	// lbz r11,73(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 73);
	// extsb r10,r11
	ctx.r10.s64 = ctx.r11.s8;
	// cmpwi cr6,r10,3
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 3, ctx.xer);
	// blt cr6,0x82c97fd0
	if (ctx.cr6.lt) goto loc_82C97FD0;
	// cmpwi cr6,r10,5
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 5, ctx.xer);
	// ble cr6,0x82c98014
	if (!ctx.cr6.gt) goto loc_82C98014;
loc_82C97FD0:
	// lbz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmpwi cr6,r11,239
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 239, ctx.xer);
	// bgt cr6,0x82c97ff4
	if (ctx.cr6.gt) goto loc_82C97FF4;
	// beq cr6,0x82c98004
	if (ctx.cr6.eq) goto loc_82C98004;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c98014
	if (ctx.cr6.eq) goto loc_82C98014;
	// cmpwi cr6,r11,60
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 60, ctx.xer);
	// beq cr6,0x82c98014
	if (ctx.cr6.eq) goto loc_82C98014;
	// b 0x82c981cc
	goto loc_82C981CC;
loc_82C97FF4:
	// cmpwi cr6,r11,254
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 254, ctx.xer);
	// blt cr6,0x82c981cc
	if (ctx.cr6.lt) goto loc_82C981CC;
	// cmpwi cr6,r11,255
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 255, ctx.xer);
	// bgt cr6,0x82c981cc
	if (ctx.cr6.gt) goto loc_82C981CC;
loc_82C98004:
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c98014
	if (!ctx.cr6.eq) goto loc_82C98014;
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// beq cr6,0x82c981cc
	if (ctx.cr6.eq) goto loc_82C981CC;
loc_82C98014:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C98020:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// lis r11,0
	ctx.r11.s64 = 0;
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// ori r29,r11,65279
	ctx.r29.u64 = ctx.r11.u64 | 65279;
	// rlwimi r8,r10,8,16,23
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 8) & 0xFF00) | (ctx.r8.u64 & 0xFFFFFFFFFFFF00FF);
	// clrlwi r11,r8,16
	ctx.r11.u64 = ctx.r8.u32 & 0xFFFF;
	// cmpw cr6,r11,r29
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r29.s32, ctx.xer);
	// bgt cr6,0x82c98134
	if (ctx.cr6.gt) goto loc_82C98134;
	// cmplwi cr6,r11,65279
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 65279, ctx.xer);
	// beq cr6,0x82c98104
	if (ctx.cr6.eq) goto loc_82C98104;
	// cmpwi cr6,r11,15360
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 15360, ctx.xer);
	// beq cr6,0x82c980c0
	if (ctx.cr6.eq) goto loc_82C980C0;
	// cmplwi cr6,r11,61371
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 61371, ctx.xer);
	// bne cr6,0x82c9813c
	if (!ctx.cr6.eq) goto loc_82C9813C;
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// bne cr6,0x82c9808c
	if (!ctx.cr6.eq) goto loc_82C9808C;
	// lbz r11,73(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 73);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c981cc
	if (ctx.cr6.eq) goto loc_82C981CC;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// beq cr6,0x82c981cc
	if (ctx.cr6.eq) goto loc_82C981CC;
	// cmpwi cr6,r11,5
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 5, ctx.xer);
	// beq cr6,0x82c981cc
	if (ctx.cr6.eq) goto loc_82C981CC;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82c981cc
	if (ctx.cr6.eq) goto loc_82C981CC;
loc_82C9808C:
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c98014
	if (ctx.cr6.eq) goto loc_82C98014;
	// lbz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r11,191
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 191, ctx.xer);
	// bne cr6,0x82c981cc
	if (!ctx.cr6.eq) goto loc_82C981CC;
	// addi r11,r4,3
	ctx.r11.s64 = ctx.r4.s64 + 3;
	// li r3,14
	ctx.r3.s64 = 14;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C980C0:
	// lbz r11,73(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 73);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,4
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 4, ctx.xer);
	// beq cr6,0x82c980d8
	if (ctx.cr6.eq) goto loc_82C980D8;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// bne cr6,0x82c980e0
	if (!ctx.cr6.eq) goto loc_82C980E0;
loc_82C980D8:
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// beq cr6,0x82c981cc
	if (ctx.cr6.eq) goto loc_82C981CC;
loc_82C980E0:
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r11.u32);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C980FC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C98104:
	// lbz r11,73(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 73);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c98118
	if (!ctx.cr6.eq) goto loc_82C98118;
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// beq cr6,0x82c981cc
	if (ctx.cr6.eq) goto loc_82C981CC;
loc_82C98118:
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// li r3,14
	ctx.r3.s64 = 14;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C98134:
	// cmplwi cr6,r11,65534
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 65534, ctx.xer);
	// beq cr6,0x82c981b8
	if (ctx.cr6.eq) goto loc_82C981B8;
loc_82C9813C:
	// extsb r11,r10
	ctx.r11.s64 = ctx.r10.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c98180
	if (!ctx.cr6.eq) goto loc_82C98180;
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// bne cr6,0x82c9815c
	if (!ctx.cr6.eq) goto loc_82C9815C;
	// lbz r11,73(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 73);
	// cmplwi cr6,r11,5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 5, ctx.xer);
	// beq cr6,0x82c981cc
	if (ctx.cr6.eq) goto loc_82C981CC;
loc_82C9815C:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r11.u32);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C98178;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C98180:
	// extsb r11,r9
	ctx.r11.s64 = ctx.r9.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c981cc
	if (!ctx.cr6.eq) goto loc_82C981CC;
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// beq cr6,0x82c981cc
	if (ctx.cr6.eq) goto loc_82C981CC;
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r11.u32);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C981B0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C981B8:
	// lbz r11,73(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 73);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c981fc
	if (!ctx.cr6.eq) goto loc_82C981FC;
	// cmpwi cr6,r3,1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 1, ctx.xer);
	// bne cr6,0x82c981fc
	if (!ctx.cr6.eq) goto loc_82C981FC;
loc_82C981CC:
	// lbz r11,73(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 73);
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// extsb r9,r11
	ctx.r9.s64 = ctx.r11.s8;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r8,r31
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r31.u32);
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r11.u32);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C981F4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C981FC:
	// addi r11,r4,2
	ctx.r11.s64 = ctx.r4.s64 + 2;
	// li r3,14
	ctx.r3.s64 = 14;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
}

__attribute__((alias("__imp__sub_82C98218"))) PPC_WEAK_FUNC(sub_82C98218);
PPC_FUNC_IMPL(__imp__sub_82C98218) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lis r10,-31953
	ctx.r10.s64 = -2094071808;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// addi r3,r10,-5856
	ctx.r3.s64 = ctx.r10.s64 + -5856;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// b 0x82c97f70
	sub_82C97F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C9823C"))) PPC_WEAK_FUNC(sub_82C9823C);
PPC_FUNC_IMPL(__imp__sub_82C9823C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C98240"))) PPC_WEAK_FUNC(sub_82C98240);
PPC_FUNC_IMPL(__imp__sub_82C98240) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lis r10,-31953
	ctx.r10.s64 = -2094071808;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// addi r3,r10,-5856
	ctx.r3.s64 = ctx.r10.s64 + -5856;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// b 0x82c97f70
	sub_82C97F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C98264"))) PPC_WEAK_FUNC(sub_82C98264);
PPC_FUNC_IMPL(__imp__sub_82C98264) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C98268"))) PPC_WEAK_FUNC(sub_82C98268);
PPC_FUNC_IMPL(__imp__sub_82C98268) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82c97ee0
	ctx.lr = 0x82C9828C;
	sub_82C97EE0(ctx, base);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// bne cr6,0x82c9829c
	if (!ctx.cr6.eq) goto loc_82C9829C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c982d0
	goto loc_82C982D0;
loc_82C9829C:
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// stb r3,73(r31)
	PPC_STORE_U8(ctx.r31.u32 + 73, ctx.r3.u8);
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// stw r30,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r30.u32);
	// lis r9,-32055
	ctx.r9.s64 = -2100756480;
	// addi r7,r11,-32232
	ctx.r7.s64 = ctx.r11.s64 + -32232;
	// addi r6,r10,-32192
	ctx.r6.s64 = ctx.r10.s64 + -32192;
	// addi r5,r9,28832
	ctx.r5.s64 = ctx.r9.s64 + 28832;
	// stw r7,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r7.u32);
	// stw r6,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r6.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r5,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r5.u32);
	// stw r31,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r31.u32);
loc_82C982D0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C982E8"))) PPC_WEAK_FUNC(sub_82C982E8);
PPC_FUNC_IMPL(__imp__sub_82C982E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r4,284(r1)
	PPC_STORE_U32(ctx.r1.u32 + 284, ctx.r4.u32);
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// addi r7,r1,223
	ctx.r7.s64 = ctx.r1.s64 + 223;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r10,60(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// addi r4,r1,284
	ctx.r4.s64 = ctx.r1.s64 + 284;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C98328;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r9,284(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// cmplw cr6,r9,r30
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c9833c
	if (ctx.cr6.eq) goto loc_82C9833C;
loc_82C98334:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c98394
	goto loc_82C98394;
loc_82C9833C:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r10,0
	ctx.r10.s64 = 0;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// addi r4,r9,2896
	ctx.r4.s64 = ctx.r9.s64 + 2896;
	// stb r10,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r10.u8);
	// bl 0x82c97030
	ctx.lr = 0x82C98358;
	sub_82C97030(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c98374
	if (ctx.cr6.eq) goto loc_82C98374;
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82c98374
	if (!ctx.cr6.eq) goto loc_82C98374;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// b 0x82c98394
	goto loc_82C98394;
loc_82C98374:
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82c97ee0
	ctx.lr = 0x82C9837C;
	sub_82C97EE0(ctx, base);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// beq cr6,0x82c98334
	if (ctx.cr6.eq) goto loc_82C98334;
	// lis r11,-31953
	ctx.r11.s64 = -2094071808;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r11,-5856
	ctx.r9.s64 = ctx.r11.s64 + -5856;
	// lwzx r3,r10,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
loc_82C98394:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C983AC"))) PPC_WEAK_FUNC(sub_82C983AC);
PPC_FUNC_IMPL(__imp__sub_82C983AC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C983B0"))) PPC_WEAK_FUNC(sub_82C983B0);
PPC_FUNC_IMPL(__imp__sub_82C983B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// lwz r31,220(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// lwz r30,212(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r31.u32);
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r30.u32);
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r11,-32024
	ctx.r3.s64 = ctx.r11.s64 + -32024;
	// bl 0x82c97458
	ctx.lr = 0x82C98404;
	sub_82C97458(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9841C"))) PPC_WEAK_FUNC(sub_82C9841C);
PPC_FUNC_IMPL(__imp__sub_82C9841C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C98420"))) PPC_WEAK_FUNC(sub_82C98420);
PPC_FUNC_IMPL(__imp__sub_82C98420) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lis r10,-31953
	ctx.r10.s64 = -2094071808;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// addi r3,r10,-5828
	ctx.r3.s64 = ctx.r10.s64 + -5828;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// b 0x82c97f70
	sub_82C97F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C98444"))) PPC_WEAK_FUNC(sub_82C98444);
PPC_FUNC_IMPL(__imp__sub_82C98444) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C98448"))) PPC_WEAK_FUNC(sub_82C98448);
PPC_FUNC_IMPL(__imp__sub_82C98448) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lis r10,-31953
	ctx.r10.s64 = -2094071808;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// addi r3,r10,-5828
	ctx.r3.s64 = ctx.r10.s64 + -5828;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// b 0x82c97f70
	sub_82C97F70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82C9846C"))) PPC_WEAK_FUNC(sub_82C9846C);
PPC_FUNC_IMPL(__imp__sub_82C9846C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C98470"))) PPC_WEAK_FUNC(sub_82C98470);
PPC_FUNC_IMPL(__imp__sub_82C98470) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82c97ee0
	ctx.lr = 0x82C98494;
	sub_82C97EE0(ctx, base);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// bne cr6,0x82c984a4
	if (!ctx.cr6.eq) goto loc_82C984A4;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c984d8
	goto loc_82C984D8;
loc_82C984A4:
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// stb r3,73(r31)
	PPC_STORE_U8(ctx.r31.u32 + 73, ctx.r3.u8);
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// stw r30,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r30.u32);
	// lis r9,-32055
	ctx.r9.s64 = -2100756480;
	// addi r7,r11,-31712
	ctx.r7.s64 = ctx.r11.s64 + -31712;
	// addi r6,r10,-31672
	ctx.r6.s64 = ctx.r10.s64 + -31672;
	// addi r5,r9,28832
	ctx.r5.s64 = ctx.r9.s64 + 28832;
	// stw r7,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r7.u32);
	// stw r6,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r6.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r5,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r5.u32);
	// stw r31,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r31.u32);
loc_82C984D8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C984F0"))) PPC_WEAK_FUNC(sub_82C984F0);
PPC_FUNC_IMPL(__imp__sub_82C984F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r4,284(r1)
	PPC_STORE_U32(ctx.r1.u32 + 284, ctx.r4.u32);
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// addi r7,r1,223
	ctx.r7.s64 = ctx.r1.s64 + 223;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r10,60(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// addi r4,r1,284
	ctx.r4.s64 = ctx.r1.s64 + 284;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C98530;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r9,284(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// cmplw cr6,r9,r30
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c98544
	if (ctx.cr6.eq) goto loc_82C98544;
loc_82C9853C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c9859c
	goto loc_82C9859C;
loc_82C98544:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r10,0
	ctx.r10.s64 = 0;
	// lis r9,-32255
	ctx.r9.s64 = -2113863680;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// addi r4,r9,2896
	ctx.r4.s64 = ctx.r9.s64 + 2896;
	// stb r10,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r10.u8);
	// bl 0x82c97030
	ctx.lr = 0x82C98560;
	sub_82C97030(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9857c
	if (ctx.cr6.eq) goto loc_82C9857C;
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82c9857c
	if (!ctx.cr6.eq) goto loc_82C9857C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// b 0x82c9859c
	goto loc_82C9859C;
loc_82C9857C:
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82c97ee0
	ctx.lr = 0x82C98584;
	sub_82C97EE0(ctx, base);
	// cmpwi cr6,r3,-1
	ctx.cr6.compare<int32_t>(ctx.r3.s32, -1, ctx.xer);
	// beq cr6,0x82c9853c
	if (ctx.cr6.eq) goto loc_82C9853C;
	// lis r11,-31953
	ctx.r11.s64 = -2094071808;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r11,-5828
	ctx.r9.s64 = ctx.r11.s64 + -5828;
	// lwzx r3,r10,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
loc_82C9859C:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C985B4"))) PPC_WEAK_FUNC(sub_82C985B4);
PPC_FUNC_IMPL(__imp__sub_82C985B4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C985B8"))) PPC_WEAK_FUNC(sub_82C985B8);
PPC_FUNC_IMPL(__imp__sub_82C985B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// lwz r31,220(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// lwz r30,212(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r31.u32);
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r30.u32);
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r11,-31504
	ctx.r3.s64 = ctx.r11.s64 + -31504;
	// bl 0x82c97458
	ctx.lr = 0x82C9860C;
	sub_82C97458(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C98624"))) PPC_WEAK_FUNC(sub_82C98624);
PPC_FUNC_IMPL(__imp__sub_82C98624) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C98628"))) PPC_WEAK_FUNC(sub_82C98628);
PPC_FUNC_IMPL(__imp__sub_82C98628) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x82c97be0
	ctx.lr = 0x82C98638;
	sub_82C97BE0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c98648
	if (ctx.cr6.eq) goto loc_82C98648;
	// li r11,23
	ctx.r11.s64 = 23;
	// stb r11,134(r3)
	PPC_STORE_U8(ctx.r3.u32 + 134, ctx.r11.u8);
loc_82C98648:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C98658"))) PPC_WEAK_FUNC(sub_82C98658);
PPC_FUNC_IMPL(__imp__sub_82C98658) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C98660;
	sub_82CA2BEC(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r31
	ctx.r30.u64 = ctx.r31.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c986a8
	if (ctx.cr6.eq) goto loc_82C986A8;
loc_82C98678:
	// lwz r31,4(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// lwz r11,20(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9868C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9869C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r30,r31
	ctx.r30.u64 = ctx.r31.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82c98678
	if (!ctx.cr6.eq) goto loc_82C98678;
loc_82C986A8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
}

__attribute__((alias("__imp__sub_82C986B0"))) PPC_WEAK_FUNC(sub_82C986B0);
PPC_FUNC_IMPL(__imp__sub_82C986B0) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r4,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r4.u32);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bnelr cr6
	if (!ctx.cr6.eq) return;
	// stw r4,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r4.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C986CC"))) PPC_WEAK_FUNC(sub_82C986CC);
PPC_FUNC_IMPL(__imp__sub_82C986CC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C986D0"))) PPC_WEAK_FUNC(sub_82C986D0);
PPC_FUNC_IMPL(__imp__sub_82C986D0) {
	PPC_FUNC_PROLOGUE();
	// stw r4,52(r3)
	PPC_STORE_U32(ctx.r3.u32 + 52, ctx.r4.u32);
	// stw r5,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, ctx.r5.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C986DC"))) PPC_WEAK_FUNC(sub_82C986DC);
PPC_FUNC_IMPL(__imp__sub_82C986DC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C986E0"))) PPC_WEAK_FUNC(sub_82C986E0);
PPC_FUNC_IMPL(__imp__sub_82C986E0) {
	PPC_FUNC_PROLOGUE();
	// stw r4,60(r3)
	PPC_STORE_U32(ctx.r3.u32 + 60, ctx.r4.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C986E8"))) PPC_WEAK_FUNC(sub_82C986E8);
PPC_FUNC_IMPL(__imp__sub_82C986E8) {
	PPC_FUNC_PROLOGUE();
	// stw r4,72(r3)
	PPC_STORE_U32(ctx.r3.u32 + 72, ctx.r4.u32);
	// stw r5,76(r3)
	PPC_STORE_U32(ctx.r3.u32 + 76, ctx.r5.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C986F4"))) PPC_WEAK_FUNC(sub_82C986F4);
PPC_FUNC_IMPL(__imp__sub_82C986F4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C986F8"))) PPC_WEAK_FUNC(sub_82C986F8);
PPC_FUNC_IMPL(__imp__sub_82C986F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C98700;
	sub_82CA2BEC(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,480(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82c98898
	if (ctx.cr6.eq) goto loc_82C98898;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82c98884
	if (ctx.cr6.eq) goto loc_82C98884;
	// lwz r6,32(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// subf r10,r11,r6
	ctx.r10.s64 = ctx.r6.s64 - ctx.r11.s64;
	// cmpw cr6,r4,r10
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r10.s32, ctx.xer);
	// ble cr6,0x82c98878
	if (!ctx.cr6.gt) goto loc_82C98878;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// subf r8,r9,r11
	ctx.r8.s64 = ctx.r11.s64 - ctx.r9.s64;
	// subf r10,r3,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r3.s64;
	// add r7,r8,r4
	ctx.r7.u64 = ctx.r8.u64 + ctx.r4.u64;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,1024
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1024, ctx.xer);
	// ble cr6,0x82c98754
	if (!ctx.cr6.gt) goto loc_82C98754;
	// li r11,1024
	ctx.r11.s64 = 1024;
loc_82C98754:
	// add r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 + ctx.r7.u64;
	// subf r5,r3,r6
	ctx.r5.s64 = ctx.r6.s64 - ctx.r3.s64;
	// cmpw cr6,r7,r5
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, ctx.xer);
	// bgt cr6,0x82c987a0
	if (ctx.cr6.gt) goto loc_82C987A0;
	// cmpw cr6,r11,r10
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r10.s32, ctx.xer);
	// bge cr6,0x82c98878
	if (!ctx.cr6.lt) goto loc_82C98878;
	// subf r30,r11,r10
	ctx.r30.s64 = ctx.r10.s64 - ctx.r11.s64;
	// add r5,r8,r11
	ctx.r5.u64 = ctx.r8.u64 + ctx.r11.u64;
	// add r4,r3,r30
	ctx.r4.u64 = ctx.r3.u64 + ctx.r30.u64;
	// bl 0x82caa2e0
	ctx.lr = 0x82C9877C;
	sub_82CAA2E0(ctx, base);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// subf r9,r30,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r30.s64;
	// subf r8,r30,r10
	ctx.r8.s64 = ctx.r10.s64 - ctx.r30.s64;
	// stw r9,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r9.u32);
	// rotlwi r3,r9,0
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// stw r8,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r8.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C987A0:
	// subf. r29,r9,r6
	ctx.r29.s64 = ctx.r6.s64 - ctx.r9.s64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// bne 0x82c987ac
	if (!ctx.cr0.eq) goto loc_82C987AC;
	// li r29,1024
	ctx.r29.s64 = 1024;
loc_82C987AC:
	// rlwinm r29,r29,1,0,30
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
	// cmpw cr6,r29,r7
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r7.s32, ctx.xer);
	// blt cr6,0x82c987ac
	if (ctx.cr6.lt) goto loc_82C987AC;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C987C8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82c987e4
	if (!ctx.cr6.eq) goto loc_82C987E4;
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 284, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C987E4:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// add r10,r30,r29
	ctx.r10.u64 = ctx.r30.u64 + ctx.r29.u64;
	// stw r10,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r10.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c98864
	if (ctx.cr6.eq) goto loc_82C98864;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// subf r29,r10,r11
	ctx.r29.s64 = ctx.r11.s64 - ctx.r10.s64;
	// cmpwi cr6,r29,1024
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 1024, ctx.xer);
	// ble cr6,0x82c9880c
	if (!ctx.cr6.gt) goto loc_82C9880C;
	// li r29,1024
	ctx.r29.s64 = 1024;
loc_82C9880C:
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// subf r4,r29,r11
	ctx.r4.s64 = ctx.r11.s64 - ctx.r29.s64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// add r5,r11,r29
	ctx.r5.u64 = ctx.r11.u64 + ctx.r29.u64;
	// bl 0x82ca2c60
	ctx.lr = 0x82C98824;
	sub_82CA2C60(ctx, base);
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C98834;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r7,28(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// add r8,r29,r30
	ctx.r8.u64 = ctx.r29.u64 + ctx.r30.u64;
	// stw r30,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r30.u32);
	// subf r11,r6,r7
	ctx.r11.s64 = ctx.r7.s64 - ctx.r6.s64;
	// stw r8,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r8.u32);
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// add r5,r11,r30
	ctx.r5.u64 = ctx.r11.u64 + ctx.r30.u64;
	// stw r5,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r5.u32);
	// rotlwi r3,r5,0
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r5.u32, 0);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C98864:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r30,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r30.u32);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// stw r30,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r30.u32);
	// stw r11,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r11.u32);
loc_82C98878:
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C98884:
	// li r11,33
	ctx.r11.s64 = 33;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 284, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C98898:
	// li r11,36
	ctx.r11.s64 = 36;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 284, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
}

__attribute__((alias("__imp__sub_82C988AC"))) PPC_WEAK_FUNC(sub_82C988AC);
PPC_FUNC_IMPL(__imp__sub_82C988AC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C988B0"))) PPC_WEAK_FUNC(sub_82C988B0);
PPC_FUNC_IMPL(__imp__sub_82C988B0) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,288(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 288);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c988d0
	if (ctx.cr6.eq) goto loc_82C988D0;
	// lwz r10,36(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// lwz r9,40(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + ctx.r11.u64;
	// blr 
	return;
loc_82C988D0:
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C988D8"))) PPC_WEAK_FUNC(sub_82C988D8);
PPC_FUNC_IMPL(__imp__sub_82C988D8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r5,288(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 288);
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82c98924
	if (ctx.cr6.eq) goto loc_82C98924;
	// lwz r4,296(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 296);
	// cmplw cr6,r5,r4
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r4.u32, ctx.xer);
	// blt cr6,0x82c98924
	if (ctx.cr6.lt) goto loc_82C98924;
	// lwz r11,144(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// addi r6,r31,408
	ctx.r6.s64 = ctx.r31.s64 + 408;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9891C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r9,288(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 288);
	// stw r9,296(r31)
	PPC_STORE_U32(ctx.r31.u32 + 296, ctx.r9.u32);
loc_82C98924:
	// lwz r11,408(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 408);
	// addi r3,r11,1
	ctx.r3.s64 = ctx.r11.s64 + 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C98940"))) PPC_WEAK_FUNC(sub_82C98940);
PPC_FUNC_IMPL(__imp__sub_82C98940) {
	PPC_FUNC_PROLOGUE();
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// ble cr6,0x82c98964
	if (!ctx.cr6.gt) goto loc_82C98964;
	// cmplwi cr6,r3,38
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 38, ctx.xer);
	// bge cr6,0x82c98964
	if (!ctx.cr6.lt) goto loc_82C98964;
	// lis r11,-31953
	ctx.r11.s64 = -2094071808;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r11,-5800
	ctx.r9.s64 = ctx.r11.s64 + -5800;
	// lwzx r3,r10,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// blr 
	return;
loc_82C98964:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9896C"))) PPC_WEAK_FUNC(sub_82C9896C);
PPC_FUNC_IMPL(__imp__sub_82C9896C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C98970"))) PPC_WEAK_FUNC(sub_82C98970);
PPC_FUNC_IMPL(__imp__sub_82C98970) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C98978;
	sub_82CA2BE4(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// lwz r31,364(r27)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r27.u32 + 364);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c98a34
	if (ctx.cr6.eq) goto loc_82C98A34;
loc_82C9898C:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r3,36(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// addi r28,r11,1
	ctx.r28.s64 = ctx.r11.s64 + 1;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// add r30,r3,r28
	ctx.r30.u64 = ctx.r3.u64 + ctx.r28.u64;
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c98a34
	if (ctx.cr6.eq) goto loc_82C98A34;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// add r29,r28,r11
	ctx.r29.u64 = ctx.r28.u64 + ctx.r11.u64;
	// subf r9,r3,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r3.s64;
	// cmpw cr6,r29,r9
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r9.s32, ctx.xer);
	// ble cr6,0x82c98a14
	if (!ctx.cr6.gt) goto loc_82C98A14;
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C989D0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c98a40
	if (ctx.cr6.eq) goto loc_82C98A40;
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c989ec
	if (!ctx.cr6.eq) goto loc_82C989EC;
	// stw r3,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r3.u32);
loc_82C989EC:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c98a04
	if (ctx.cr6.eq) goto loc_82C98A04;
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
loc_82C98A04:
	// add r11,r3,r29
	ctx.r11.u64 = ctx.r3.u64 + ctx.r29.u64;
	// stw r3,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r3.u32);
	// add r30,r3,r28
	ctx.r30.u64 = ctx.r3.u64 + ctx.r28.u64;
	// stw r11,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r11.u32);
loc_82C98A14:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82ca2c60
	ctx.lr = 0x82C98A24;
	sub_82CA2C60(ctx, base);
	// stw r30,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r30.u32);
	// lwz r31,0(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82c9898c
	if (!ctx.cr6.eq) goto loc_82C9898C;
loc_82C98A34:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
loc_82C98A40:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
}

__attribute__((alias("__imp__sub_82C98A4C"))) PPC_WEAK_FUNC(sub_82C98A4C);
PPC_FUNC_IMPL(__imp__sub_82C98A4C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C98A50"))) PPC_WEAK_FUNC(sub_82C98A50);
PPC_FUNC_IMPL(__imp__sub_82C98A50) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// lbz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 484);
	// lwz r5,144(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// bl 0x82c9eac0
	ctx.lr = 0x82C98A8C;
	sub_82C9EAC0(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82c98ab0
	if (!ctx.cr6.eq) goto loc_82C98AB0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c98970
	ctx.lr = 0x82C98AA0;
	sub_82C98970(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// li r3,1
	ctx.r3.s64 = 1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c98ab4
	if (ctx.cr6.eq) goto loc_82C98AB4;
loc_82C98AB0:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
loc_82C98AB4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C98ACC"))) PPC_WEAK_FUNC(sub_82C98ACC);
PPC_FUNC_IMPL(__imp__sub_82C98ACC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C98AD0"))) PPC_WEAK_FUNC(sub_82C98AD0);
PPC_FUNC_IMPL(__imp__sub_82C98AD0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bd8
	ctx.lr = 0x82C98AD8;
	sub_82CA2BD8(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// mr r24,r7
	ctx.r24.u64 = ctx.r7.u64;
	// lbz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r27.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c98b18
	if (!ctx.cr6.eq) goto loc_82C98B18;
	// lwz r10,0(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c98b18
	if (ctx.cr6.eq) goto loc_82C98B18;
	// li r3,28
	ctx.r3.s64 = 28;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
loc_82C98B18:
	// li r30,0
	ctx.r30.s64 = 0;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c98b34
	if (ctx.cr6.eq) goto loc_82C98B34;
loc_82C98B24:
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// lbzx r11,r30,r27
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + ctx.r27.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c98b24
	if (!ctx.cr6.eq) goto loc_82C98B24;
loc_82C98B34:
	// lbz r11,472(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 472);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c98b44
	if (ctx.cr6.eq) goto loc_82C98B44;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82C98B44:
	// lwz r31,376(r28)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r28.u32 + 376);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c98b90
	if (ctx.cr6.eq) goto loc_82C98B90;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// cmpw cr6,r30,r11
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r11.s32, ctx.xer);
	// ble cr6,0x82c98b84
	if (!ctx.cr6.gt) goto loc_82C98B84;
	// addi r29,r30,24
	ctx.r29.s64 = ctx.r30.s64 + 24;
	// lwz r11,16(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C98B74;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c98bdc
	if (ctx.cr6.eq) goto loc_82C98BDC;
	// stw r3,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r3.u32);
	// stw r29,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r29.u32);
loc_82C98B84:
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r11,376(r28)
	PPC_STORE_U32(ctx.r28.u32 + 376, ctx.r11.u32);
	// b 0x82c98bec
	goto loc_82C98BEC;
loc_82C98B90:
	// lwz r11,12(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 12);
	// li r3,28
	ctx.r3.s64 = 28;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C98BA0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c98bdc
	if (ctx.cr6.eq) goto loc_82C98BDC;
	// addi r29,r30,24
	ctx.r29.s64 = ctx.r30.s64 + 24;
	// lwz r11,12(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 12);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C98BC0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c98be8
	if (!ctx.cr6.eq) goto loc_82C98BE8;
	// lwz r11,20(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 20);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C98BDC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82C98BDC:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
loc_82C98BE8:
	// stw r29,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r29.u32);
loc_82C98BEC:
	// stw r30,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r30.u32);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// bl 0x82ca2c60
	ctx.lr = 0x82C98C00;
	sub_82CA2C60(ctx, base);
	// lbz r11,472(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 472);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c98c18
	if (ctx.cr6.eq) goto loc_82C98C18;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// add r10,r30,r10
	ctx.r10.u64 = ctx.r30.u64 + ctx.r10.u64;
	// stb r11,-1(r10)
	PPC_STORE_U8(ctx.r10.u32 + -1, ctx.r11.u8);
loc_82C98C18:
	// stw r26,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r26.u32);
	// stw r25,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r25.u32);
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// lbz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r27.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c98c50
	if (!ctx.cr6.eq) goto loc_82C98C50;
	// lwz r11,356(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 356);
	// addi r11,r11,152
	ctx.r11.s64 = ctx.r11.s64 + 152;
	// cmplw cr6,r26,r11
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c98c50
	if (!ctx.cr6.eq) goto loc_82C98C50;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,4(r26)
	PPC_STORE_U32(ctx.r26.u32 + 4, ctx.r11.u32);
	// b 0x82c98c54
	goto loc_82C98C54;
loc_82C98C50:
	// stw r31,4(r26)
	PPC_STORE_U32(ctx.r26.u32 + 4, ctx.r31.u32);
loc_82C98C54:
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// stw r31,0(r24)
	PPC_STORE_U32(ctx.r24.u32 + 0, ctx.r31.u32);
	// beq cr6,0x82c98c98
	if (ctx.cr6.eq) goto loc_82C98C98;
	// lwz r11,100(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 100);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c98c98
	if (ctx.cr6.eq) goto loc_82C98C98;
	// lwz r10,4(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c98c88
	if (!ctx.cr6.eq) goto loc_82C98C88;
	// li r5,0
	ctx.r5.s64 = 0;
loc_82C98C88:
	// lwz r4,0(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// lwz r3,4(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C98C98;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82C98C98:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
}

__attribute__((alias("__imp__sub_82C98CA4"))) PPC_WEAK_FUNC(sub_82C98CA4);
PPC_FUNC_IMPL(__imp__sub_82C98CA4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C98CA8"))) PPC_WEAK_FUNC(sub_82C98CA8);
PPC_FUNC_IMPL(__imp__sub_82C98CA8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-1136(r1)
	ea = -1136 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r8,124(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82c98ddc
	if (ctx.cr6.eq) goto loc_82C98DDC;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// li r10,-1
	ctx.r10.s64 = -1;
	// li r9,256
	ctx.r9.s64 = 256;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82C98CD8:
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x82c98cd8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82C98CD8;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,248(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 248);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stw r11,1108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1108, ctx.r11.u32);
	// stw r11,1104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1104, ctx.r11.u32);
	// stw r11,1112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1112, ctx.r11.u32);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82C98D04;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c98dc4
	if (ctx.cr6.eq) goto loc_82C98DC4;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// li r3,1912
	ctx.r3.s64 = 1912;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C98D1C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,240(r31)
	PPC_STORE_U32(ctx.r31.u32 + 240, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c98d58
	if (!ctx.cr6.eq) goto loc_82C98D58;
	// lwz r11,1112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c98d40
	if (ctx.cr6.eq) goto loc_82C98D40;
	// lwz r3,1104(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C98D40;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82C98D40:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,1136
	ctx.r1.s64 = ctx.r1.s64 + 1136;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C98D58:
	// lbz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 236);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c98d70
	if (ctx.cr6.eq) goto loc_82C98D70;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r11,r11,-31192
	ctx.r11.s64 = ctx.r11.s64 + -31192;
	// b 0x82c98d78
	goto loc_82C98D78;
loc_82C98D70:
	// lis r11,-32055
	ctx.r11.s64 = -2100756480;
	// addi r11,r11,31712
	ctx.r11.s64 = ctx.r11.s64 + 31712;
loc_82C98D78:
	// lwz r6,1104(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r5,1108(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1108);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C98D8C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c98dc4
	if (ctx.cr6.eq) goto loc_82C98DC4;
	// lwz r10,1104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r9,1112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	// stw r11,144(r31)
	PPC_STORE_U32(ctx.r31.u32 + 144, ctx.r11.u32);
	// stw r10,244(r31)
	PPC_STORE_U32(ctx.r31.u32 + 244, ctx.r10.u32);
	// stw r9,252(r31)
	PPC_STORE_U32(ctx.r31.u32 + 252, ctx.r9.u32);
	// addi r1,r1,1136
	ctx.r1.s64 = ctx.r1.s64 + 1136;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C98DC4:
	// lwz r11,1112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1112);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c98ddc
	if (ctx.cr6.eq) goto loc_82C98DDC;
	// lwz r3,1104(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1104);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C98DDC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82C98DDC:
	// li r3,18
	ctx.r3.s64 = 18;
	// addi r1,r1,1136
	ctx.r1.s64 = ctx.r1.s64 + 1136;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C98DF4"))) PPC_WEAK_FUNC(sub_82C98DF4);
PPC_FUNC_IMPL(__imp__sub_82C98DF4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C98DF8"))) PPC_WEAK_FUNC(sub_82C98DF8);
PPC_FUNC_IMPL(__imp__sub_82C98DF8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C98E00;
	sub_82CA2BE0(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// lwz r30,304(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 304);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c98eb4
	if (ctx.cr6.eq) goto loc_82C98EB4;
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stw r11,304(r31)
	PPC_STORE_U32(ctx.r31.u32 + 304, ctx.r11.u32);
loc_82C98E24:
	// li r26,0
	ctx.r26.s64 = 0;
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r26,12(r29)
	PPC_STORE_U32(ctx.r29.u32 + 12, ctx.r26.u32);
	// stb r11,32(r29)
	PPC_STORE_U8(ctx.r29.u32 + 32, ctx.r11.u8);
	// lwz r10,300(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 300);
	// stw r10,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r10.u32);
	// stw r30,300(r31)
	PPC_STORE_U32(ctx.r31.u32 + 300, ctx.r30.u32);
	// stw r29,12(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12, ctx.r29.u32);
	// lwz r9,312(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 312);
	// stw r9,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r9.u32);
	// stb r28,20(r30)
	PPC_STORE_U8(ctx.r30.u32 + 20, ctx.r28.u8);
	// stw r26,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r26.u32);
	// stw r26,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r26.u32);
	// lwz r28,4(r29)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// lbz r8,33(r29)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r29.u32 + 33);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// add r27,r11,r28
	ctx.r27.u64 = ctx.r11.u64 + ctx.r28.u64;
	// beq cr6,0x82c98edc
	if (ctx.cr6.eq) goto loc_82C98EDC;
	// lwz r3,228(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 228);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C98E8C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r4,228(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 228);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c9fb58
	ctx.lr = 0x82C98EB0;
	sub_82C9FB58(ctx, base);
	// b 0x82c98efc
	goto loc_82C98EFC;
loc_82C98EB4:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// li r3,24
	ctx.r3.s64 = 24;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C98EC4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82c98e24
	if (!ctx.cr6.eq) goto loc_82C98E24;
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C98EDC:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r5,228(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 228);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lwz r4,312(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 312);
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c9eac0
	ctx.lr = 0x82C98EFC;
	sub_82C9EAC0(ctx, base);
loc_82C98EFC:
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c98f50
	if (!ctx.cr6.eq) goto loc_82C98F50;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82c98f38
	if (ctx.cr6.eq) goto loc_82C98F38;
	// lwz r10,480(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// cmpwi cr6,r10,3
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 3, ctx.xer);
	// bne cr6,0x82c98f38
	if (!ctx.cr6.eq) goto loc_82C98F38;
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// subf r9,r28,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r28.s64;
	// addi r8,r10,6088
	ctx.r8.s64 = ctx.r10.s64 + 6088;
	// stw r9,12(r29)
	PPC_STORE_U32(ctx.r29.u32 + 12, ctx.r9.u32);
	// stw r8,280(r31)
	PPC_STORE_U32(ctx.r31.u32 + 280, ctx.r8.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C98F38:
	// stb r26,32(r29)
	PPC_STORE_U8(ctx.r29.u32 + 32, ctx.r26.u8);
	// lwz r11,304(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 304);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stw r10,300(r31)
	PPC_STORE_U32(ctx.r31.u32 + 300, ctx.r10.u32);
	// stw r11,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r11.u32);
	// stw r30,304(r31)
	PPC_STORE_U32(ctx.r31.u32 + 304, ctx.r30.u32);
loc_82C98F50:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
}

__attribute__((alias("__imp__sub_82C98F58"))) PPC_WEAK_FUNC(sub_82C98F58);
PPC_FUNC_IMPL(__imp__sub_82C98F58) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82C98F68:
	// cmpwi cr6,r11,13
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 13, ctx.xer);
	// beq cr6,0x82c98f88
	if (ctx.cr6.eq) goto loc_82C98F88;
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// lbz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c98f68
	if (!ctx.cr6.eq) goto loc_82C98F68;
	// blr 
	return;
loc_82C98F88:
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// li r9,10
	ctx.r9.s64 = 10;
loc_82C98F90:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r10,13
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 13, ctx.xer);
	// bne cr6,0x82c98fbc
	if (!ctx.cr6.eq) goto loc_82C98FBC;
	// stb r9,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r9.u8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// cmplwi cr6,r10,10
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 10, ctx.xer);
	// bne cr6,0x82c98fc4
	if (!ctx.cr6.eq) goto loc_82C98FC4;
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// b 0x82c98fc4
	goto loc_82C98FC4;
loc_82C98FBC:
	// stb r10,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r10.u8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82C98FC4:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c98f90
	if (!ctx.cr6.eq) goto loc_82C98F90;
	// stb r10,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C98FD8"))) PPC_WEAK_FUNC(sub_82C98FD8);
PPC_FUNC_IMPL(__imp__sub_82C98FD8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C98FE0;
	sub_82CA2BE4(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r4,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r4.u32);
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// lbz r11,72(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 72);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9908c
	if (!ctx.cr6.eq) goto loc_82C9908C;
	// lwz r11,144(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9901c
	if (!ctx.cr6.eq) goto loc_82C9901C;
	// addi r29,r31,288
	ctx.r29.s64 = ctx.r31.s64 + 288;
	// addi r27,r31,292
	ctx.r27.s64 = ctx.r31.s64 + 292;
	// b 0x82c99024
	goto loc_82C99024;
loc_82C9901C:
	// lwz r29,300(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 300);
	// addi r27,r29,4
	ctx.r27.s64 = ctx.r29.s64 + 4;
loc_82C99024:
	// lwz r11,44(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r7,48(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// lwz r10,60(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	// addi r4,r1,180
	ctx.r4.s64 = ctx.r1.s64 + 180;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9904C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r9,180(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r9,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r9.u32);
	// lwz r4,44(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// subf r5,r4,r8
	ctx.r5.s64 = ctx.r8.s64 - ctx.r4.s64;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r7,80(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
	// bctrl 
	ctx.lr = 0x82C99070;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// stw r6,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r6.u32);
	// lwz r5,180(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// cmplw cr6,r5,r28
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c99024
	if (!ctx.cr6.eq) goto loc_82C99024;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
loc_82C9908C:
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// subf r5,r4,r28
	ctx.r5.s64 = ctx.r28.s64 - ctx.r4.s64;
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C990A0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
}

__attribute__((alias("__imp__sub_82C990A8"))) PPC_WEAK_FUNC(sub_82C990A8);
PPC_FUNC_IMPL(__imp__sub_82C990A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C990B0;
	sub_82CA2BE4(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// bne cr6,0x82c990d8
	if (!ctx.cr6.eq) goto loc_82C990D8;
	// clrlwi r11,r6,24
	ctx.r11.u64 = ctx.r6.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c99134
	if (ctx.cr6.eq) goto loc_82C99134;
loc_82C990D8:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x82c9910c
	if (!ctx.cr6.gt) goto loc_82C9910C;
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
loc_82C990EC:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r29,r9
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82c991f0
	if (ctx.cr6.eq) goto loc_82C991F0;
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
	// cmpw cr6,r10,r9
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, ctx.xer);
	// blt cr6,0x82c990ec
	if (ctx.cr6.lt) goto loc_82C990EC;
loc_82C9910C:
	// clrlwi r11,r6,24
	ctx.r11.u64 = ctx.r6.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c99134
	if (ctx.cr6.eq) goto loc_82C99134;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c99134
	if (!ctx.cr6.eq) goto loc_82C99134;
	// lbz r11,9(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 9);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c99134
	if (!ctx.cr6.eq) goto loc_82C99134;
	// stw r29,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r29.u32);
loc_82C99134:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmpw cr6,r10,r11
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r11.s32, ctx.xer);
	// bne cr6,0x82c991ac
	if (!ctx.cr6.eq) goto loc_82C991AC;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c9917c
	if (!ctx.cr6.eq) goto loc_82C9917C;
	// li r11,8
	ctx.r11.s64 = 8;
	// li r3,96
	ctx.r3.s64 = 96;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// lwz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C99164;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c991ac
	if (!ctx.cr6.eq) goto loc_82C991AC;
loc_82C99170:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
loc_82C9917C:
	// rlwinm r30,r11,1,0,30
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r10,16(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// add r9,r30,r11
	ctx.r9.u64 = ctx.r30.u64 + ctx.r11.u64;
	// rlwinm r4,r9,2,0,29
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9919C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c99170
	if (ctx.cr6.eq) goto loc_82C99170;
	// stw r30,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r30.u32);
	// stw r3,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r3.u32);
loc_82C991AC:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// clrlwi r8,r28,24
	ctx.r8.u64 = ctx.r28.u32 & 0xFF;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// add r7,r11,r9
	ctx.r7.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r29,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r29.u32);
	// stw r27,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r27.u32);
	// stb r28,4(r11)
	PPC_STORE_U8(ctx.r11.u32 + 4, ctx.r28.u8);
	// bne cr6,0x82c991e4
	if (!ctx.cr6.eq) goto loc_82C991E4;
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,8(r29)
	PPC_STORE_U8(ctx.r29.u32 + 8, ctx.r11.u8);
loc_82C991E4:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
loc_82C991F0:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
}

__attribute__((alias("__imp__sub_82C991FC"))) PPC_WEAK_FUNC(sub_82C991FC);
PPC_FUNC_IMPL(__imp__sub_82C991FC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C99200"))) PPC_WEAK_FUNC(sub_82C99200);
PPC_FUNC_IMPL(__imp__sub_82C99200) {
	PPC_FUNC_PROLOGUE();
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c9928c
	if (ctx.cr6.eq) goto loc_82C9928C;
	// li r7,32
	ctx.r7.s64 = 32;
loc_82C99218:
	// lbz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// extsb r10,r9
	ctx.r10.s64 = ctx.r9.s8;
	// cmpwi cr6,r10,10
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 10, ctx.xer);
	// beq cr6,0x82c99240
	if (ctx.cr6.eq) goto loc_82C99240;
	// cmpwi cr6,r10,13
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 13, ctx.xer);
	// beq cr6,0x82c99240
	if (ctx.cr6.eq) goto loc_82C99240;
	// cmpwi cr6,r10,32
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 32, ctx.xer);
	// beq cr6,0x82c99240
	if (ctx.cr6.eq) goto loc_82C99240;
	// stb r9,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r9.u8);
	// b 0x82c99258
	goto loc_82C99258;
loc_82C99240:
	// cmplw cr6,r11,r3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r3.u32, ctx.xer);
	// beq cr6,0x82c9925c
	if (ctx.cr6.eq) goto loc_82C9925C;
	// lbz r10,-1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + -1);
	// cmplwi cr6,r10,32
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 32, ctx.xer);
	// beq cr6,0x82c9925c
	if (ctx.cr6.eq) goto loc_82C9925C;
	// stb r7,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r7.u8);
loc_82C99258:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82C9925C:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// lbz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c99218
	if (!ctx.cr6.eq) goto loc_82C99218;
	// cmplw cr6,r11,r3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r3.u32, ctx.xer);
	// beq cr6,0x82c9928c
	if (ctx.cr6.eq) goto loc_82C9928C;
	// lbz r10,-1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + -1);
	// cmplwi cr6,r10,32
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 32, ctx.xer);
	// li r10,0
	ctx.r10.s64 = 0;
	// bne cr6,0x82c99290
	if (!ctx.cr6.eq) goto loc_82C99290;
	// stb r10,-1(r11)
	PPC_STORE_U8(ctx.r11.u32 + -1, ctx.r10.u8);
	// blr 
	return;
loc_82C9928C:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82C99290:
	// stb r10,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C99298"))) PPC_WEAK_FUNC(sub_82C99298);
PPC_FUNC_IMPL(__imp__sub_82C99298) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bd0
	ctx.lr = 0x82C992A0;
	sub_82CA2BD0(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// mr r22,r5
	ctx.r22.u64 = ctx.r5.u64;
	// lwz r3,8(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c99364
	if (!ctx.cr6.eq) goto loc_82C99364;
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// bne cr6,0x82c992d0
	if (!ctx.cr6.eq) goto loc_82C992D0;
loc_82C992C4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	// ERROR 82CA2C20
	return;
loc_82C992D0:
	// lwz r11,16(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// li r10,6
	ctx.r10.s64 = 6;
	// li r9,64
	ctx.r9.s64 = 64;
	// stb r10,4(r28)
	PPC_STORE_U8(ctx.r28.u32 + 4, ctx.r10.u8);
	// li r3,256
	ctx.r3.s64 = 256;
	// stw r9,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r9.u32);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82C992F4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c99310
	if (!ctx.cr6.eq) goto loc_82C99310;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r11.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	// ERROR 82CA2C20
	return;
loc_82C99310:
	// li r5,256
	ctx.r5.s64 = 256;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82ca3190
	ctx.lr = 0x82C9931C;
	sub_82CA3190(ctx, base);
	// lbz r10,0(r23)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r23.u32 + 0);
	// mr r11,r23
	ctx.r11.u64 = ctx.r23.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c99354
	if (ctx.cr6.eq) goto loc_82C99354;
	// lis r8,15
	ctx.r8.s64 = 983040;
	// ori r25,r8,16963
	ctx.r25.u64 = ctx.r8.u64 | 16963;
loc_82C99338:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// clrlwi r8,r10,24
	ctx.r8.u64 = ctx.r10.u32 & 0xFF;
	// mullw r7,r9,r25
	ctx.r7.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r25.s32);
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// xor r9,r7,r8
	ctx.r9.u64 = ctx.r7.u64 ^ ctx.r8.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c99338
	if (!ctx.cr6.eq) goto loc_82C99338;
loc_82C99354:
	// lwz r11,8(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// and r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 & ctx.r9.u64;
	// b 0x82c99650
	goto loc_82C99650;
loc_82C99364:
	// lbz r10,0(r23)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r23.u32 + 0);
	// lis r9,15
	ctx.r9.s64 = 983040;
	// mr r11,r23
	ctx.r11.u64 = ctx.r23.u64;
	// extsb r4,r10
	ctx.r4.s64 = ctx.r10.s8;
	// ori r25,r9,16963
	ctx.r25.u64 = ctx.r9.u64 | 16963;
	// li r24,0
	ctx.r24.s64 = 0;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x82c993a0
	if (ctx.cr6.eq) goto loc_82C993A0;
loc_82C99384:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// clrlwi r9,r10,24
	ctx.r9.u64 = ctx.r10.u32 & 0xFF;
	// mullw r8,r24,r25
	ctx.r8.s64 = int64_t(ctx.r24.s32) * int64_t(ctx.r25.s32);
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// xor r24,r8,r9
	ctx.r24.u64 = ctx.r8.u64 ^ ctx.r9.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c99384
	if (!ctx.cr6.eq) goto loc_82C99384;
loc_82C993A0:
	// addi r7,r3,-1
	ctx.r7.s64 = ctx.r3.s64 + -1;
	// lwz r5,0(r28)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// and r9,r24,r7
	ctx.r9.u64 = ctx.r24.u64 & ctx.r7.u64;
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c99478
	if (ctx.cr6.eq) goto loc_82C99478;
loc_82C993C0:
	// lwzx r11,r11,r5
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r8,r10
	ctx.r8.s64 = ctx.r10.s8;
	// cmpw cr6,r4,r8
	ctx.cr6.compare<int32_t>(ctx.r4.s32, ctx.r8.s32, ctx.xer);
	// bne cr6,0x82c99404
	if (!ctx.cr6.eq) goto loc_82C99404;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// subf r8,r11,r23
	ctx.r8.s64 = ctx.r23.s64 - ctx.r11.s64;
loc_82C993E0:
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82c99458
	if (ctx.cr6.eq) goto loc_82C99458;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lbzx r10,r8,r11
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r11.u32);
	// lbz r31,0(r11)
	ctx.r31.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// extsb r31,r31
	ctx.r31.s64 = ctx.r31.s8;
	// cmpw cr6,r10,r31
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r31.s32, ctx.xer);
	// beq cr6,0x82c993e0
	if (ctx.cr6.eq) goto loc_82C993E0;
loc_82C99404:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82C99408:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9962c
	if (!ctx.cr6.eq) goto loc_82C9962C;
	// clrlwi r11,r6,24
	ctx.r11.u64 = ctx.r6.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c99440
	if (!ctx.cr6.eq) goto loc_82C99440;
	// lbz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// andc r10,r24,r7
	ctx.r10.u64 = ctx.r24.u64 & ~ctx.r7.u64;
	// rlwinm r8,r7,30,2,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r6,r11,-1
	ctx.r6.s64 = ctx.r11.s64 + -1;
	// srw r11,r10,r6
	ctx.r11.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r6.u8 & 0x3F));
	// and r10,r11,r8
	ctx.r10.u64 = ctx.r11.u64 & ctx.r8.u64;
	// clrlwi r8,r10,24
	ctx.r8.u64 = ctx.r10.u32 & 0xFF;
	// ori r6,r8,1
	ctx.r6.u64 = ctx.r8.u64 | 1;
loc_82C99440:
	// clrlwi r11,r6,24
	ctx.r11.u64 = ctx.r6.u32 & 0xFF;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82c99460
	if (!ctx.cr6.lt) goto loc_82C99460;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// b 0x82c99464
	goto loc_82C99464;
loc_82C99458:
	// li r11,1
	ctx.r11.s64 = 1;
	// b 0x82c99408
	goto loc_82C99408;
loc_82C99460:
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r11.s64;
loc_82C99464:
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c993c0
	if (!ctx.cr6.eq) goto loc_82C993C0;
loc_82C99478:
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82c992c4
	if (ctx.cr6.eq) goto loc_82C992C4;
	// lbz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// lwz r10,12(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 12);
	// addi r8,r11,-1
	ctx.r8.s64 = ctx.r11.s64 + -1;
	// srw. r7,r10,r8
	ctx.r7.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r8.u8 & 0x3F));
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq 0x82c99650
	if (ctx.cr0.eq) goto loc_82C99650;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// li r9,1
	ctx.r9.s64 = 1;
	// clrlwi r26,r11,24
	ctx.r26.u64 = ctx.r11.u32 & 0xFF;
	// slw r27,r9,r26
	ctx.r27.u64 = ctx.r26.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r26.u8 & 0x3F));
	// rlwinm r31,r27,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r29,r27,-1
	ctx.r29.s64 = ctx.r27.s64 + -1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82C994C0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c992c4
	if (ctx.cr6.eq) goto loc_82C992C4;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82ca3190
	ctx.lr = 0x82C994D8;
	sub_82CA3190(ctx, base);
	// lwz r11,8(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// li r5,0
	ctx.r5.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82c995b0
	if (!ctx.cr6.gt) goto loc_82C995B0;
	// li r6,0
	ctx.r6.s64 = 0;
loc_82C994EC:
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lwzx r10,r6,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r11.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c9959c
	if (ctx.cr6.eq) goto loc_82C9959C;
	// rotlwi r7,r10,0
	ctx.r7.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r11,0(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c99530
	if (ctx.cr6.eq) goto loc_82C99530;
loc_82C99514:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// clrlwi r8,r10,24
	ctx.r8.u64 = ctx.r10.u32 & 0xFF;
	// mullw r4,r9,r25
	ctx.r4.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r25.s32);
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// xor r9,r4,r8
	ctx.r9.u64 = ctx.r4.u64 ^ ctx.r8.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c99514
	if (!ctx.cr6.eq) goto loc_82C99514;
loc_82C99530:
	// and r11,r9,r29
	ctx.r11.u64 = ctx.r9.u64 & ctx.r29.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r10,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r30.u32);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c99594
	if (ctx.cr6.eq) goto loc_82C99594;
loc_82C99548:
	// clrlwi r10,r8,24
	ctx.r10.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c99570
	if (!ctx.cr6.eq) goto loc_82C99570;
	// andc r10,r9,r29
	ctx.r10.u64 = ctx.r9.u64 & ~ctx.r29.u64;
	// addi r8,r26,-1
	ctx.r8.s64 = ctx.r26.s64 + -1;
	// rlwinm r4,r29,30,2,31
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 30) & 0x3FFFFFFF;
	// srw r3,r10,r8
	ctx.r3.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r8.u8 & 0x3F));
	// and r10,r3,r4
	ctx.r10.u64 = ctx.r3.u64 & ctx.r4.u64;
	// clrlwi r8,r10,24
	ctx.r8.u64 = ctx.r10.u32 & 0xFF;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
loc_82C99570:
	// clrlwi r10,r8,24
	ctx.r10.u64 = ctx.r8.u32 & 0xFF;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// subf r11,r10,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r10.s64;
	// bge cr6,0x82c99584
	if (!ctx.cr6.lt) goto loc_82C99584;
	// add r11,r11,r27
	ctx.r11.u64 = ctx.r11.u64 + ctx.r27.u64;
loc_82C99584:
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r10,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r30.u32);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82c99548
	if (!ctx.cr6.eq) goto loc_82C99548;
loc_82C99594:
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r7,r11,r30
	PPC_STORE_U32(ctx.r11.u32 + ctx.r30.u32, ctx.r7.u32);
loc_82C9959C:
	// lwz r11,8(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82c994ec
	if (ctx.cr6.lt) goto loc_82C994EC;
loc_82C995B0:
	// lwz r11,16(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C995C4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// and r9,r24,r29
	ctx.r9.u64 = ctx.r24.u64 & ctx.r29.u64;
	// stw r30,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r30.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stb r26,4(r28)
	PPC_STORE_U8(ctx.r28.u32 + 4, ctx.r26.u8);
	// stw r27,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r27.u32);
	// lwzx r7,r8,r30
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r30.u32);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82c99650
	if (ctx.cr6.eq) goto loc_82C99650;
	// rotlwi r8,r30,0
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r30.u32, 0);
loc_82C995EC:
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c99614
	if (!ctx.cr6.eq) goto loc_82C99614;
	// addi r10,r26,-1
	ctx.r10.s64 = ctx.r26.s64 + -1;
	// andc r11,r24,r29
	ctx.r11.u64 = ctx.r24.u64 & ~ctx.r29.u64;
	// rlwinm r7,r29,30,2,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r29.u32 | (ctx.r29.u64 << 32), 30) & 0x3FFFFFFF;
	// srw r6,r11,r10
	ctx.r6.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r11.u32 >> (ctx.r10.u8 & 0x3F));
	// and r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 & ctx.r7.u64;
	// clrlwi r4,r5,24
	ctx.r4.u64 = ctx.r5.u32 & 0xFF;
	// ori r10,r4,1
	ctx.r10.u64 = ctx.r4.u64 | 1;
loc_82C99614:
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82c9963c
	if (!ctx.cr6.lt) goto loc_82C9963C;
	// subf r11,r11,r27
	ctx.r11.s64 = ctx.r27.s64 - ctx.r11.s64;
	// add r9,r11,r9
	ctx.r9.u64 = ctx.r11.u64 + ctx.r9.u64;
	// b 0x82c99640
	goto loc_82C99640;
loc_82C9962C:
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r5
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r5.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	// ERROR 82CA2C20
	return;
loc_82C9963C:
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r11.s64;
loc_82C99640:
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r11,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c995ec
	if (!ctx.cr6.eq) goto loc_82C995EC;
loc_82C99650:
	// lwz r11,16(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// rlwinm r31,r9,2,0,29
	ctx.r31.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C99668;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r9,0(r28)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// stwx r3,r31,r9
	PPC_STORE_U32(ctx.r31.u32 + ctx.r9.u32, ctx.r3.u32);
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lwzx r8,r31,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r11.u32);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82c992c4
	if (ctx.cr6.eq) goto loc_82C992C4;
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// rotlwi r3,r8,0
	ctx.r3.u64 = __builtin_rotateleft32(ctx.r8.u32, 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82ca3190
	ctx.lr = 0x82C99690;
	sub_82CA3190(ctx, base);
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lwzx r10,r31,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r11.u32);
	// stw r23,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r23.u32);
	// lwz r11,12(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 12);
	// lwz r9,0(r28)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// addi r8,r11,1
	ctx.r8.s64 = ctx.r11.s64 + 1;
	// stw r8,12(r28)
	PPC_STORE_U32(ctx.r28.u32 + 12, ctx.r8.u32);
	// lwzx r3,r31,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r9.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c20
	// ERROR 82CA2C20
	return;
}

__attribute__((alias("__imp__sub_82C996B8"))) PPC_WEAK_FUNC(sub_82C996B8);
PPC_FUNC_IMPL(__imp__sub_82C996B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C996C0;
	sub_82CA2BEC(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r29,0
	ctx.r29.s64 = 0;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82c99708
	if (!ctx.cr6.gt) goto loc_82C99708;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82C996DC:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwzx r3,r30,r10
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r10.u32);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C996F4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r29,r8
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r8.u32, ctx.xer);
	// blt cr6,0x82c996dc
	if (ctx.cr6.lt) goto loc_82C996DC;
loc_82C99708:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9971C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
}

__attribute__((alias("__imp__sub_82C99724"))) PPC_WEAK_FUNC(sub_82C99724);
PPC_FUNC_IMPL(__imp__sub_82C99724) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C99728"))) PPC_WEAK_FUNC(sub_82C99728);
PPC_FUNC_IMPL(__imp__sub_82C99728) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// bne cr6,0x82c99740
	if (!ctx.cr6.eq) goto loc_82C99740;
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r11.u32);
	// b 0x82c99764
	goto loc_82C99764;
loc_82C99740:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c99764
	if (ctx.cr6.eq) goto loc_82C99764;
loc_82C99748:
	// lwz r9,4(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r11.u32);
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// bne cr6,0x82c99748
	if (!ctx.cr6.eq) goto loc_82C99748;
loc_82C99764:
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9977C"))) PPC_WEAK_FUNC(sub_82C9977C);
PPC_FUNC_IMPL(__imp__sub_82C9977C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C99780"))) PPC_WEAK_FUNC(sub_82C99780);
PPC_FUNC_IMPL(__imp__sub_82C99780) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c997c4
	if (ctx.cr6.eq) goto loc_82C997C4;
loc_82C997A4:
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C997B8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82c997a4
	if (!ctx.cr6.eq) goto loc_82C997A4;
loc_82C997C4:
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c997f0
	if (ctx.cr6.eq) goto loc_82C997F0;
loc_82C997D0:
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C997E4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82c997d0
	if (!ctx.cr6.eq) goto loc_82C997D0;
loc_82C997F0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C99808"))) PPC_WEAK_FUNC(sub_82C99808);
PPC_FUNC_IMPL(__imp__sub_82C99808) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C99810;
	sub_82CA2BEC(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c998ec
	if (ctx.cr6.eq) goto loc_82C998EC;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c9986c
	if (!ctx.cr6.eq) goto loc_82C9986C;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// rotlwi r9,r11,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r11.u32, 0);
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r8,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r8.u32);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r11,r10,8
	ctx.r11.s64 = ctx.r10.s64 + 8;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// add r7,r10,r11
	ctx.r7.u64 = ctx.r10.u64 + ctx.r11.u64;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// stw r7,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r7.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C9986C:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// subf r7,r10,r9
	ctx.r7.s64 = ctx.r9.s64 - ctx.r10.s64;
	// cmpw cr6,r7,r8
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, ctx.xer);
	// bge cr6,0x82c998ec
	if (!ctx.cr6.lt) goto loc_82C998EC;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// rotlwi r11,r8,0
	ctx.r11.u64 = __builtin_rotateleft32(ctx.r8.u32, 0);
	// stw r8,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r8.u32);
	// addi r3,r11,8
	ctx.r3.s64 = ctx.r11.s64 + 8;
	// stw r9,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r9.u32);
	// subf r5,r4,r7
	ctx.r5.s64 = ctx.r7.s64 - ctx.r4.s64;
	// bl 0x82ca2c60
	ctx.lr = 0x82C998B0;
	sub_82CA2C60(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r6,16(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r8,12(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r10,r11,8
	ctx.r10.s64 = ctx.r11.s64 + 8;
	// subf r9,r6,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r6.s64;
	// stw r10,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r10.u32);
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// addi r5,r9,8
	ctx.r5.s64 = ctx.r9.s64 + 8;
	// stw r5,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r5.u32);
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// add r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r4,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r4.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C998EC:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c99968
	if (ctx.cr6.eq) goto loc_82C99968;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addi r10,r3,8
	ctx.r10.s64 = ctx.r3.s64 + 8;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c99968
	if (!ctx.cr6.eq) goto loc_82C99968;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// subf r8,r11,r10
	ctx.r8.s64 = ctx.r10.s64 - ctx.r11.s64;
	// rlwinm r30,r8,1,0,30
	ctx.r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r7,4(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// addi r4,r30,8
	ctx.r4.s64 = ctx.r30.s64 + 8;
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
	// bctrl 
	ctx.lr = 0x82C99928;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c99940
	if (!ctx.cr6.eq) goto loc_82C99940;
loc_82C99934:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C99940:
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
	// lwz r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r11,r10,8
	ctx.r11.s64 = ctx.r10.s64 + 8;
	// add r7,r11,r30
	ctx.r7.u64 = ctx.r11.u64 + ctx.r30.u64;
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// subf r11,r8,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r8.s64;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// b 0x82c999f0
	goto loc_82C999F0;
loc_82C99968:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// li r29,1024
	ctx.r29.s64 = 1024;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// cmpwi cr6,r11,1024
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1024, ctx.xer);
	// blt cr6,0x82c99984
	if (ctx.cr6.lt) goto loc_82C99984;
	// rlwinm r29,r11,1,0,30
	ctx.r29.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
loc_82C99984:
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// addi r3,r29,8
	ctx.r3.s64 = ctx.r29.s64 + 8;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C99998;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c99934
	if (ctx.cr6.eq) goto loc_82C99934;
	// stw r29,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r29.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stw r11,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r11.u32);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplw cr6,r11,r4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r4.u32, ctx.xer);
	// beq cr6,0x82c999d0
	if (ctx.cr6.eq) goto loc_82C999D0;
	// subf r5,r4,r11
	ctx.r5.s64 = ctx.r11.s64 - ctx.r4.s64;
	// addi r3,r30,8
	ctx.r3.s64 = ctx.r30.s64 + 8;
	// bl 0x82ca2c60
	ctx.lr = 0x82C999D0;
	sub_82CA2C60(ctx, base);
loc_82C999D0:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// add r9,r30,r29
	ctx.r9.u64 = ctx.r30.u64 + ctx.r29.u64;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r8,r30,8
	ctx.r8.s64 = ctx.r30.s64 + 8;
	// subf r11,r11,r30
	ctx.r11.s64 = ctx.r30.s64 - ctx.r11.s64;
	// addi r7,r9,8
	ctx.r7.s64 = ctx.r9.s64 + 8;
	// stw r8,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r8.u32);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82C999F0:
	// addi r6,r11,8
	ctx.r6.s64 = ctx.r11.s64 + 8;
	// stw r7,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r7.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r6,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r6.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
}

__attribute__((alias("__imp__sub_82C99A08"))) PPC_WEAK_FUNC(sub_82C99A08);
PPC_FUNC_IMPL(__imp__sub_82C99A08) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C99A10;
	sub_82CA2BEC(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r29,0
	ctx.r29.s64 = 0;
	// lwz r31,356(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 356);
	// lwz r11,184(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 184);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c99a5c
	if (!ctx.cr6.eq) goto loc_82C99A5C;
	// lwz r11,468(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 468);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C99A40;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,184(r31)
	PPC_STORE_U32(ctx.r31.u32 + 184, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c99a58
	if (!ctx.cr6.eq) goto loc_82C99A58;
loc_82C99A4C:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C99A58:
	// stw r29,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r29.u32);
loc_82C99A5C:
	// lwz r10,176(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 176);
	// lwz r11,172(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 172);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82c99ac4
	if (ctx.cr6.lt) goto loc_82C99AC4;
	// lwz r3,164(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 164);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c99aa0
	if (ctx.cr6.eq) goto loc_82C99AA0;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// mulli r4,r11,56
	ctx.r4.s64 = ctx.r11.s64 * 56;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C99A88;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c99a4c
	if (ctx.cr6.eq) goto loc_82C99A4C;
	// lwz r11,172(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 172);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r10,172(r31)
	PPC_STORE_U32(ctx.r31.u32 + 172, ctx.r10.u32);
	// b 0x82c99ac0
	goto loc_82C99AC0;
loc_82C99AA0:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// li r3,896
	ctx.r3.s64 = 896;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C99AB0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c99a4c
	if (ctx.cr6.eq) goto loc_82C99A4C;
	// li r11,32
	ctx.r11.s64 = 32;
	// stw r11,172(r31)
	PPC_STORE_U32(ctx.r31.u32 + 172, ctx.r11.u32);
loc_82C99AC0:
	// stw r3,164(r31)
	PPC_STORE_U32(ctx.r31.u32 + 164, ctx.r3.u32);
loc_82C99AC4:
	// lwz r3,176(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 176);
	// lwz r11,164(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 164);
	// addi r8,r3,1
	ctx.r8.s64 = ctx.r3.s64 + 1;
	// lwz r10,180(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 180);
	// mulli r9,r3,28
	ctx.r9.s64 = ctx.r3.s64 * 28;
	// stw r8,176(r31)
	PPC_STORE_U32(ctx.r31.u32 + 176, ctx.r8.u32);
	// add r8,r9,r11
	ctx.r8.u64 = ctx.r9.u64 + ctx.r11.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82c99b34
	if (ctx.cr6.eq) goto loc_82C99B34;
	// lwz r9,184(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 184);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r9,-4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	// mulli r10,r9,28
	ctx.r10.s64 = ctx.r9.s64 * 28;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x82c99b18
	if (ctx.cr6.eq) goto loc_82C99B18;
	// mulli r9,r9,28
	ctx.r9.s64 = ctx.r9.s64 * 28;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// stw r3,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r3.u32);
loc_82C99B18:
	// lwz r11,20(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c99b28
	if (!ctx.cr6.eq) goto loc_82C99B28;
	// stw r3,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r3.u32);
loc_82C99B28:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r3,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, ctx.r3.u32);
	// stw r11,20(r10)
	PPC_STORE_U32(ctx.r10.u32 + 20, ctx.r11.u32);
loc_82C99B34:
	// stw r29,24(r8)
	PPC_STORE_U32(ctx.r8.u32 + 24, ctx.r29.u32);
	// stw r29,20(r8)
	PPC_STORE_U32(ctx.r8.u32 + 20, ctx.r29.u32);
	// stw r29,16(r8)
	PPC_STORE_U32(ctx.r8.u32 + 16, ctx.r29.u32);
	// stw r29,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, ctx.r29.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
}

__attribute__((alias("__imp__sub_82C99B4C"))) PPC_WEAK_FUNC(sub_82C99B4C);
PPC_FUNC_IMPL(__imp__sub_82C99B4C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C99B50"))) PPC_WEAK_FUNC(sub_82C99B50);
PPC_FUNC_IMPL(__imp__sub_82C99B50) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bd4
	ctx.lr = 0x82C99B58;
	sub_82CA2BD4(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// mulli r11,r4,28
	ctx.r11.s64 = ctx.r4.s64 * 28;
	// lwz r28,356(r24)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r24.u32 + 356);
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// lwz r10,164(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 164);
	// mr r25,r7
	ctx.r25.u64 = ctx.r7.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// rotlwi r8,r9,0
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// cmpwi cr6,r8,4
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 4, ctx.xer);
	// stw r9,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r9.u32);
	// lwz r10,164(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 164);
	// add r7,r10,r11
	ctx.r7.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r6,4(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// stw r6,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r6.u32);
	// bne cr6,0x82c99c10
	if (!ctx.cr6.eq) goto loc_82C99C10;
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
	// lwz r9,0(r25)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// lwz r10,164(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 164);
	// add r8,r10,r11
	ctx.r8.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r11,8(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// stb r7,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r7.u8);
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// addi r6,r10,1
	ctx.r6.s64 = ctx.r10.s64 + 1;
	// stw r6,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r6.u32);
	// lbz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82c99bfc
	if (ctx.cr6.eq) goto loc_82C99BFC;
loc_82C99BD4:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// stb r9,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r9.u8);
	// lwz r10,0(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// stw r8,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r8.u32);
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82c99bd4
	if (!ctx.cr6.eq) goto loc_82C99BD4;
loc_82C99BFC:
	// li r23,0
	ctx.r23.s64 = 0;
	// stw r23,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r23.u32);
	// stw r23,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r23.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c24
	// ERROR 82CA2C24
	return;
loc_82C99C10:
	// lwz r10,164(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 164);
	// li r23,0
	ctx.r23.s64 = 0;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// mr r30,r23
	ctx.r30.u64 = ctx.r23.u64;
	// lwz r9,20(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// rotlwi r10,r9,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// stw r9,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r9.u32);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r10,r9
	ctx.r7.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r7,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,0(r26)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// stw r8,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r8.u32);
	// lwz r9,0(r26)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// add r6,r10,r9
	ctx.r6.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r6,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r6.u32);
	// lwz r5,12(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r10,164(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 164);
	// add r4,r10,r11
	ctx.r4.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r29,12(r4)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// ble cr6,0x82c99ca8
	if (!ctx.cr6.gt) goto loc_82C99CA8;
	// mr r27,r23
	ctx.r27.u64 = ctx.r23.u64;
loc_82C99C68:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// add r5,r11,r27
	ctx.r5.u64 = ctx.r11.u64 + ctx.r27.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82c99b50
	ctx.lr = 0x82C99C84;
	sub_82C99B50(ctx, base);
	// lwz r10,164(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 164);
	// mulli r11,r29,28
	ctx.r11.s64 = ctx.r29.s64 * 28;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// addi r27,r27,20
	ctx.r27.s64 = ctx.r27.s64 + 20;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r29,24(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmplw cr6,r30,r10
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82c99c68
	if (ctx.cr6.lt) goto loc_82C99C68;
loc_82C99CA8:
	// stw r23,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r23.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c24
	// ERROR 82CA2C24
	return;
}

__attribute__((alias("__imp__sub_82C99CB4"))) PPC_WEAK_FUNC(sub_82C99CB4);
PPC_FUNC_IMPL(__imp__sub_82C99CB4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C99CB8"))) PPC_WEAK_FUNC(sub_82C99CB8);
PPC_FUNC_IMPL(__imp__sub_82C99CB8) {
	PPC_FUNC_PROLOGUE();
	// lbz r10,2(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// addi r8,r4,2
	ctx.r8.s64 = ctx.r4.s64 + 2;
	// li r11,0
	ctx.r11.s64 = 0;
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,120
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 120, ctx.xer);
	// bne cr6,0x82c99e38
	if (!ctx.cr6.eq) {
		sub_82C99E38(ctx, base);
		return;
	}
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// lbz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,59
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 59, ctx.xer);
	// beq cr6,0x82c99e74
	if (ctx.cr6.eq) {
		// ERROR 82C99E74
		return;
	}
	// lis r7,17
	ctx.r7.s64 = 1114112;
	// addi r9,r10,-48
	ctx.r9.s64 = ctx.r10.s64 + -48;
	// cmplwi cr6,r9,54
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 54, ctx.xer);
	// bgt cr6,0x82c99e10
	if (ctx.cr6.gt) {
		// ERROR 82C99E10
		return;
	}
	// lis r12,-32054
	ctx.r12.s64 = -2100690944;
	// addi r12,r12,-25332
	ctx.r12.s64 = ctx.r12.s64 + -25332;
	// rlwinm r0,r9,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		// ERROR: 0x82C99DE8
		return;
	case 1:
		// ERROR: 0x82C99DE8
		return;
	case 2:
		// ERROR: 0x82C99DE8
		return;
	case 3:
		// ERROR: 0x82C99DE8
		return;
	case 4:
		// ERROR: 0x82C99DE8
		return;
	case 5:
		// ERROR: 0x82C99DE8
		return;
	case 6:
		// ERROR: 0x82C99DE8
		return;
	case 7:
		// ERROR: 0x82C99DE8
		return;
	case 8:
		// ERROR: 0x82C99DE8
		return;
	case 9:
		// ERROR: 0x82C99DE8
		return;
	case 10:
		// ERROR: 0x82C99E10
		return;
	case 11:
		// ERROR: 0x82C99E10
		return;
	case 12:
		// ERROR: 0x82C99E10
		return;
	case 13:
		// ERROR: 0x82C99E10
		return;
	case 14:
		// ERROR: 0x82C99E10
		return;
	case 15:
		// ERROR: 0x82C99E10
		return;
	case 16:
		// ERROR: 0x82C99E10
		return;
	case 17:
		// ERROR: 0x82C99DF4
		return;
	case 18:
		// ERROR: 0x82C99DF4
		return;
	case 19:
		// ERROR: 0x82C99DF4
		return;
	case 20:
		// ERROR: 0x82C99DF4
		return;
	case 21:
		// ERROR: 0x82C99DF4
		return;
	case 22:
		// ERROR: 0x82C99DF4
		return;
	case 23:
		// ERROR: 0x82C99E10
		return;
	case 24:
		// ERROR: 0x82C99E10
		return;
	case 25:
		// ERROR: 0x82C99E10
		return;
	case 26:
		// ERROR: 0x82C99E10
		return;
	case 27:
		// ERROR: 0x82C99E10
		return;
	case 28:
		// ERROR: 0x82C99E10
		return;
	case 29:
		// ERROR: 0x82C99E10
		return;
	case 30:
		// ERROR: 0x82C99E10
		return;
	case 31:
		// ERROR: 0x82C99E10
		return;
	case 32:
		// ERROR: 0x82C99E10
		return;
	case 33:
		// ERROR: 0x82C99E10
		return;
	case 34:
		// ERROR: 0x82C99E10
		return;
	case 35:
		// ERROR: 0x82C99E10
		return;
	case 36:
		// ERROR: 0x82C99E10
		return;
	case 37:
		// ERROR: 0x82C99E10
		return;
	case 38:
		// ERROR: 0x82C99E10
		return;
	case 39:
		// ERROR: 0x82C99E10
		return;
	case 40:
		// ERROR: 0x82C99E10
		return;
	case 41:
		// ERROR: 0x82C99E10
		return;
	case 42:
		// ERROR: 0x82C99E10
		return;
	case 43:
		// ERROR: 0x82C99E10
		return;
	case 44:
		// ERROR: 0x82C99E10
		return;
	case 45:
		// ERROR: 0x82C99E10
		return;
	case 46:
		// ERROR: 0x82C99E10
		return;
	case 47:
		// ERROR: 0x82C99E10
		return;
	case 48:
		// ERROR: 0x82C99E10
		return;
	case 49:
		// ERROR: 0x82C99E04
		return;
	case 50:
		// ERROR: 0x82C99E04
		return;
	case 51:
		// ERROR: 0x82C99E04
		return;
	case 52:
		// ERROR: 0x82C99E04
		return;
	case 53:
		// ERROR: 0x82C99E04
		return;
	case 54:
		// ERROR: 0x82C99E04
		return;
	default:
		__builtin_unreachable();
	}
}

__attribute__((alias("__imp__sub_82C99D0C"))) PPC_WEAK_FUNC(sub_82C99D0C);
PPC_FUNC_IMPL(__imp__sub_82C99D0C) {
	PPC_FUNC_PROLOGUE();
	// lwz r22,-25112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25112);
	// lwz r22,-25112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25112);
	// lwz r22,-25112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25112);
	// lwz r22,-25112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25112);
	// lwz r22,-25112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25112);
	// lwz r22,-25112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25112);
	// lwz r22,-25112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25112);
	// lwz r22,-25112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25112);
	// lwz r22,-25112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25112);
	// lwz r22,-25112(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25112);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25100);
	// lwz r22,-25100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25100);
	// lwz r22,-25100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25100);
	// lwz r22,-25100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25100);
	// lwz r22,-25100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25100);
	// lwz r22,-25100(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25100);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25072(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25072);
	// lwz r22,-25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25084);
	// lwz r22,-25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25084);
	// lwz r22,-25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25084);
	// lwz r22,-25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25084);
	// lwz r22,-25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25084);
	// lwz r22,-25084(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -25084);
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// or r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 | ctx.r9.u64;
	// b 0x82c99e10
	// ERROR 82C99E10
	return;
}

__attribute__((alias("__imp__sub_82C99DF4"))) PPC_WEAK_FUNC(sub_82C99DF4);
PPC_FUNC_IMPL(__imp__sub_82C99DF4) {
	PPC_FUNC_PROLOGUE();
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,-55
	ctx.r11.s64 = ctx.r11.s64 + -55;
	// b 0x82c99e10
	// ERROR 82C99E10
	return;
}

__attribute__((alias("__imp__sub_82C99E04"))) PPC_WEAK_FUNC(sub_82C99E04);
PPC_FUNC_IMPL(__imp__sub_82C99E04) {
	PPC_FUNC_PROLOGUE();
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,-87
	ctx.r11.s64 = ctx.r11.s64 + -87;
	// cmpw cr6,r11,r7
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r7.s32, ctx.xer);
	// bge cr6,0x82c99e30
	if (!ctx.cr6.lt) goto loc_82C99E30;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// lbz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,59
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 59, ctx.xer);
	// bne cr6,0x82c99ce8
	if (!ctx.cr6.eq) {
		// ERROR 82C99CE8
		return;
	}
	// b 0x82c99e74
	// ERROR 82C99E74
	return;
loc_82C99E30:
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C99E38"))) PPC_WEAK_FUNC(sub_82C99E38);
PPC_FUNC_IMPL(__imp__sub_82C99E38) {
	PPC_FUNC_PROLOGUE();
	// cmpwi cr6,r10,59
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 59, ctx.xer);
	// beq cr6,0x82c99e74
	if (ctx.cr6.eq) goto loc_82C99E74;
	// lis r7,17
	ctx.r7.s64 = 1114112;
loc_82C99E44:
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,-48
	ctx.r11.s64 = ctx.r11.s64 + -48;
	// cmpw cr6,r11,r7
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r7.s32, ctx.xer);
	// bge cr6,0x82c99e30
	if (!ctx.cr6.lt) {
		// ERROR 82C99E30
		return;
	}
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// lbz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,59
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 59, ctx.xer);
	// bne cr6,0x82c99e44
	if (!ctx.cr6.eq) goto loc_82C99E44;
loc_82C99E74:
	// srawi r10,r11,8
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0xFF) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 8;
	// cmpwi cr6,r10,223
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 223, ctx.xer);
	// bgt cr6,0x82c99ea8
	if (ctx.cr6.gt) goto loc_82C99EA8;
	// cmpwi cr6,r10,216
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 216, ctx.xer);
	// bge cr6,0x82c99ec0
	if (!ctx.cr6.lt) goto loc_82C99EC0;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c99ec4
	if (!ctx.cr6.eq) goto loc_82C99EC4;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// addi r10,r10,-504
	ctx.r10.s64 = ctx.r10.s64 + -504;
	// addi r9,r10,76
	ctx.r9.s64 = ctx.r10.s64 + 76;
	// lbzx r8,r11,r9
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// b 0x82c99ebc
	goto loc_82C99EBC;
loc_82C99EA8:
	// cmpwi cr6,r10,255
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 255, ctx.xer);
	// bne cr6,0x82c99ec4
	if (!ctx.cr6.eq) goto loc_82C99EC4;
	// cmplwi cr6,r11,65534
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 65534, ctx.xer);
	// beq cr6,0x82c99ec0
	if (ctx.cr6.eq) goto loc_82C99EC0;
	// cmplwi cr6,r11,65535
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 65535, ctx.xer);
loc_82C99EBC:
	// bne cr6,0x82c99ec4
	if (!ctx.cr6.eq) goto loc_82C99EC4;
loc_82C99EC0:
	// li r11,-1
	ctx.r11.s64 = -1;
loc_82C99EC4:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C99ECC"))) PPC_WEAK_FUNC(sub_82C99ECC);
PPC_FUNC_IMPL(__imp__sub_82C99ECC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C99ED0"))) PPC_WEAK_FUNC(sub_82C99ED0);
PPC_FUNC_IMPL(__imp__sub_82C99ED0) {
	PPC_FUNC_PROLOGUE();
	// lbz r10,5(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 5);
	// addi r8,r4,4
	ctx.r8.s64 = ctx.r4.s64 + 4;
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c9a060
	if (!ctx.cr6.eq) {
		sub_82C9A060(ctx, base);
		return;
	}
	// lbz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// cmplwi cr6,r10,120
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 120, ctx.xer);
	// bne cr6,0x82c9a060
	if (!ctx.cr6.eq) {
		sub_82C9A060(ctx, base);
		return;
	}
	// lis r7,17
	ctx.r7.s64 = 1114112;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// lbz r10,1(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c99f24
	if (!ctx.cr6.eq) goto loc_82C99F24;
	// lbz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// cmplwi cr6,r9,59
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 59, ctx.xer);
	// beq cr6,0x82c9a0bc
	if (ctx.cr6.eq) {
		// ERROR 82C9A0BC
		return;
	}
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c99f24
	if (!ctx.cr6.eq) goto loc_82C99F24;
	// extsb r10,r9
	ctx.r10.s64 = ctx.r9.s8;
	// b 0x82c99f28
	goto loc_82C99F28;
loc_82C99F24:
	// li r10,-1
	ctx.r10.s64 = -1;
loc_82C99F28:
	// addi r9,r10,-48
	ctx.r9.s64 = ctx.r10.s64 + -48;
	// cmplwi cr6,r9,54
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 54, ctx.xer);
	// bgt cr6,0x82c9a050
	if (ctx.cr6.gt) {
		// ERROR 82C9A050
		return;
	}
	// lis r12,-32054
	ctx.r12.s64 = -2100690944;
	// addi r12,r12,-24756
	ctx.r12.s64 = ctx.r12.s64 + -24756;
	// rlwinm r0,r9,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		// ERROR: 0x82C9A028
		return;
	case 1:
		// ERROR: 0x82C9A028
		return;
	case 2:
		// ERROR: 0x82C9A028
		return;
	case 3:
		// ERROR: 0x82C9A028
		return;
	case 4:
		// ERROR: 0x82C9A028
		return;
	case 5:
		// ERROR: 0x82C9A028
		return;
	case 6:
		// ERROR: 0x82C9A028
		return;
	case 7:
		// ERROR: 0x82C9A028
		return;
	case 8:
		// ERROR: 0x82C9A028
		return;
	case 9:
		// ERROR: 0x82C9A028
		return;
	case 10:
		// ERROR: 0x82C9A050
		return;
	case 11:
		// ERROR: 0x82C9A050
		return;
	case 12:
		// ERROR: 0x82C9A050
		return;
	case 13:
		// ERROR: 0x82C9A050
		return;
	case 14:
		// ERROR: 0x82C9A050
		return;
	case 15:
		// ERROR: 0x82C9A050
		return;
	case 16:
		// ERROR: 0x82C9A050
		return;
	case 17:
		// ERROR: 0x82C9A034
		return;
	case 18:
		// ERROR: 0x82C9A034
		return;
	case 19:
		// ERROR: 0x82C9A034
		return;
	case 20:
		// ERROR: 0x82C9A034
		return;
	case 21:
		// ERROR: 0x82C9A034
		return;
	case 22:
		// ERROR: 0x82C9A034
		return;
	case 23:
		// ERROR: 0x82C9A050
		return;
	case 24:
		// ERROR: 0x82C9A050
		return;
	case 25:
		// ERROR: 0x82C9A050
		return;
	case 26:
		// ERROR: 0x82C9A050
		return;
	case 27:
		// ERROR: 0x82C9A050
		return;
	case 28:
		// ERROR: 0x82C9A050
		return;
	case 29:
		// ERROR: 0x82C9A050
		return;
	case 30:
		// ERROR: 0x82C9A050
		return;
	case 31:
		// ERROR: 0x82C9A050
		return;
	case 32:
		// ERROR: 0x82C9A050
		return;
	case 33:
		// ERROR: 0x82C9A050
		return;
	case 34:
		// ERROR: 0x82C9A050
		return;
	case 35:
		// ERROR: 0x82C9A050
		return;
	case 36:
		// ERROR: 0x82C9A050
		return;
	case 37:
		// ERROR: 0x82C9A050
		return;
	case 38:
		// ERROR: 0x82C9A050
		return;
	case 39:
		// ERROR: 0x82C9A050
		return;
	case 40:
		// ERROR: 0x82C9A050
		return;
	case 41:
		// ERROR: 0x82C9A050
		return;
	case 42:
		// ERROR: 0x82C9A050
		return;
	case 43:
		// ERROR: 0x82C9A050
		return;
	case 44:
		// ERROR: 0x82C9A050
		return;
	case 45:
		// ERROR: 0x82C9A050
		return;
	case 46:
		// ERROR: 0x82C9A050
		return;
	case 47:
		// ERROR: 0x82C9A050
		return;
	case 48:
		// ERROR: 0x82C9A050
		return;
	case 49:
		// ERROR: 0x82C9A044
		return;
	case 50:
		// ERROR: 0x82C9A044
		return;
	case 51:
		// ERROR: 0x82C9A044
		return;
	case 52:
		// ERROR: 0x82C9A044
		return;
	case 53:
		// ERROR: 0x82C9A044
		return;
	case 54:
		// ERROR: 0x82C9A044
		return;
	default:
		__builtin_unreachable();
	}
}

__attribute__((alias("__imp__sub_82C99F4C"))) PPC_WEAK_FUNC(sub_82C99F4C);
PPC_FUNC_IMPL(__imp__sub_82C99F4C) {
	PPC_FUNC_PROLOGUE();
	// lwz r22,-24536(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24536);
	// lwz r22,-24536(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24536);
	// lwz r22,-24536(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24536);
	// lwz r22,-24536(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24536);
	// lwz r22,-24536(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24536);
	// lwz r22,-24536(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24536);
	// lwz r22,-24536(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24536);
	// lwz r22,-24536(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24536);
	// lwz r22,-24536(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24536);
	// lwz r22,-24536(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24536);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24524(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24524);
	// lwz r22,-24524(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24524);
	// lwz r22,-24524(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24524);
	// lwz r22,-24524(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24524);
	// lwz r22,-24524(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24524);
	// lwz r22,-24524(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24524);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24496(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24496);
	// lwz r22,-24508(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24508);
	// lwz r22,-24508(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24508);
	// lwz r22,-24508(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24508);
	// lwz r22,-24508(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24508);
	// lwz r22,-24508(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24508);
	// lwz r22,-24508(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -24508);
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// or r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 | ctx.r9.u64;
	// b 0x82c9a050
	// ERROR 82C9A050
	return;
}

__attribute__((alias("__imp__sub_82C9A034"))) PPC_WEAK_FUNC(sub_82C9A034);
PPC_FUNC_IMPL(__imp__sub_82C9A034) {
	PPC_FUNC_PROLOGUE();
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,-55
	ctx.r11.s64 = ctx.r11.s64 + -55;
	// b 0x82c9a050
	// ERROR 82C9A050
	return;
}

__attribute__((alias("__imp__sub_82C9A044"))) PPC_WEAK_FUNC(sub_82C9A044);
PPC_FUNC_IMPL(__imp__sub_82C9A044) {
	PPC_FUNC_PROLOGUE();
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,-87
	ctx.r11.s64 = ctx.r11.s64 + -87;
	// cmpw cr6,r11,r7
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r7.s32, ctx.xer);
	// blt cr6,0x82c99ef4
	if (ctx.cr6.lt) {
		// ERROR 82C99EF4
		return;
	}
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9A060"))) PPC_WEAK_FUNC(sub_82C9A060);
PPC_FUNC_IMPL(__imp__sub_82C9A060) {
	PPC_FUNC_PROLOGUE();
	// lis r7,17
	ctx.r7.s64 = 1114112;
loc_82C9A064:
	// lbz r10,1(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9a094
	if (!ctx.cr6.eq) goto loc_82C9A094;
	// lbz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// cmplwi cr6,r9,59
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 59, ctx.xer);
	// beq cr6,0x82c9a0bc
	if (ctx.cr6.eq) goto loc_82C9A0BC;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9a094
	if (!ctx.cr6.eq) goto loc_82C9A094;
	// clrlwi r10,r9,24
	ctx.r10.u64 = ctx.r9.u32 & 0xFF;
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// b 0x82c9a098
	goto loc_82C9A098;
loc_82C9A094:
	// li r9,-1
	ctx.r9.s64 = -1;
loc_82C9A098:
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// addi r11,r11,-48
	ctx.r11.s64 = ctx.r11.s64 + -48;
	// cmpw cr6,r11,r7
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r7.s32, ctx.xer);
	// bge cr6,0x82c9a058
	if (!ctx.cr6.lt) {
		// ERROR 82C9A058
		return;
	}
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// b 0x82c9a064
	goto loc_82C9A064;
loc_82C9A0BC:
	// srawi r10,r11,8
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0xFF) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 8;
	// cmpwi cr6,r10,223
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 223, ctx.xer);
	// bgt cr6,0x82c9a0f0
	if (ctx.cr6.gt) goto loc_82C9A0F0;
	// cmpwi cr6,r10,216
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 216, ctx.xer);
	// bge cr6,0x82c9a108
	if (!ctx.cr6.lt) goto loc_82C9A108;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9a10c
	if (!ctx.cr6.eq) goto loc_82C9A10C;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// addi r10,r10,-504
	ctx.r10.s64 = ctx.r10.s64 + -504;
	// addi r9,r10,76
	ctx.r9.s64 = ctx.r10.s64 + 76;
	// lbzx r8,r11,r9
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// b 0x82c9a104
	goto loc_82C9A104;
loc_82C9A0F0:
	// cmpwi cr6,r10,255
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 255, ctx.xer);
	// bne cr6,0x82c9a10c
	if (!ctx.cr6.eq) goto loc_82C9A10C;
	// cmplwi cr6,r11,65534
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 65534, ctx.xer);
	// beq cr6,0x82c9a108
	if (ctx.cr6.eq) goto loc_82C9A108;
	// cmplwi cr6,r11,65535
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 65535, ctx.xer);
loc_82C9A104:
	// bne cr6,0x82c9a10c
	if (!ctx.cr6.eq) goto loc_82C9A10C;
loc_82C9A108:
	// li r11,-1
	ctx.r11.s64 = -1;
loc_82C9A10C:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9A114"))) PPC_WEAK_FUNC(sub_82C9A114);
PPC_FUNC_IMPL(__imp__sub_82C9A114) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9A118"))) PPC_WEAK_FUNC(sub_82C9A118);
PPC_FUNC_IMPL(__imp__sub_82C9A118) {
	PPC_FUNC_PROLOGUE();
	// lbz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 4);
	// addi r8,r4,4
	ctx.r8.s64 = ctx.r4.s64 + 4;
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c9a2a8
	if (!ctx.cr6.eq) {
		sub_82C9A2A8(ctx, base);
		return;
	}
	// lbz r10,1(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// cmplwi cr6,r10,120
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 120, ctx.xer);
	// bne cr6,0x82c9a2a8
	if (!ctx.cr6.eq) {
		sub_82C9A2A8(ctx, base);
		return;
	}
	// lis r7,17
	ctx.r7.s64 = 1114112;
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// lbz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9a16c
	if (!ctx.cr6.eq) goto loc_82C9A16C;
	// lbz r9,1(r8)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// cmplwi cr6,r9,59
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 59, ctx.xer);
	// beq cr6,0x82c9a304
	if (ctx.cr6.eq) {
		// ERROR 82C9A304
		return;
	}
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9a16c
	if (!ctx.cr6.eq) goto loc_82C9A16C;
	// extsb r10,r9
	ctx.r10.s64 = ctx.r9.s8;
	// b 0x82c9a170
	goto loc_82C9A170;
loc_82C9A16C:
	// li r10,-1
	ctx.r10.s64 = -1;
loc_82C9A170:
	// addi r9,r10,-48
	ctx.r9.s64 = ctx.r10.s64 + -48;
	// cmplwi cr6,r9,54
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 54, ctx.xer);
	// bgt cr6,0x82c9a298
	if (ctx.cr6.gt) {
		// ERROR 82C9A298
		return;
	}
	// lis r12,-32054
	ctx.r12.s64 = -2100690944;
	// addi r12,r12,-24172
	ctx.r12.s64 = ctx.r12.s64 + -24172;
	// rlwinm r0,r9,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		// ERROR: 0x82C9A270
		return;
	case 1:
		// ERROR: 0x82C9A270
		return;
	case 2:
		// ERROR: 0x82C9A270
		return;
	case 3:
		// ERROR: 0x82C9A270
		return;
	case 4:
		// ERROR: 0x82C9A270
		return;
	case 5:
		// ERROR: 0x82C9A270
		return;
	case 6:
		// ERROR: 0x82C9A270
		return;
	case 7:
		// ERROR: 0x82C9A270
		return;
	case 8:
		// ERROR: 0x82C9A270
		return;
	case 9:
		// ERROR: 0x82C9A270
		return;
	case 10:
		// ERROR: 0x82C9A298
		return;
	case 11:
		// ERROR: 0x82C9A298
		return;
	case 12:
		// ERROR: 0x82C9A298
		return;
	case 13:
		// ERROR: 0x82C9A298
		return;
	case 14:
		// ERROR: 0x82C9A298
		return;
	case 15:
		// ERROR: 0x82C9A298
		return;
	case 16:
		// ERROR: 0x82C9A298
		return;
	case 17:
		// ERROR: 0x82C9A27C
		return;
	case 18:
		// ERROR: 0x82C9A27C
		return;
	case 19:
		// ERROR: 0x82C9A27C
		return;
	case 20:
		// ERROR: 0x82C9A27C
		return;
	case 21:
		// ERROR: 0x82C9A27C
		return;
	case 22:
		// ERROR: 0x82C9A27C
		return;
	case 23:
		// ERROR: 0x82C9A298
		return;
	case 24:
		// ERROR: 0x82C9A298
		return;
	case 25:
		// ERROR: 0x82C9A298
		return;
	case 26:
		// ERROR: 0x82C9A298
		return;
	case 27:
		// ERROR: 0x82C9A298
		return;
	case 28:
		// ERROR: 0x82C9A298
		return;
	case 29:
		// ERROR: 0x82C9A298
		return;
	case 30:
		// ERROR: 0x82C9A298
		return;
	case 31:
		// ERROR: 0x82C9A298
		return;
	case 32:
		// ERROR: 0x82C9A298
		return;
	case 33:
		// ERROR: 0x82C9A298
		return;
	case 34:
		// ERROR: 0x82C9A298
		return;
	case 35:
		// ERROR: 0x82C9A298
		return;
	case 36:
		// ERROR: 0x82C9A298
		return;
	case 37:
		// ERROR: 0x82C9A298
		return;
	case 38:
		// ERROR: 0x82C9A298
		return;
	case 39:
		// ERROR: 0x82C9A298
		return;
	case 40:
		// ERROR: 0x82C9A298
		return;
	case 41:
		// ERROR: 0x82C9A298
		return;
	case 42:
		// ERROR: 0x82C9A298
		return;
	case 43:
		// ERROR: 0x82C9A298
		return;
	case 44:
		// ERROR: 0x82C9A298
		return;
	case 45:
		// ERROR: 0x82C9A298
		return;
	case 46:
		// ERROR: 0x82C9A298
		return;
	case 47:
		// ERROR: 0x82C9A298
		return;
	case 48:
		// ERROR: 0x82C9A298
		return;
	case 49:
		// ERROR: 0x82C9A28C
		return;
	case 50:
		// ERROR: 0x82C9A28C
		return;
	case 51:
		// ERROR: 0x82C9A28C
		return;
	case 52:
		// ERROR: 0x82C9A28C
		return;
	case 53:
		// ERROR: 0x82C9A28C
		return;
	case 54:
		// ERROR: 0x82C9A28C
		return;
	default:
		__builtin_unreachable();
	}
}

__attribute__((alias("__imp__sub_82C9A194"))) PPC_WEAK_FUNC(sub_82C9A194);
PPC_FUNC_IMPL(__imp__sub_82C9A194) {
	PPC_FUNC_PROLOGUE();
	// lwz r22,-23952(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23952);
	// lwz r22,-23952(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23952);
	// lwz r22,-23952(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23952);
	// lwz r22,-23952(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23952);
	// lwz r22,-23952(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23952);
	// lwz r22,-23952(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23952);
	// lwz r22,-23952(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23952);
	// lwz r22,-23952(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23952);
	// lwz r22,-23952(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23952);
	// lwz r22,-23952(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23952);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23940(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23940);
	// lwz r22,-23940(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23940);
	// lwz r22,-23940(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23940);
	// lwz r22,-23940(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23940);
	// lwz r22,-23940(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23940);
	// lwz r22,-23940(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23940);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23912(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23912);
	// lwz r22,-23924(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23924);
	// lwz r22,-23924(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23924);
	// lwz r22,-23924(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23924);
	// lwz r22,-23924(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23924);
	// lwz r22,-23924(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23924);
	// lwz r22,-23924(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23924);
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// or r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 | ctx.r9.u64;
	// b 0x82c9a298
	// ERROR 82C9A298
	return;
}

__attribute__((alias("__imp__sub_82C9A27C"))) PPC_WEAK_FUNC(sub_82C9A27C);
PPC_FUNC_IMPL(__imp__sub_82C9A27C) {
	PPC_FUNC_PROLOGUE();
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,-55
	ctx.r11.s64 = ctx.r11.s64 + -55;
	// b 0x82c9a298
	// ERROR 82C9A298
	return;
}

__attribute__((alias("__imp__sub_82C9A28C"))) PPC_WEAK_FUNC(sub_82C9A28C);
PPC_FUNC_IMPL(__imp__sub_82C9A28C) {
	PPC_FUNC_PROLOGUE();
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,-87
	ctx.r11.s64 = ctx.r11.s64 + -87;
	// cmpw cr6,r11,r7
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r7.s32, ctx.xer);
	// blt cr6,0x82c9a13c
	if (ctx.cr6.lt) {
		// ERROR 82C9A13C
		return;
	}
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9A2A8"))) PPC_WEAK_FUNC(sub_82C9A2A8);
PPC_FUNC_IMPL(__imp__sub_82C9A2A8) {
	PPC_FUNC_PROLOGUE();
	// lis r7,17
	ctx.r7.s64 = 1114112;
loc_82C9A2AC:
	// lbz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9a2dc
	if (!ctx.cr6.eq) goto loc_82C9A2DC;
	// lbz r9,1(r8)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// cmplwi cr6,r9,59
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 59, ctx.xer);
	// beq cr6,0x82c9a304
	if (ctx.cr6.eq) goto loc_82C9A304;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9a2dc
	if (!ctx.cr6.eq) goto loc_82C9A2DC;
	// clrlwi r10,r9,24
	ctx.r10.u64 = ctx.r9.u32 & 0xFF;
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// b 0x82c9a2e0
	goto loc_82C9A2E0;
loc_82C9A2DC:
	// li r9,-1
	ctx.r9.s64 = -1;
loc_82C9A2E0:
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// addi r11,r11,-48
	ctx.r11.s64 = ctx.r11.s64 + -48;
	// cmpw cr6,r11,r7
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r7.s32, ctx.xer);
	// bge cr6,0x82c9a2a0
	if (!ctx.cr6.lt) {
		// ERROR 82C9A2A0
		return;
	}
	// addi r8,r8,2
	ctx.r8.s64 = ctx.r8.s64 + 2;
	// b 0x82c9a2ac
	goto loc_82C9A2AC;
loc_82C9A304:
	// srawi r10,r11,8
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0xFF) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 8;
	// cmpwi cr6,r10,223
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 223, ctx.xer);
	// bgt cr6,0x82c9a338
	if (ctx.cr6.gt) goto loc_82C9A338;
	// cmpwi cr6,r10,216
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 216, ctx.xer);
	// bge cr6,0x82c9a350
	if (!ctx.cr6.lt) goto loc_82C9A350;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9a354
	if (!ctx.cr6.eq) goto loc_82C9A354;
	// lis r10,-32255
	ctx.r10.s64 = -2113863680;
	// addi r10,r10,-504
	ctx.r10.s64 = ctx.r10.s64 + -504;
	// addi r9,r10,76
	ctx.r9.s64 = ctx.r10.s64 + 76;
	// lbzx r8,r11,r9
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// b 0x82c9a34c
	goto loc_82C9A34C;
loc_82C9A338:
	// cmpwi cr6,r10,255
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 255, ctx.xer);
	// bne cr6,0x82c9a354
	if (!ctx.cr6.eq) goto loc_82C9A354;
	// cmplwi cr6,r11,65534
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 65534, ctx.xer);
	// beq cr6,0x82c9a350
	if (ctx.cr6.eq) goto loc_82C9A350;
	// cmplwi cr6,r11,65535
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 65535, ctx.xer);
loc_82C9A34C:
	// bne cr6,0x82c9a354
	if (!ctx.cr6.eq) goto loc_82C9A354;
loc_82C9A350:
	// li r11,-1
	ctx.r11.s64 = -1;
loc_82C9A354:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9A35C"))) PPC_WEAK_FUNC(sub_82C9A35C);
PPC_FUNC_IMPL(__imp__sub_82C9A35C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9A360"))) PPC_WEAK_FUNC(sub_82C9A360);
PPC_FUNC_IMPL(__imp__sub_82C9A360) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C9A368;
	sub_82CA2BE8(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// li r28,1
	ctx.r28.s64 = 1;
	// lwz r11,480(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82c9a478
	if (ctx.cr6.eq) goto loc_82C9A478;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82c9a464
	if (ctx.cr6.eq) goto loc_82C9A464;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// addi r30,r31,24
	ctx.r30.s64 = ctx.r31.s64 + 24;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// add r5,r11,r4
	ctx.r5.u64 = ctx.r11.u64 + ctx.r4.u64;
	// lwz r7,280(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 280);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// add r11,r4,r10
	ctx.r11.u64 = ctx.r4.u64 + ctx.r10.u64;
	// stw r5,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r5.u32);
	// stw r5,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r5.u32);
	// mr r4,r9
	ctx.r4.u64 = ctx.r9.u64;
	// stw r9,296(r31)
	PPC_STORE_U32(ctx.r31.u32 + 296, ctx.r9.u32);
	// stw r28,480(r31)
	PPC_STORE_U32(ctx.r31.u32 + 480, ctx.r28.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// stb r29,484(r31)
	PPC_STORE_U8(ctx.r31.u32 + 484, ctx.r29.u8);
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
	// bctrl 
	ctx.lr = 0x82C9A3D0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 284, ctx.r3.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9a3fc
	if (ctx.cr6.eq) goto loc_82C9A3FC;
	// lwz r11,288(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 288);
	// lis r10,-32204
	ctx.r10.s64 = -2110521344;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r9,r10,-11704
	ctx.r9.s64 = ctx.r10.s64 + -11704;
	// stw r9,280(r31)
	PPC_STORE_U32(ctx.r31.u32 + 280, ctx.r9.u32);
	// stw r11,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9A3FC:
	// lwz r11,480(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// blt cr6,0x82c9a448
	if (ctx.cr6.lt) goto loc_82C9A448;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bne cr6,0x82c9a414
	if (!ctx.cr6.eq) goto loc_82C9A414;
	// li r28,2
	ctx.r28.s64 = 2;
loc_82C9A414:
	// lwz r11,144(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// addi r6,r31,408
	ctx.r6.s64 = ctx.r31.s64 + 408;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r4,296(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 296);
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9A434;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// stw r9,296(r31)
	PPC_STORE_U32(ctx.r31.u32 + 296, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9A448:
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq cr6,0x82c9a414
	if (ctx.cr6.eq) goto loc_82C9A414;
	// li r11,2
	ctx.r11.s64 = 2;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,480(r31)
	PPC_STORE_U32(ctx.r31.u32 + 480, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9A464:
	// li r11,33
	ctx.r11.s64 = 33;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 284, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9A478:
	// li r11,36
	ctx.r11.s64 = 36;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 284, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
}

__attribute__((alias("__imp__sub_82C9A48C"))) PPC_WEAK_FUNC(sub_82C9A48C);
PPC_FUNC_IMPL(__imp__sub_82C9A48C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9A490"))) PPC_WEAK_FUNC(sub_82C9A490);
PPC_FUNC_IMPL(__imp__sub_82C9A490) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bd4
	ctx.lr = 0x82C9A498;
	sub_82CA2BD4(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r23,r7
	ctx.r23.u64 = ctx.r7.u64;
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// mr r24,r8
	ctx.r24.u64 = ctx.r8.u64;
	// lwz r10,144(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// cmplw cr6,r30,r10
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r10.u32, ctx.xer);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// bne cr6,0x82c9a4d8
	if (!ctx.cr6.eq) goto loc_82C9A4D8;
	// addi r28,r31,288
	ctx.r28.s64 = ctx.r31.s64 + 288;
	// stw r11,288(r31)
	PPC_STORE_U32(ctx.r31.u32 + 288, ctx.r11.u32);
	// addi r29,r31,292
	ctx.r29.s64 = ctx.r31.s64 + 292;
	// b 0x82c9a4e0
	goto loc_82C9A4E0;
loc_82C9A4D8:
	// lwz r28,300(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 300);
	// addi r29,r28,4
	ctx.r29.s64 = ctx.r28.s64 + 4;
loc_82C9A4E0:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// stw r10,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r10.u32);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C9A508;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r11,r3,4
	ctx.r11.s64 = ctx.r3.s64 + 4;
	// cmplwi cr6,r11,44
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 44, ctx.xer);
	// stw r5,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r5.u32);
	// bgt cr6,0x82c9a76c
	if (ctx.cr6.gt) goto loc_82C9A76C;
	// li r26,10
	ctx.r26.s64 = 10;
loc_82C9A520:
	// lis r12,-32054
	ctx.r12.s64 = -2100690944;
	// addi r12,r12,-23240
	ctx.r12.s64 = ctx.r12.s64 + -23240;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9A828;
	case 1:
		goto loc_82C9A76C;
	case 2:
		goto loc_82C9A7FC;
	case 3:
		goto loc_82C9A828;
	case 4:
		goto loc_82C9A7EC;
	case 5:
		goto loc_82C9A76C;
	case 6:
		goto loc_82C9A76C;
	case 7:
		goto loc_82C9A76C;
	case 8:
		goto loc_82C9A76C;
	case 9:
		goto loc_82C9A76C;
	case 10:
		goto loc_82C9A614;
	case 11:
		goto loc_82C9A5EC;
	case 12:
		goto loc_82C9A76C;
	case 13:
		goto loc_82C9A76C;
	case 14:
		goto loc_82C9A76C;
	case 15:
		goto loc_82C9A76C;
	case 16:
		goto loc_82C9A76C;
	case 17:
		goto loc_82C9A76C;
	case 18:
		goto loc_82C9A76C;
	case 19:
		goto loc_82C9A76C;
	case 20:
		goto loc_82C9A76C;
	case 21:
		goto loc_82C9A76C;
	case 22:
		goto loc_82C9A76C;
	case 23:
		goto loc_82C9A76C;
	case 24:
		goto loc_82C9A76C;
	case 25:
		goto loc_82C9A76C;
	case 26:
		goto loc_82C9A76C;
	case 27:
		goto loc_82C9A76C;
	case 28:
		goto loc_82C9A76C;
	case 29:
		goto loc_82C9A76C;
	case 30:
		goto loc_82C9A76C;
	case 31:
		goto loc_82C9A76C;
	case 32:
		goto loc_82C9A76C;
	case 33:
		goto loc_82C9A76C;
	case 34:
		goto loc_82C9A76C;
	case 35:
		goto loc_82C9A76C;
	case 36:
		goto loc_82C9A76C;
	case 37:
		goto loc_82C9A76C;
	case 38:
		goto loc_82C9A76C;
	case 39:
		goto loc_82C9A76C;
	case 40:
		goto loc_82C9A76C;
	case 41:
		goto loc_82C9A76C;
	case 42:
		goto loc_82C9A76C;
	case 43:
		goto loc_82C9A76C;
	case 44:
		goto loc_82C9A77C;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-22488(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22488);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22532(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22532);
	// lwz r22,-22488(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22488);
	// lwz r22,-22548(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22548);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-23020(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23020);
	// lwz r22,-23060(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -23060);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22676(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22676);
	// lwz r22,-22660(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22660);
loc_82C9A5EC:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9a6fc
	if (ctx.cr6.eq) goto loc_82C9A6FC;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// li r5,1
	ctx.r5.s64 = 1;
	// stb r26,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r26.u8);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9A610;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82c9a71c
	goto loc_82C9A71C;
loc_82C9A614:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9a6fc
	if (ctx.cr6.eq) goto loc_82C9A6FC;
	// lbz r10,72(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 72);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82c9a6e4
	if (!ctx.cr6.eq) goto loc_82C9A6E4;
	// lwz r11,44(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// addi r6,r1,92
	ctx.r6.s64 = ctx.r1.s64 + 92;
	// lwz r10,60(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// lwz r7,48(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9A650;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// stw r9,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r9.u32);
	// lwz r4,44(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// subf r5,r4,r8
	ctx.r5.s64 = ctx.r8.s64 - ctx.r4.s64;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r7,60(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
	// bctrl 
	ctx.lr = 0x82C9A674;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82c9a720
	if (ctx.cr6.eq) goto loc_82C9A720;
loc_82C9A684:
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// addi r6,r1,92
	ctx.r6.s64 = ctx.r1.s64 + 92;
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// lwz r11,60(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// lwz r7,48(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9A6AC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// stw r9,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r9.u32);
	// lwz r4,44(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r7,60(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// subf r5,r4,r8
	ctx.r5.s64 = ctx.r8.s64 - ctx.r4.s64;
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
	// bctrl 
	ctx.lr = 0x82C9A6D0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bne cr6,0x82c9a684
	if (!ctx.cr6.eq) goto loc_82C9A684;
	// b 0x82c9a720
	goto loc_82C9A720;
loc_82C9A6E4:
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// subf r5,r4,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r4.s64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9A6F8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82c9a71c
	goto loc_82C9A71C;
loc_82C9A6FC:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9a720
	if (ctx.cr6.eq) goto loc_82C9A720;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// lwz r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c98fd8
	ctx.lr = 0x82C9A71C;
	sub_82C98FD8(ctx, base);
loc_82C9A71C:
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82C9A720:
	// stw r5,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r5.u32);
	// stw r5,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r5.u32);
	// lwz r11,480(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82c9a7d0
	if (ctx.cr6.eq) goto loc_82C9A7D0;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82c9a7dc
	if (ctx.cr6.eq) goto loc_82C9A7DC;
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9A758;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r11,r3,4
	ctx.r11.s64 = ctx.r3.s64 + 4;
	// cmplwi cr6,r11,44
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 44, ctx.xer);
	// stw r5,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r5.u32);
	// ble cr6,0x82c9a520
	if (!ctx.cr6.gt) goto loc_82C9A520;
loc_82C9A76C:
	// li r3,23
	ctx.r3.s64 = 23;
	// stw r5,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r5.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	// ERROR 82CA2C24
	return;
loc_82C9A77C:
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9a798
	if (ctx.cr6.eq) goto loc_82C9A798;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9A794;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82c9a7b8
	goto loc_82C9A7B8;
loc_82C9A798:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9a7bc
	if (ctx.cr6.eq) goto loc_82C9A7BC;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// lwz r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c98fd8
	ctx.lr = 0x82C9A7B8;
	sub_82C98FD8(ctx, base);
loc_82C9A7B8:
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_82C9A7BC:
	// stw r5,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r5.u32);
	// stw r5,0(r23)
	PPC_STORE_U32(ctx.r23.u32 + 0, ctx.r5.u32);
	// lwz r11,480(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82c9a7e0
	if (!ctx.cr6.eq) goto loc_82C9A7E0;
loc_82C9A7D0:
	// li r3,35
	ctx.r3.s64 = 35;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	// ERROR 82CA2C24
	return;
loc_82C9A7DC:
	// stw r5,0(r23)
	PPC_STORE_U32(ctx.r23.u32 + 0, ctx.r5.u32);
loc_82C9A7E0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	// ERROR 82CA2C24
	return;
loc_82C9A7EC:
	// li r3,4
	ctx.r3.s64 = 4;
	// stw r5,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r5.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	// ERROR 82CA2C24
	return;
loc_82C9A7FC:
	// clrlwi r11,r24,24
	ctx.r11.u64 = ctx.r24.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9a81c
	if (ctx.cr6.eq) goto loc_82C9A81C;
loc_82C9A808:
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r23)
	PPC_STORE_U32(ctx.r23.u32 + 0, ctx.r11.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	// ERROR 82CA2C24
	return;
loc_82C9A81C:
	// li r3,6
	ctx.r3.s64 = 6;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	// ERROR 82CA2C24
	return;
loc_82C9A828:
	// clrlwi r11,r24,24
	ctx.r11.u64 = ctx.r24.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9a808
	if (!ctx.cr6.eq) goto loc_82C9A808;
	// li r3,20
	ctx.r3.s64 = 20;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x82ca2c24
	// ERROR 82CA2C24
	return;
}

__attribute__((alias("__imp__sub_82C9A840"))) PPC_WEAK_FUNC(sub_82C9A840);
PPC_FUNC_IMPL(__imp__sub_82C9A840) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bd8
	ctx.lr = 0x82C9A848;
	sub_82CA2BD8(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mr r25,r7
	ctx.r25.u64 = ctx.r7.u64;
	// lwz r11,144(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 144);
	// mr r24,r8
	ctx.r24.u64 = ctx.r8.u64;
	// lwz r31,0(r26)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9a884
	if (!ctx.cr6.eq) goto loc_82C9A884;
	// addi r28,r30,288
	ctx.r28.s64 = ctx.r30.s64 + 288;
	// stw r31,288(r30)
	PPC_STORE_U32(ctx.r30.u32 + 288, ctx.r31.u32);
	// addi r27,r30,292
	ctx.r27.s64 = ctx.r30.s64 + 292;
	// b 0x82c9a88c
	goto loc_82C9A88C;
loc_82C9A884:
	// lwz r28,300(r30)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r30.u32 + 300);
	// addi r27,r28,4
	ctx.r27.s64 = ctx.r28.s64 + 4;
loc_82C9A88C:
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r31,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r31.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r10,12(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9A8B0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r3,4
	ctx.r11.s64 = ctx.r3.s64 + 4;
	// cmplwi cr6,r11,46
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 46, ctx.xer);
	// stw r9,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r9.u32);
	// bgt cr6,0x82c9aa30
	if (ctx.cr6.gt) goto loc_82C9AA30;
	// lis r12,-32054
	ctx.r12.s64 = -2100690944;
	// addi r12,r12,-22308
	ctx.r12.s64 = ctx.r12.s64 + -22308;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9AA18;
	case 1:
		goto loc_82C9AA30;
	case 2:
		goto loc_82C9A9F0;
	case 3:
		goto loc_82C9AA18;
	case 4:
		goto loc_82C9A9DC;
	case 5:
		goto loc_82C9AA30;
	case 6:
		goto loc_82C9AA30;
	case 7:
		goto loc_82C9AA30;
	case 8:
		goto loc_82C9AA30;
	case 9:
		goto loc_82C9AA30;
	case 10:
		goto loc_82C9AA30;
	case 11:
		goto loc_82C9AA30;
	case 12:
		goto loc_82C9AA30;
	case 13:
		goto loc_82C9AA30;
	case 14:
		goto loc_82C9AA30;
	case 15:
		goto loc_82C9AA30;
	case 16:
		goto loc_82C9AA30;
	case 17:
		goto loc_82C9AA30;
	case 18:
		goto loc_82C9AA30;
	case 19:
		goto loc_82C9AA30;
	case 20:
		goto loc_82C9AA30;
	case 21:
		goto loc_82C9AA30;
	case 22:
		goto loc_82C9AA30;
	case 23:
		goto loc_82C9AA30;
	case 24:
		goto loc_82C9AA30;
	case 25:
		goto loc_82C9AA30;
	case 26:
		goto loc_82C9AA30;
	case 27:
		goto loc_82C9AA30;
	case 28:
		goto loc_82C9AA30;
	case 29:
		goto loc_82C9AA30;
	case 30:
		goto loc_82C9AA30;
	case 31:
		goto loc_82C9AA30;
	case 32:
		goto loc_82C9AA30;
	case 33:
		goto loc_82C9AA30;
	case 34:
		goto loc_82C9AA30;
	case 35:
		goto loc_82C9AA30;
	case 36:
		goto loc_82C9AA30;
	case 37:
		goto loc_82C9AA30;
	case 38:
		goto loc_82C9AA30;
	case 39:
		goto loc_82C9AA30;
	case 40:
		goto loc_82C9AA30;
	case 41:
		goto loc_82C9AA30;
	case 42:
		goto loc_82C9AA30;
	case 43:
		goto loc_82C9AA30;
	case 44:
		goto loc_82C9AA30;
	case 45:
		goto loc_82C9AA30;
	case 46:
		goto loc_82C9A998;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-21992(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21992);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-22032(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22032);
	// lwz r22,-21992(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21992);
	// lwz r22,-22052(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22052);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-21968(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -21968);
	// lwz r22,-22120(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -22120);
loc_82C9A998:
	// lwz r11,80(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9a9b8
	if (ctx.cr6.eq) goto loc_82C9A9B8;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c98fd8
	ctx.lr = 0x82C9A9B8;
	sub_82C98FD8(ctx, base);
loc_82C9A9B8:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r11.u32);
	// stw r11,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r11.u32);
	// lwz r11,480(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 480);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82c9aa00
	if (!ctx.cr6.eq) goto loc_82C9AA00;
	// li r3,35
	ctx.r3.s64 = 35;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
loc_82C9A9DC:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r3,4
	ctx.r3.s64 = 4;
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
loc_82C9A9F0:
	// clrlwi r11,r24,24
	ctx.r11.u64 = ctx.r24.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9aa0c
	if (ctx.cr6.eq) goto loc_82C9AA0C;
loc_82C9A9FC:
	// stw r31,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r31.u32);
loc_82C9AA00:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
loc_82C9AA0C:
	// li r3,6
	ctx.r3.s64 = 6;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
loc_82C9AA18:
	// clrlwi r11,r24,24
	ctx.r11.u64 = ctx.r24.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9a9fc
	if (!ctx.cr6.eq) goto loc_82C9A9FC;
	// li r3,2
	ctx.r3.s64 = 2;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
loc_82C9AA30:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r3,23
	ctx.r3.s64 = 23;
	// stw r11,0(r28)
	PPC_STORE_U32(ctx.r28.u32 + 0, ctx.r11.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
}

__attribute__((alias("__imp__sub_82C9AA44"))) PPC_WEAK_FUNC(sub_82C9AA44);
PPC_FUNC_IMPL(__imp__sub_82C9AA44) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9AA48"))) PPC_WEAK_FUNC(sub_82C9AA48);
PPC_FUNC_IMPL(__imp__sub_82C9AA48) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lbz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 236);
	// lwz r5,232(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 232);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9aa78
	if (ctx.cr6.eq) goto loc_82C9AA78;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r11,r11,-31632
	ctx.r11.s64 = ctx.r11.s64 + -31632;
	// b 0x82c9aa80
	goto loc_82C9AA80;
loc_82C9AA78:
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r11,r11,-32152
	ctx.r11.s64 = ctx.r11.s64 + -32152;
loc_82C9AA80:
	// addi r4,r31,144
	ctx.r4.s64 = ctx.r31.s64 + 144;
	// addi r3,r31,148
	ctx.r3.s64 = ctx.r31.s64 + 148;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9AA90;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9aab0
	if (ctx.cr6.eq) goto loc_82C9AAB0;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C9AAB0:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,232(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 232);
	// bl 0x82c98ca8
	ctx.lr = 0x82C9AABC;
	sub_82C98CA8(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9AAD0"))) PPC_WEAK_FUNC(sub_82C9AAD0);
PPC_FUNC_IMPL(__imp__sub_82C9AAD0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C9AAD8;
	sub_82CA2BE4(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// lwz r31,356(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 356);
	// lwz r29,0(r28)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lbz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c9abe0
	if (ctx.cr6.eq) goto loc_82C9ABE0;
	// li r27,0
	ctx.r27.s64 = 0;
loc_82C9AAFC:
	// cmpwi cr6,r11,58
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 58, ctx.xer);
	// bne cr6,0x82c9abcc
	if (!ctx.cr6.eq) goto loc_82C9ABCC;
	// lwz r30,0(r28)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// cmplw cr6,r30,r29
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x82c9ab58
	if (ctx.cr6.eq) goto loc_82C9AB58;
loc_82C9AB10:
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// lwz r10,88(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9ab34
	if (!ctx.cr6.eq) goto loc_82C9AB34;
	// addi r3,r31,80
	ctx.r3.s64 = ctx.r31.s64 + 80;
	// bl 0x82c99808
	ctx.lr = 0x82C9AB28;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9abec
	if (ctx.cr6.eq) goto loc_82C9ABEC;
loc_82C9AB34:
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// cmplw cr6,r30,r29
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r29.u32, ctx.xer);
	// stb r11,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r11.u8);
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// stw r9,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r9.u32);
	// bne cr6,0x82c9ab10
	if (!ctx.cr6.eq) goto loc_82C9AB10;
loc_82C9AB58:
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9ab7c
	if (!ctx.cr6.eq) goto loc_82C9AB7C;
	// addi r3,r31,80
	ctx.r3.s64 = ctx.r31.s64 + 80;
	// bl 0x82c99808
	ctx.lr = 0x82C9AB70;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9abec
	if (ctx.cr6.eq) goto loc_82C9ABEC;
loc_82C9AB7C:
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// li r5,8
	ctx.r5.s64 = 8;
	// addi r3,r31,60
	ctx.r3.s64 = ctx.r31.s64 + 60;
	// stb r27,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r27.u8);
	// lwz r4,96(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r10.u32);
	// bl 0x82c99298
	ctx.lr = 0x82C9ABA0;
	sub_82C99298(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c9abec
	if (ctx.cr6.eq) goto loc_82C9ABEC;
	// lwz r11,96(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9abc4
	if (!ctx.cr6.eq) goto loc_82C9ABC4;
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// stw r11,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r11.u32);
	// b 0x82c9abc8
	goto loc_82C9ABC8;
loc_82C9ABC4:
	// stw r11,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r11.u32);
loc_82C9ABC8:
	// stw r3,4(r28)
	PPC_STORE_U32(ctx.r28.u32 + 4, ctx.r3.u32);
loc_82C9ABCC:
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// lbz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c9aafc
	if (!ctx.cr6.eq) goto loc_82C9AAFC;
loc_82C9ABE0:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
loc_82C9ABEC:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
}

__attribute__((alias("__imp__sub_82C9ABF8"))) PPC_WEAK_FUNC(sub_82C9ABF8);
PPC_FUNC_IMPL(__imp__sub_82C9ABF8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bd4
	ctx.lr = 0x82C9AC00;
	sub_82CA2BD4(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r24,61
	ctx.r24.s64 = 61;
	// lwz r25,356(r31)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r31.u32 + 356);
	// lwz r11,156(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 156);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9accc
	if (ctx.cr6.eq) goto loc_82C9ACCC;
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// lwz r10,424(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9ac44
	if (!ctx.cr6.eq) goto loc_82C9AC44;
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99808
	ctx.lr = 0x82C9AC38;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9af88
	if (ctx.cr6.eq) goto loc_82C9AF88;
loc_82C9AC44:
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// stb r24,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r24.u8);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r11.u32);
	// lwz r10,156(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 156);
	// lbz r9,472(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 472);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// lwz r29,20(r10)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// beq cr6,0x82c9ac70
	if (ctx.cr6.eq) goto loc_82C9AC70;
	// addi r29,r29,-1
	ctx.r29.s64 = ctx.r29.s64 + -1;
loc_82C9AC70:
	// li r30,0
	ctx.r30.s64 = 0;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// ble cr6,0x82c9acc8
	if (!ctx.cr6.gt) goto loc_82C9ACC8;
loc_82C9AC7C:
	// lwz r10,424(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9ac9c
	if (!ctx.cr6.eq) goto loc_82C9AC9C;
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99808
	ctx.lr = 0x82C9AC90;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9af88
	if (ctx.cr6.eq) goto loc_82C9AF88;
loc_82C9AC9C:
	// lwz r11,156(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 156);
	// lwz r10,428(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lbzx r8,r9,r30
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r30.u32);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// cmpw cr6,r30,r29
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r29.s32, ctx.xer);
	// stb r8,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r8.u8);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r11.u32);
	// blt cr6,0x82c9ac7c
	if (ctx.cr6.lt) goto loc_82C9AC7C;
loc_82C9ACC8:
	// li r10,1
	ctx.r10.s64 = 1;
loc_82C9ACCC:
	// lwz r11,68(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 68);
	// li r23,12
	ctx.r23.s64 = 12;
	// lwz r27,60(r25)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r25.u32 + 60);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r26,r11,r27
	ctx.r26.u64 = ctx.r11.u64 + ctx.r27.u64;
loc_82C9ACE0:
	// cmplw cr6,r27,r26
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r26.u32, ctx.xer);
	// beq cr6,0x82c9ad00
	if (ctx.cr6.eq) goto loc_82C9AD00;
loc_82C9ACE8:
	// lwz r28,0(r27)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r27,r27,4
	ctx.r27.s64 = ctx.r27.s64 + 4;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// bne cr6,0x82c9ad78
	if (!ctx.cr6.eq) goto loc_82C9AD78;
	// cmplw cr6,r27,r26
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r26.u32, ctx.xer);
	// bne cr6,0x82c9ace8
	if (!ctx.cr6.eq) goto loc_82C9ACE8;
loc_82C9AD00:
	// lwz r11,8(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	// lwz r29,0(r25)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r11,r29
	ctx.r28.u64 = ctx.r11.u64 + ctx.r29.u64;
loc_82C9AD10:
	// cmplw cr6,r29,r28
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c9ad30
	if (ctx.cr6.eq) goto loc_82C9AD30;
loc_82C9AD18:
	// lwz r30,0(r29)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82c9aed4
	if (!ctx.cr6.eq) goto loc_82C9AED4;
	// cmplw cr6,r29,r28
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c9ad18
	if (!ctx.cr6.eq) goto loc_82C9AD18;
loc_82C9AD30:
	// lwz r11,424(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	// lwz r10,428(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9ad54
	if (!ctx.cr6.eq) goto loc_82C9AD54;
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99808
	ctx.lr = 0x82C9AD48;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9af88
	if (ctx.cr6.eq) goto loc_82C9AF88;
loc_82C9AD54:
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r10,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r10.u8);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// lwz r3,432(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 432);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// stw r9,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r9.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c24
	// ERROR 82CA2C24
	return;
loc_82C9AD78:
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9ace0
	if (ctx.cr6.eq) goto loc_82C9ACE0;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9adc8
	if (ctx.cr6.eq) goto loc_82C9ADC8;
	// lwz r11,424(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	// lwz r10,428(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9adb4
	if (!ctx.cr6.eq) goto loc_82C9ADB4;
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99808
	ctx.lr = 0x82C9ADA8;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9af88
	if (ctx.cr6.eq) goto loc_82C9AF88;
loc_82C9ADB4:
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// stb r23,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r23.u8);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r10.u32);
loc_82C9ADC8:
	// lwz r30,0(r28)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9ae24
	if (ctx.cr6.eq) goto loc_82C9AE24;
loc_82C9ADD8:
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// lwz r10,424(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9adfc
	if (!ctx.cr6.eq) goto loc_82C9ADFC;
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99808
	ctx.lr = 0x82C9ADF0;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9af88
	if (ctx.cr6.eq) goto loc_82C9AF88;
loc_82C9ADFC:
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// lwz r10,428(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// stb r11,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r11.u8);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// stw r9,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r9.u32);
	// lbz r8,0(r30)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c9add8
	if (!ctx.cr6.eq) goto loc_82C9ADD8;
loc_82C9AE24:
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// lwz r10,424(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9ae48
	if (!ctx.cr6.eq) goto loc_82C9AE48;
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99808
	ctx.lr = 0x82C9AE3C;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9af88
	if (ctx.cr6.eq) goto loc_82C9AF88;
loc_82C9AE48:
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// stb r24,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r24.u8);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r11.u32);
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// lbz r9,472(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 472);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// lwz r29,20(r10)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// beq cr6,0x82c9ae74
	if (ctx.cr6.eq) goto loc_82C9AE74;
	// addi r29,r29,-1
	ctx.r29.s64 = ctx.r29.s64 + -1;
loc_82C9AE74:
	// li r30,0
	ctx.r30.s64 = 0;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// ble cr6,0x82c9aecc
	if (!ctx.cr6.gt) goto loc_82C9AECC;
loc_82C9AE80:
	// lwz r10,424(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9aea0
	if (!ctx.cr6.eq) goto loc_82C9AEA0;
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99808
	ctx.lr = 0x82C9AE94;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9af88
	if (ctx.cr6.eq) goto loc_82C9AF88;
loc_82C9AEA0:
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// lwz r10,428(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lbzx r8,r9,r30
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r30.u32);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// cmpw cr6,r30,r29
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r29.s32, ctx.xer);
	// stb r8,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r8.u8);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r11.u32);
	// blt cr6,0x82c9ae80
	if (ctx.cr6.lt) goto loc_82C9AE80;
loc_82C9AECC:
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x82c9ace0
	goto loc_82C9ACE0;
loc_82C9AED4:
	// lbz r11,32(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9ad10
	if (ctx.cr6.eq) goto loc_82C9AD10;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9af24
	if (ctx.cr6.eq) goto loc_82C9AF24;
	// lwz r11,424(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	// lwz r10,428(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9af10
	if (!ctx.cr6.eq) goto loc_82C9AF10;
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99808
	ctx.lr = 0x82C9AF04;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9af88
	if (ctx.cr6.eq) goto loc_82C9AF88;
loc_82C9AF10:
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// stb r23,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r23.u8);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r10.u32);
loc_82C9AF24:
	// lwz r30,0(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9af80
	if (ctx.cr6.eq) goto loc_82C9AF80;
loc_82C9AF34:
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// lwz r10,424(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9af58
	if (!ctx.cr6.eq) goto loc_82C9AF58;
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99808
	ctx.lr = 0x82C9AF4C;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9af88
	if (ctx.cr6.eq) goto loc_82C9AF88;
loc_82C9AF58:
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// lwz r10,428(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// stb r11,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r11.u8);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// stw r9,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r9.u32);
	// lbz r8,0(r30)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82c9af34
	if (!ctx.cr6.eq) goto loc_82C9AF34;
loc_82C9AF80:
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x82c9ad10
	goto loc_82C9AD10;
loc_82C9AF88:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c24
	// ERROR 82CA2C24
	return;
}

__attribute__((alias("__imp__sub_82C9AF94"))) PPC_WEAK_FUNC(sub_82C9AF94);
PPC_FUNC_IMPL(__imp__sub_82C9AF94) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9AF98"))) PPC_WEAK_FUNC(sub_82C9AF98);
PPC_FUNC_IMPL(__imp__sub_82C9AF98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r3,188
	ctx.r3.s64 = 188;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9AFBC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c9afd8
	if (!ctx.cr6.eq) goto loc_82C9AFD8;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C9AFD8:
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r31,100(r3)
	PPC_STORE_U32(ctx.r3.u32 + 100, ctx.r31.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,80(r3)
	PPC_STORE_U32(ctx.r3.u32 + 80, ctx.r11.u32);
	// stw r11,84(r3)
	PPC_STORE_U32(ctx.r3.u32 + 84, ctx.r11.u32);
	// stw r11,96(r3)
	PPC_STORE_U32(ctx.r3.u32 + 96, ctx.r11.u32);
	// stw r11,92(r3)
	PPC_STORE_U32(ctx.r3.u32 + 92, ctx.r11.u32);
	// stw r11,88(r3)
	PPC_STORE_U32(ctx.r3.u32 + 88, ctx.r11.u32);
	// stw r11,104(r3)
	PPC_STORE_U32(ctx.r3.u32 + 104, ctx.r11.u32);
	// stw r11,108(r3)
	PPC_STORE_U32(ctx.r3.u32 + 108, ctx.r11.u32);
	// stw r11,120(r3)
	PPC_STORE_U32(ctx.r3.u32 + 120, ctx.r11.u32);
	// stw r11,116(r3)
	PPC_STORE_U32(ctx.r3.u32 + 116, ctx.r11.u32);
	// stw r11,112(r3)
	PPC_STORE_U32(ctx.r3.u32 + 112, ctx.r11.u32);
	// stw r31,124(r3)
	PPC_STORE_U32(ctx.r3.u32 + 124, ctx.r31.u32);
	// stb r11,4(r3)
	PPC_STORE_U8(ctx.r3.u32 + 4, ctx.r11.u8);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// stw r31,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r31.u32);
	// stb r11,24(r3)
	PPC_STORE_U8(ctx.r3.u32 + 24, ctx.r11.u8);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r11.u32);
	// stw r31,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, ctx.r31.u32);
	// stb r11,44(r3)
	PPC_STORE_U8(ctx.r3.u32 + 44, ctx.r11.u8);
	// stw r11,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, ctx.r11.u32);
	// stw r11,52(r3)
	PPC_STORE_U32(ctx.r3.u32 + 52, ctx.r11.u32);
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r11.u32);
	// stw r31,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, ctx.r31.u32);
	// stb r11,64(r3)
	PPC_STORE_U8(ctx.r3.u32 + 64, ctx.r11.u8);
	// stw r11,68(r3)
	PPC_STORE_U32(ctx.r3.u32 + 68, ctx.r11.u32);
	// stw r11,72(r3)
	PPC_STORE_U32(ctx.r3.u32 + 72, ctx.r11.u32);
	// stw r11,60(r3)
	PPC_STORE_U32(ctx.r3.u32 + 60, ctx.r11.u32);
	// stw r31,76(r3)
	PPC_STORE_U32(ctx.r3.u32 + 76, ctx.r31.u32);
	// stb r11,131(r3)
	PPC_STORE_U8(ctx.r3.u32 + 131, ctx.r11.u8);
	// stb r11,136(r3)
	PPC_STORE_U8(ctx.r3.u32 + 136, ctx.r11.u8);
	// stw r11,140(r3)
	PPC_STORE_U32(ctx.r3.u32 + 140, ctx.r11.u32);
	// stw r11,144(r3)
	PPC_STORE_U32(ctx.r3.u32 + 144, ctx.r11.u32);
	// stw r11,132(r3)
	PPC_STORE_U32(ctx.r3.u32 + 132, ctx.r11.u32);
	// stw r31,148(r3)
	PPC_STORE_U32(ctx.r3.u32 + 148, ctx.r31.u32);
	// stw r11,152(r3)
	PPC_STORE_U32(ctx.r3.u32 + 152, ctx.r11.u32);
	// stw r11,156(r3)
	PPC_STORE_U32(ctx.r3.u32 + 156, ctx.r11.u32);
	// stb r11,160(r3)
	PPC_STORE_U8(ctx.r3.u32 + 160, ctx.r11.u8);
	// stw r11,184(r3)
	PPC_STORE_U32(ctx.r3.u32 + 184, ctx.r11.u32);
	// stw r11,164(r3)
	PPC_STORE_U32(ctx.r3.u32 + 164, ctx.r11.u32);
	// stw r11,180(r3)
	PPC_STORE_U32(ctx.r3.u32 + 180, ctx.r11.u32);
	// stw r11,172(r3)
	PPC_STORE_U32(ctx.r3.u32 + 172, ctx.r11.u32);
	// stw r11,176(r3)
	PPC_STORE_U32(ctx.r3.u32 + 176, ctx.r11.u32);
	// stw r11,168(r3)
	PPC_STORE_U32(ctx.r3.u32 + 168, ctx.r11.u32);
	// stb r10,128(r3)
	PPC_STORE_U8(ctx.r3.u32 + 128, ctx.r10.u8);
	// stb r11,129(r3)
	PPC_STORE_U8(ctx.r3.u32 + 129, ctx.r11.u8);
	// stb r11,130(r3)
	PPC_STORE_U8(ctx.r3.u32 + 130, ctx.r11.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9B0BC"))) PPC_WEAK_FUNC(sub_82C9B0BC);
PPC_FUNC_IMPL(__imp__sub_82C9B0BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9B0C0"))) PPC_WEAK_FUNC(sub_82C9B0C0);
PPC_FUNC_IMPL(__imp__sub_82C9B0C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C9B0C8;
	sub_82CA2BE0(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// addi r29,r30,20
	ctx.r29.s64 = ctx.r30.s64 + 20;
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// lwz r31,20(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r28,r11,r31
	ctx.r28.u64 = ctx.r11.u64 + ctx.r31.u64;
loc_82C9B0EC:
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c9b10c
	if (ctx.cr6.eq) goto loc_82C9B10C;
loc_82C9B0F4:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9b188
	if (!ctx.cr6.eq) goto loc_82C9B188;
	// cmplw cr6,r31,r28
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r28.u32, ctx.xer);
	// bne cr6,0x82c9b0f4
	if (!ctx.cr6.eq) goto loc_82C9B0F4;
loc_82C9B10C:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c996b8
	ctx.lr = 0x82C9B114;
	sub_82C996B8(ctx, base);
	// addi r3,r30,132
	ctx.r3.s64 = ctx.r30.s64 + 132;
	// bl 0x82c996b8
	ctx.lr = 0x82C9B11C;
	sub_82C996B8(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c996b8
	ctx.lr = 0x82C9B124;
	sub_82C996B8(ctx, base);
	// addi r3,r30,40
	ctx.r3.s64 = ctx.r30.s64 + 40;
	// bl 0x82c996b8
	ctx.lr = 0x82C9B12C;
	sub_82C996B8(ctx, base);
	// addi r3,r30,60
	ctx.r3.s64 = ctx.r30.s64 + 60;
	// bl 0x82c996b8
	ctx.lr = 0x82C9B134;
	sub_82C996B8(ctx, base);
	// addi r3,r30,80
	ctx.r3.s64 = ctx.r30.s64 + 80;
	// bl 0x82c99780
	ctx.lr = 0x82C9B13C;
	sub_82C99780(ctx, base);
	// addi r3,r30,104
	ctx.r3.s64 = ctx.r30.s64 + 104;
	// bl 0x82c99780
	ctx.lr = 0x82C9B144;
	sub_82C99780(ctx, base);
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9b170
	if (ctx.cr6.eq) goto loc_82C9B170;
	// lwz r3,184(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 184);
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9B160;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,164(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 164);
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9B170;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82C9B170:
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9B180;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C9B188:
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82c9b0ec
	if (ctx.cr6.eq) goto loc_82C9B0EC;
	// lwz r3,20(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9B1A4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82c9b0ec
	goto loc_82C9B0EC;
}

__attribute__((alias("__imp__sub_82C9B1A8"))) PPC_WEAK_FUNC(sub_82C9B1A8);
PPC_FUNC_IMPL(__imp__sub_82C9B1A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C9B1B0;
	sub_82CA2BE8(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r5,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r5.u32);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// addi r28,r29,12
	ctx.r28.s64 = ctx.r29.s64 + 12;
	// lwz r11,12(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9b1e4
	if (!ctx.cr6.eq) goto loc_82C9B1E4;
	// bl 0x82c99808
	ctx.lr = 0x82C9B1D8;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9b25c
	if (ctx.cr6.eq) goto loc_82C9B25C;
loc_82C9B1E4:
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r1,164
	ctx.r4.s64 = ctx.r1.s64 + 164;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9B204;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r10,164(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82c9b250
	if (ctx.cr6.eq) goto loc_82C9B250;
loc_82C9B210:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82c99808
	ctx.lr = 0x82C9B218;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9b25c
	if (ctx.cr6.eq) goto loc_82C9B25C;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// lwz r11,60(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r1,164
	ctx.r4.s64 = ctx.r1.s64 + 164;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9B244;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r10,164(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplw cr6,r10,r30
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r30.u32, ctx.xer);
	// bne cr6,0x82c9b210
	if (!ctx.cr6.eq) goto loc_82C9B210;
loc_82C9B250:
	// lwz r3,16(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9B25C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
}

__attribute__((alias("__imp__sub_82C9B268"))) PPC_WEAK_FUNC(sub_82C9B268);
PPC_FUNC_IMPL(__imp__sub_82C9B268) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
loc_82C9B284:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9b2a8
	if (!ctx.cr6.eq) goto loc_82C9B2A8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c99808
	ctx.lr = 0x82C9B29C;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9b2f0
	if (ctx.cr6.eq) goto loc_82C9B2F0;
loc_82C9B2A8:
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stb r11,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r11.u8);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// lbz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// bne cr6,0x82c9b284
	if (!ctx.cr6.eq) goto loc_82C9B284;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// stw r11,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r11.u32);
loc_82C9B2D8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C9B2F0:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82c9b2d8
	goto loc_82C9B2D8;
}

__attribute__((alias("__imp__sub_82C9B2F8"))) PPC_WEAK_FUNC(sub_82C9B2F8);
PPC_FUNC_IMPL(__imp__sub_82C9B2F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82c9b1a8
	ctx.lr = 0x82C9B310;
	sub_82C9B1A8(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c9b330
	if (!ctx.cr6.eq) goto loc_82C9B330;
loc_82C9B318:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C9B330:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9b354
	if (!ctx.cr6.eq) goto loc_82C9B354;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c99808
	ctx.lr = 0x82C9B348;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9b318
	if (ctx.cr6.eq) goto loc_82C9B318;
loc_82C9B354:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r10,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r10.u8);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// stw r9,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r9.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9B384"))) PPC_WEAK_FUNC(sub_82C9B384);
PPC_FUNC_IMPL(__imp__sub_82C9B384) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9B388"))) PPC_WEAK_FUNC(sub_82C9B388);
PPC_FUNC_IMPL(__imp__sub_82C9B388) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C9B390;
	sub_82CA2BE8(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// lwz r31,356(r28)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r28.u32 + 356);
	// addi r3,r31,80
	ctx.r3.s64 = ctx.r31.s64 + 80;
	// bl 0x82c9b2f8
	ctx.lr = 0x82C9B3A4;
	sub_82C9B2F8(ctx, base);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82c9b3bc
	if (!ctx.cr6.eq) goto loc_82C9B3BC;
loc_82C9B3B0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9B3BC:
	// li r5,24
	ctx.r5.s64 = 24;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r3,r31,20
	ctx.r3.s64 = ctx.r31.s64 + 20;
	// bl 0x82c99298
	ctx.lr = 0x82C9B3CC;
	sub_82C99298(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c9b3b0
	if (ctx.cr6.eq) goto loc_82C9B3B0;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x82c9b3f4
	if (ctx.cr6.eq) goto loc_82C9B3F4;
	// lwz r11,96(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// stw r11,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9B3F4:
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// stw r11,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r11.u32);
	// bl 0x82c9aad0
	ctx.lr = 0x82C9B408;
	sub_82C9AAD0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// beq cr6,0x82c9b418
	if (ctx.cr6.eq) goto loc_82C9B418;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
loc_82C9B418:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
}

__attribute__((alias("__imp__sub_82C9B420"))) PPC_WEAK_FUNC(sub_82C9B420);
PPC_FUNC_IMPL(__imp__sub_82C9B420) {
	PPC_FUNC_PROLOGUE();
	// addi r11,r4,-11
	ctx.r11.s64 = ctx.r4.s64 + -11;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,18
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 18, ctx.xer);
	// bgt cr6,0x82c9b4c0
	if (ctx.cr6.gt) {
		sub_82C9B4C0(ctx, base);
		return;
	}
	// lis r12,-32054
	ctx.r12.s64 = -2100690944;
	// addi r12,r12,-19384
	ctx.r12.s64 = ctx.r12.s64 + -19384;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		// ERROR: 0x82C9B49C
		return;
	case 1:
		// ERROR: 0x82C9B4C0
		return;
	case 2:
		// ERROR: 0x82C9B4A4
		return;
	case 3:
		// ERROR: 0x82C9B4C0
		return;
	case 4:
		// ERROR: 0x82C9B494
		return;
	case 5:
		// ERROR: 0x82C9B4C0
		return;
	case 6:
		// ERROR: 0x82C9B4C0
		return;
	case 7:
		// ERROR: 0x82C9B4C0
		return;
	case 8:
		// ERROR: 0x82C9B4C0
		return;
	case 9:
		// ERROR: 0x82C9B4C0
		return;
	case 10:
		// ERROR: 0x82C9B4C0
		return;
	case 11:
		// ERROR: 0x82C9B4C0
		return;
	case 12:
		// ERROR: 0x82C9B4C0
		return;
	case 13:
		// ERROR: 0x82C9B4C0
		return;
	case 14:
		// ERROR: 0x82C9B4C0
		return;
	case 15:
		// ERROR: 0x82C9B4C0
		return;
	case 16:
		// ERROR: 0x82C9B4C0
		return;
	case 17:
		// ERROR: 0x82C9B4C0
		return;
	case 18:
		// ERROR: 0x82C9B4AC
		return;
	default:
		__builtin_unreachable();
	}
}

__attribute__((alias("__imp__sub_82C9B448"))) PPC_WEAK_FUNC(sub_82C9B448);
PPC_FUNC_IMPL(__imp__sub_82C9B448) {
	PPC_FUNC_PROLOGUE();
	// lwz r22,-19300(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19300);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19292(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19292);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19308);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19264(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19264);
	// lwz r22,-19284(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -19284);
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9B49C"))) PPC_WEAK_FUNC(sub_82C9B49C);
PPC_FUNC_IMPL(__imp__sub_82C9B49C) {
	PPC_FUNC_PROLOGUE();
	// li r3,55
	ctx.r3.s64 = 55;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9B4A4"))) PPC_WEAK_FUNC(sub_82C9B4A4);
PPC_FUNC_IMPL(__imp__sub_82C9B4A4) {
	PPC_FUNC_PROLOGUE();
	// li r3,56
	ctx.r3.s64 = 56;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9B4AC"))) PPC_WEAK_FUNC(sub_82C9B4AC);
PPC_FUNC_IMPL(__imp__sub_82C9B4AC) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-31968
	ctx.r11.s64 = -2095054848;
	// li r3,2
	ctx.r3.s64 = 2;
	// addi r9,r11,-11496
	ctx.r9.s64 = ctx.r11.s64 + -11496;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9B4C0"))) PPC_WEAK_FUNC(sub_82C9B4C0);
PPC_FUNC_IMPL(__imp__sub_82C9B4C0) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,16(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c9b4dc
	if (!ctx.cr6.eq) goto loc_82C9B4DC;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9b4dc
	if (!ctx.cr6.eq) goto loc_82C9B4DC;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9B4DC:
	// lis r11,-31968
	ctx.r11.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r11,-11496
	ctx.r9.s64 = ctx.r11.s64 + -11496;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9B4F0"))) PPC_WEAK_FUNC(sub_82C9B4F0);
PPC_FUNC_IMPL(__imp__sub_82C9B4F0) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9b548
	if (ctx.cr6.eq) goto loc_82C9B548;
	// cmpwi cr6,r4,17
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 17, ctx.xer);
	// beq cr6,0x82c9b534
	if (ctx.cr6.eq) goto loc_82C9B534;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9b520
	if (!ctx.cr6.eq) goto loc_82C9B520;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9b520
	if (!ctx.cr6.eq) goto loc_82C9B520;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9B520:
	// lis r10,-31968
	ctx.r10.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r10,-11496
	ctx.r9.s64 = ctx.r10.s64 + -11496;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9B534:
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r3,8
	ctx.r3.s64 = 8;
	// addi r9,r10,-19424
	ctx.r9.s64 = ctx.r10.s64 + -19424;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9B548:
	// li r3,3
	ctx.r3.s64 = 3;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9B550"))) PPC_WEAK_FUNC(sub_82C9B550);
PPC_FUNC_IMPL(__imp__sub_82C9B550) {
	PPC_FUNC_PROLOGUE();
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9b5c8
	if (ctx.cr6.eq) goto loc_82C9B5C8;
	// lwz r11,16(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// cmpwi cr6,r4,17
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 17, ctx.xer);
	// beq cr6,0x82c9b598
	if (ctx.cr6.eq) goto loc_82C9B598;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c9b580
	if (!ctx.cr6.eq) goto loc_82C9B580;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9b580
	if (!ctx.cr6.eq) goto loc_82C9B580;
	// li r11,59
	ctx.r11.s64 = 59;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// blr 
	return;
loc_82C9B580:
	// lis r10,-31968
	ctx.r10.s64 = -2095054848;
	// li r11,-1
	ctx.r11.s64 = -1;
	// addi r9,r10,-11496
	ctx.r9.s64 = ctx.r10.s64 + -11496;
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// blr 
	return;
loc_82C9B598:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c9b5b4
	if (ctx.cr6.eq) goto loc_82C9B5B4;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r11,r11,7224
	ctx.r11.s64 = ctx.r11.s64 + 7224;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// li r3,15
	ctx.r3.s64 = 15;
	// blr 
	return;
loc_82C9B5B4:
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r11,r11,7832
	ctx.r11.s64 = ctx.r11.s64 + 7832;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// li r3,15
	ctx.r3.s64 = 15;
	// blr 
	return;
loc_82C9B5C8:
	// li r3,11
	ctx.r3.s64 = 11;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9B5D0"))) PPC_WEAK_FUNC(sub_82C9B5D0);
PPC_FUNC_IMPL(__imp__sub_82C9B5D0) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9b628
	if (ctx.cr6.eq) goto loc_82C9B628;
	// cmpwi cr6,r4,27
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 27, ctx.xer);
	// beq cr6,0x82c9b614
	if (ctx.cr6.eq) goto loc_82C9B614;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9b600
	if (!ctx.cr6.eq) goto loc_82C9B600;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9b600
	if (!ctx.cr6.eq) goto loc_82C9B600;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9B600:
	// lis r10,-31968
	ctx.r10.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r10,-11496
	ctx.r9.s64 = ctx.r10.s64 + -11496;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9B614:
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r3,38
	ctx.r3.s64 = 38;
	// addi r9,r10,6656
	ctx.r9.s64 = ctx.r10.s64 + 6656;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9B628:
	// li r3,33
	ctx.r3.s64 = 33;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9B630"))) PPC_WEAK_FUNC(sub_82C9B630);
PPC_FUNC_IMPL(__imp__sub_82C9B630) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9b68c
	if (ctx.cr6.eq) goto loc_82C9B68C;
	// cmpwi cr6,r4,25
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 25, ctx.xer);
	// beq cr6,0x82c9b674
	if (ctx.cr6.eq) goto loc_82C9B674;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9b660
	if (!ctx.cr6.eq) goto loc_82C9B660;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9b660
	if (!ctx.cr6.eq) goto loc_82C9B660;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9B660:
	// lis r10,-31968
	ctx.r10.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r10,-11496
	ctx.r9.s64 = ctx.r10.s64 + -11496;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9B674:
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lis r9,-32054
	ctx.r9.s64 = -2100690944;
	// addi r8,r9,7832
	ctx.r8.s64 = ctx.r9.s64 + 7832;
	// addi r7,r10,1
	ctx.r7.s64 = ctx.r10.s64 + 1;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// stw r7,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r7.u32);
loc_82C9B68C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9B694"))) PPC_WEAK_FUNC(sub_82C9B694);
PPC_FUNC_IMPL(__imp__sub_82C9B694) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9B698"))) PPC_WEAK_FUNC(sub_82C9B698);
PPC_FUNC_IMPL(__imp__sub_82C9B698) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9b6f0
	if (ctx.cr6.eq) goto loc_82C9B6F0;
	// cmpwi cr6,r4,25
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 25, ctx.xer);
	// beq cr6,0x82c9b6dc
	if (ctx.cr6.eq) goto loc_82C9B6DC;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9b6c8
	if (!ctx.cr6.eq) goto loc_82C9B6C8;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9b6c8
	if (!ctx.cr6.eq) goto loc_82C9B6C8;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9B6C8:
	// lis r10,-31968
	ctx.r10.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r10,-11496
	ctx.r9.s64 = ctx.r10.s64 + -11496;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9B6DC:
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r3,58
	ctx.r3.s64 = 58;
	// addi r9,r10,7832
	ctx.r9.s64 = ctx.r10.s64 + 7832;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9B6F0:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9B6F8"))) PPC_WEAK_FUNC(sub_82C9B6F8);
PPC_FUNC_IMPL(__imp__sub_82C9B6F8) {
	PPC_FUNC_PROLOGUE();
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9b764
	if (ctx.cr6.eq) goto loc_82C9B764;
	// lwz r11,16(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmpwi cr6,r4,17
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 17, ctx.xer);
	// beq cr6,0x82c9b73c
	if (ctx.cr6.eq) goto loc_82C9B73C;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c9b728
	if (!ctx.cr6.eq) goto loc_82C9B728;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9b728
	if (!ctx.cr6.eq) goto loc_82C9B728;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9B728:
	// lis r11,-31968
	ctx.r11.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r11,-11496
	ctx.r9.s64 = ctx.r11.s64 + -11496;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9B73C:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c9b758
	if (ctx.cr6.eq) goto loc_82C9B758;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// lwz r3,8(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// addi r11,r11,7224
	ctx.r11.s64 = ctx.r11.s64 + 7224;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r11.u32);
	// blr 
	return;
loc_82C9B758:
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r11,r11,7832
	ctx.r11.s64 = ctx.r11.s64 + 7832;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r11.u32);
loc_82C9B764:
	// lwz r3,8(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9B76C"))) PPC_WEAK_FUNC(sub_82C9B76C);
PPC_FUNC_IMPL(__imp__sub_82C9B76C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9B770"))) PPC_WEAK_FUNC(sub_82C9B770);
PPC_FUNC_IMPL(__imp__sub_82C9B770) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C9B778;
	sub_82CA2BE8(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c9b8f0
	if (ctx.cr6.eq) goto loc_82C9B8F0;
	// lwz r30,364(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 364);
	// li r29,0
	ctx.r29.s64 = 0;
loc_82C9B790:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82c9b7a8
	if (!ctx.cr6.eq) goto loc_82C9B7A8;
	// lwz r30,368(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 368);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c9b7e0
	if (ctx.cr6.eq) goto loc_82C9B7E0;
	// stw r29,368(r31)
	PPC_STORE_U32(ctx.r31.u32 + 368, ctx.r29.u32);
loc_82C9B7A8:
	// mr r28,r30
	ctx.r28.u64 = ctx.r30.u64;
	// lwz r30,0(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r3,36(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 36);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9B7C0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r3,44(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 44);
	// bl 0x82c98658
	ctx.lr = 0x82C9B7CC;
	sub_82C98658(ctx, base);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9B7DC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82c9b790
	goto loc_82C9B790;
loc_82C9B7E0:
	// lwz r30,300(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 300);
loc_82C9B7E4:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82c9b7fc
	if (!ctx.cr6.eq) goto loc_82C9B7FC;
	// lwz r30,304(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 304);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82c9b814
	if (ctx.cr6.eq) goto loc_82C9B814;
	// stw r29,304(r31)
	PPC_STORE_U32(ctx.r31.u32 + 304, ctx.r29.u32);
loc_82C9B7FC:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r30,8(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9B810;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82c9b7e4
	goto loc_82C9B7E4;
loc_82C9B814:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r3,376(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 376);
	// bl 0x82c98658
	ctx.lr = 0x82C9B820;
	sub_82C98658(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r3,372(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 372);
	// bl 0x82c98658
	ctx.lr = 0x82C9B82C;
	sub_82C98658(ctx, base);
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99780
	ctx.lr = 0x82C9B834;
	sub_82C99780(ctx, base);
	// addi r3,r31,440
	ctx.r3.s64 = ctx.r31.s64 + 440;
	// bl 0x82c99780
	ctx.lr = 0x82C9B83C;
	sub_82C99780(ctx, base);
	// lbz r11,488(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 488);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9b868
	if (!ctx.cr6.eq) goto loc_82C9B868;
	// lwz r3,356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 356);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c9b868
	if (ctx.cr6.eq) goto loc_82C9B868;
	// lwz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 476);
	// addi r5,r31,12
	ctx.r5.s64 = ctx.r31.s64 + 12;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r4,r10,27,31,31
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// bl 0x82c9b0c0
	ctx.lr = 0x82C9B868;
	sub_82C9B0C0(ctx, base);
loc_82C9B868:
	// lwz r3,392(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 392);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9B878;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,464(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 464);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9B888;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r9,20(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C9B898;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,44(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// lwz r8,20(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82C9B8A8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,396(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 396);
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
	// bctrl 
	ctx.lr = 0x82C9B8B8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r3,240(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 240);
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mtctr r6
	ctx.ctr.u64 = ctx.r6.u64;
	// bctrl 
	ctx.lr = 0x82C9B8C8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r11,252(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 252);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9b8e0
	if (ctx.cr6.eq) goto loc_82C9B8E0;
	// lwz r3,244(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 244);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9B8E0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82C9B8E0:
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9B8F0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82C9B8F0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
}

__attribute__((alias("__imp__sub_82C9B8F8"))) PPC_WEAK_FUNC(sub_82C9B8F8);
PPC_FUNC_IMPL(__imp__sub_82C9B8F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be8
	ctx.lr = 0x82C9B900;
	sub_82CA2BE8(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// lwz r11,480(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82c9ba3c
	if (ctx.cr6.eq) goto loc_82C9BA3C;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82c9ba28
	if (ctx.cr6.eq) goto loc_82C9BA28;
	// li r11,1
	ctx.r11.s64 = 1;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// stw r11,480(r31)
	PPC_STORE_U32(ctx.r31.u32 + 480, ctx.r11.u32);
	// bne cr6,0x82c9b9f0
	if (!ctx.cr6.eq) goto loc_82C9B9F0;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// stb r29,484(r31)
	PPC_STORE_U8(ctx.r31.u32 + 484, ctx.r29.u8);
	// beq cr6,0x82c9b9c4
	if (ctx.cr6.eq) goto loc_82C9B9C4;
	// lwz r5,28(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// addi r30,r31,24
	ctx.r30.s64 = ctx.r31.s64 + 24;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r11,280(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 280);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// stw r5,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r5.u32);
	// stw r4,296(r31)
	PPC_STORE_U32(ctx.r31.u32 + 296, ctx.r4.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9B968;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 284, ctx.r3.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c9b9d0
	if (!ctx.cr6.eq) goto loc_82C9B9D0;
	// lwz r11,480(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// blt cr6,0x82c9b9bc
	if (ctx.cr6.lt) goto loc_82C9B9BC;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bne cr6,0x82c9b9c4
	if (!ctx.cr6.eq) goto loc_82C9B9C4;
	// lwz r11,144(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// addi r6,r31,408
	ctx.r6.s64 = ctx.r31.s64 + 408;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r4,296(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 296);
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9B9A8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r3,2
	ctx.r3.s64 = 2;
	// stw r9,296(r31)
	PPC_STORE_U32(ctx.r31.u32 + 296, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9B9BC:
	// li r11,2
	ctx.r11.s64 = 2;
	// stw r11,480(r31)
	PPC_STORE_U32(ctx.r31.u32 + 480, ctx.r11.u32);
loc_82C9B9C4:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9B9D0:
	// lwz r11,288(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 288);
	// lis r10,-32204
	ctx.r10.s64 = -2110521344;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r9,r10,-11704
	ctx.r9.s64 = ctx.r10.s64 + -11704;
	// stw r9,280(r31)
	PPC_STORE_U32(ctx.r31.u32 + 280, ctx.r9.u32);
	// stw r11,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9B9F0:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c986f8
	ctx.lr = 0x82C9B9FC;
	sub_82C986F8(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c9ba44
	if (ctx.cr6.eq) goto loc_82C9BA44;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82ca2c60
	ctx.lr = 0x82C9BA10;
	sub_82CA2C60(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c9a360
	ctx.lr = 0x82C9BA20;
	sub_82C9A360(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9BA28:
	// li r11,33
	ctx.r11.s64 = 33;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 284, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
loc_82C9BA3C:
	// li r11,36
	ctx.r11.s64 = 36;
	// stw r11,284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 284, ctx.r11.u32);
loc_82C9BA44:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x82ca2c38
	// ERROR 82CA2C38
	return;
}

__attribute__((alias("__imp__sub_82C9BA50"))) PPC_WEAK_FUNC(sub_82C9BA50);
PPC_FUNC_IMPL(__imp__sub_82C9BA50) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C9BA58;
	sub_82CA2BEC(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// stw r4,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r4.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// lbz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 484);
	// addi r5,r1,140
	ctx.r5.s64 = ctx.r1.s64 + 140;
	// lwz r4,144(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r8,r10,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// bl 0x82c9a490
	ctx.lr = 0x82C9BA8C;
	sub_82C9A490(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c9bb38
	if (!ctx.cr6.eq) goto loc_82C9BB38;
	// lwz r4,140(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c9bb34
	if (ctx.cr6.eq) goto loc_82C9BB34;
	// lwz r11,476(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 476);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9bad0
	if (ctx.cr6.eq) goto loc_82C9BAD0;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// addi r10,r11,-30128
	ctx.r10.s64 = ctx.r11.s64 + -30128;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// stw r10,280(r31)
	PPC_STORE_U32(ctx.r31.u32 + 280, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c98a50
	ctx.lr = 0x82C9BAC8;
	sub_82C98A50(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C9BAD0:
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// lbz r10,484(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 484);
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// lwz r5,144(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// addi r9,r11,-1320
	ctx.r9.s64 = ctx.r11.s64 + -1320;
	// cntlzw r4,r10
	ctx.r4.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// stw r9,280(r31)
	PPC_STORE_U32(ctx.r31.u32 + 280, ctx.r9.u32);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// rlwinm r9,r4,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x1;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c9eac0
	ctx.lr = 0x82C9BB04;
	sub_82C9EAC0(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82c9bb28
	if (!ctx.cr6.eq) goto loc_82C9BB28;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c98970
	ctx.lr = 0x82C9BB18;
	sub_82C98970(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// li r3,1
	ctx.r3.s64 = 1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9bb38
	if (ctx.cr6.eq) goto loc_82C9BB38;
loc_82C9BB28:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C9BB34:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C9BB38:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
}

__attribute__((alias("__imp__sub_82C9BB40"))) PPC_WEAK_FUNC(sub_82C9BB40);
PPC_FUNC_IMPL(__imp__sub_82C9BB40) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bec
	ctx.lr = 0x82C9BB48;
	sub_82CA2BEC(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// stw r4,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r4.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// lbz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 484);
	// addi r5,r1,140
	ctx.r5.s64 = ctx.r1.s64 + 140;
	// lwz r4,144(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r8,r10,27,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// bl 0x82c9a840
	ctx.lr = 0x82C9BB7C;
	sub_82C9A840(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c9bbb8
	if (!ctx.cr6.eq) goto loc_82C9BBB8;
	// lwz r4,140(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c9bbb4
	if (ctx.cr6.eq) goto loc_82C9BBB4;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// addi r10,r11,5976
	ctx.r10.s64 = ctx.r11.s64 + 5976;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// stw r10,280(r31)
	PPC_STORE_U32(ctx.r31.u32 + 280, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82ca1758
	ctx.lr = 0x82C9BBAC;
	sub_82CA1758(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
loc_82C9BBB4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82C9BBB8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x82ca2c3c
	// ERROR 82CA2C3C
	return;
}

__attribute__((alias("__imp__sub_82C9BBC0"))) PPC_WEAK_FUNC(sub_82C9BBC0);
PPC_FUNC_IMPL(__imp__sub_82C9BBC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bdc
	ctx.lr = 0x82C9BBC8;
	sub_82CA2BDC(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r29,0
	ctx.r29.s64 = 0;
	// li r10,-1
	ctx.r10.s64 = -1;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r29.u32);
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r29.u32);
	// lbz r11,236(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 236);
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// mr r26,r29
	ctx.r26.u64 = ctx.r29.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r29,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r29.u32);
	// beq cr6,0x82c9bc10
	if (ctx.cr6.eq) goto loc_82C9BC10;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r11,r11,-31304
	ctx.r11.s64 = ctx.r11.s64 + -31304;
	// b 0x82c9bc18
	goto loc_82C9BC18;
loc_82C9BC10:
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r11,r11,-31824
	ctx.r11.s64 = ctx.r11.s64 + -31824;
loc_82C9BC18:
	// addi r10,r1,100
	ctx.r10.s64 = ctx.r1.s64 + 100;
	// lwz r4,144(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// addi r8,r1,108
	ctx.r8.s64 = ctx.r1.s64 + 108;
	// addi r25,r31,288
	ctx.r25.s64 = ctx.r31.s64 + 288;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// addi r8,r1,104
	ctx.r8.s64 = ctx.r1.s64 + 104;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9BC54;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c9bc74
	if (!ctx.cr6.eq) goto loc_82C9BC74;
	// cntlzw r11,r30
	ctx.r11.u64 = ctx.r30.u32 == 0 ? 32 : __builtin_clz(ctx.r30.u32);
	// rlwinm r10,r11,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// xori r11,r10,1
	ctx.r11.u64 = ctx.r10.u64 ^ 1;
	// addi r3,r11,30
	ctx.r3.s64 = ctx.r11.s64 + 30;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c2c
	// ERROR 82CA2C2C
	return;
loc_82C9BC74:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x82c9bca4
	if (!ctx.cr6.eq) goto loc_82C9BCA4;
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82c9bca4
	if (!ctx.cr6.eq) goto loc_82C9BCA4;
	// lwz r11,356(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 356);
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r10,130(r11)
	PPC_STORE_U8(ctx.r11.u32 + 130, ctx.r10.u8);
	// lwz r9,492(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 492);
	// cmpwi cr6,r9,1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 1, ctx.xer);
	// bne cr6,0x82c9bca4
	if (!ctx.cr6.eq) goto loc_82C9BCA4;
	// stw r29,492(r31)
	PPC_STORE_U32(ctx.r31.u32 + 492, ctx.r29.u32);
loc_82C9BCA4:
	// lwz r11,140(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 140);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9bd54
	if (ctx.cr6.eq) goto loc_82C9BD54;
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c9bd04
	if (ctx.cr6.eq) goto loc_82C9BD04;
	// lwz r11,144(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9BCD0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r4,144(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// add r6,r3,r5
	ctx.r6.u64 = ctx.r3.u64 + ctx.r5.u64;
	// addi r3,r31,440
	ctx.r3.s64 = ctx.r31.s64 + 440;
	// bl 0x82c9b2f8
	ctx.lr = 0x82C9BCE4;
	sub_82C9B2F8(ctx, base);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82c9bcfc
	if (!ctx.cr6.eq) goto loc_82C9BCFC;
loc_82C9BCF0:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c2c
	// ERROR 82CA2C2C
	return;
loc_82C9BCFC:
	// lwz r11,452(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 452);
	// stw r11,456(r31)
	PPC_STORE_U32(ctx.r31.u32 + 456, ctx.r11.u32);
loc_82C9BD04:
	// lwz r5,104(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82c9bd34
	if (ctx.cr6.eq) goto loc_82C9BD34;
	// lwz r4,144(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// addi r3,r31,440
	ctx.r3.s64 = ctx.r31.s64 + 440;
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r10,68(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 68);
	// subf r6,r10,r11
	ctx.r6.s64 = ctx.r11.s64 - ctx.r10.s64;
	// bl 0x82c9b2f8
	ctx.lr = 0x82C9BD28;
	sub_82C9B2F8(ctx, base);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82c9bcf0
	if (ctx.cr6.eq) goto loc_82C9BCF0;
loc_82C9BD34:
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r6,100(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// lwz r11,140(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 140);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9BD50;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82c9bd74
	goto loc_82C9BD74;
loc_82C9BD54:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9bd74
	if (ctx.cr6.eq) goto loc_82C9BD74;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// lwz r4,144(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c98fd8
	ctx.lr = 0x82C9BD74;
	sub_82C98FD8(ctx, base);
loc_82C9BD74:
	// lwz r11,232(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 232);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9bdb8
	if (!ctx.cr6.eq) goto loc_82C9BDB8;
	// lwz r11,108(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9bddc
	if (ctx.cr6.eq) goto loc_82C9BDDC;
	// lwz r10,144(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// lwz r9,68(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	// lwz r8,68(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 68);
	// cmpw cr6,r9,r8
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r8.s32, ctx.xer);
	// beq cr6,0x82c9bdb4
	if (ctx.cr6.eq) goto loc_82C9BDB4;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// li r3,19
	ctx.r3.s64 = 19;
	// stw r11,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r11.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c2c
	// ERROR 82CA2C2C
	return;
loc_82C9BDB4:
	// stw r11,144(r31)
	PPC_STORE_U32(ctx.r31.u32 + 144, ctx.r11.u32);
loc_82C9BDB8:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82c9bdc8
	if (!ctx.cr6.eq) goto loc_82C9BDC8;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82c9bdd0
	if (ctx.cr6.eq) goto loc_82C9BDD0;
loc_82C9BDC8:
	// addi r3,r31,440
	ctx.r3.s64 = ctx.r31.s64 + 440;
	// bl 0x82c99728
	ctx.lr = 0x82C9BDD0;
	sub_82C99728(ctx, base);
loc_82C9BDD0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c2c
	// ERROR 82CA2C2C
	return;
loc_82C9BDDC:
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c9bdb8
	if (ctx.cr6.eq) goto loc_82C9BDB8;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82c9be24
	if (!ctx.cr6.eq) goto loc_82C9BE24;
	// lwz r11,144(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9BE04;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r4,144(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// add r6,r3,r5
	ctx.r6.u64 = ctx.r3.u64 + ctx.r5.u64;
	// addi r3,r31,440
	ctx.r3.s64 = ctx.r31.s64 + 440;
	// bl 0x82c9b2f8
	ctx.lr = 0x82C9BE18;
	sub_82C9B2F8(ctx, base);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82c9bcf0
	if (ctx.cr6.eq) goto loc_82C9BCF0;
loc_82C9BE24:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c98ca8
	ctx.lr = 0x82C9BE30;
	sub_82C98CA8(ctx, base);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// addi r3,r31,440
	ctx.r3.s64 = ctx.r31.s64 + 440;
	// bl 0x82c99728
	ctx.lr = 0x82C9BE3C;
	sub_82C99728(ctx, base);
	// cmpwi cr6,r8,18
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 18, ctx.xer);
	// bne cr6,0x82c9be4c
	if (!ctx.cr6.eq) goto loc_82C9BE4C;
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r11.u32);
loc_82C9BE4C:
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c2c
	// ERROR 82CA2C2C
	return;
}

__attribute__((alias("__imp__sub_82C9BE58"))) PPC_WEAK_FUNC(sub_82C9BE58);
PPC_FUNC_IMPL(__imp__sub_82C9BE58) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bc8
	ctx.lr = 0x82C9BE60;
	sub_82CA2BC8(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r21,r7
	ctx.r21.u64 = ctx.r7.u64;
	// mr r24,r5
	ctx.r24.u64 = ctx.r5.u64;
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// mr r30,r8
	ctx.r30.u64 = ctx.r8.u64;
	// lwz r25,356(r26)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r26.u32 + 356);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9BE9C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r11,r3,4
	ctx.r11.s64 = ctx.r3.s64 + 4;
	// cmplwi cr6,r11,43
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 43, ctx.xer);
	// bgt cr6,0x82c9c280
	if (ctx.cr6.gt) goto loc_82C9C280;
	// li r23,0
	ctx.r23.s64 = 0;
	// li r20,32
	ctx.r20.s64 = 32;
	// li r22,1
	ctx.r22.s64 = 1;
loc_82C9BEB4:
	// lis r12,-32054
	ctx.r12.s64 = -2100690944;
	// addi r12,r12,-16692
	ctx.r12.s64 = ctx.r12.s64 + -16692;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9C2D4;
	case 1:
		goto loc_82C9C05C;
	case 2:
		goto loc_82C9C280;
	case 3:
		goto loc_82C9C300;
	case 4:
		goto loc_82C9C2E0;
	case 5:
		goto loc_82C9C280;
	case 6:
		goto loc_82C9C280;
	case 7:
		goto loc_82C9C280;
	case 8:
		goto loc_82C9C280;
	case 9:
		goto loc_82C9C280;
	case 10:
		goto loc_82C9C034;
	case 11:
		goto loc_82C9C068;
	case 12:
		goto loc_82C9C280;
	case 13:
		goto loc_82C9C0CC;
	case 14:
		goto loc_82C9BF7C;
	case 15:
		goto loc_82C9C280;
	case 16:
		goto loc_82C9C280;
	case 17:
		goto loc_82C9C280;
	case 18:
		goto loc_82C9C280;
	case 19:
		goto loc_82C9C280;
	case 20:
		goto loc_82C9C280;
	case 21:
		goto loc_82C9C280;
	case 22:
		goto loc_82C9C280;
	case 23:
		goto loc_82C9C280;
	case 24:
		goto loc_82C9C280;
	case 25:
		goto loc_82C9C280;
	case 26:
		goto loc_82C9C280;
	case 27:
		goto loc_82C9C280;
	case 28:
		goto loc_82C9C280;
	case 29:
		goto loc_82C9C280;
	case 30:
		goto loc_82C9C280;
	case 31:
		goto loc_82C9C280;
	case 32:
		goto loc_82C9C280;
	case 33:
		goto loc_82C9C280;
	case 34:
		goto loc_82C9C280;
	case 35:
		goto loc_82C9C280;
	case 36:
		goto loc_82C9C280;
	case 37:
		goto loc_82C9C280;
	case 38:
		goto loc_82C9C280;
	case 39:
		goto loc_82C9C280;
	case 40:
		goto loc_82C9C280;
	case 41:
		goto loc_82C9C280;
	case 42:
		goto loc_82C9C280;
	case 43:
		goto loc_82C9C068;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-15660(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15660);
	// lwz r22,-16292(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -16292);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15616(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15616);
	// lwz r22,-15648(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15648);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-16332(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -16332);
	// lwz r22,-16280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -16280);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-16180(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -16180);
	// lwz r22,-16516(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -16516);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-15744(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15744);
	// lwz r22,-16280(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -16280);
loc_82C9BF7C:
	// lwz r11,44(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 44);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9BF90;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt cr6,0x82c9c31c
	if (ctx.cr6.lt) goto loc_82C9C31C;
	// clrlwi r11,r24,24
	ctx.r11.u64 = ctx.r24.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9bfc8
	if (!ctx.cr6.eq) goto loc_82C9BFC8;
	// cmpwi cr6,r3,32
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 32, ctx.xer);
	// bne cr6,0x82c9bfc8
	if (!ctx.cr6.eq) goto loc_82C9BFC8;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// subf. r9,r10,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r10.s64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq 0x82c9c254
	if (ctx.cr0.eq) goto loc_82C9C254;
	// lbz r11,-1(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + -1);
	// cmplwi cr6,r11,32
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 32, ctx.xer);
	// beq cr6,0x82c9c254
	if (ctx.cr6.eq) goto loc_82C9C254;
loc_82C9BFC8:
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// bl 0x82c97790
	ctx.lr = 0x82C9BFD0;
	sub_82C97790(ctx, base);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// beq cr6,0x82c9c31c
	if (ctx.cr6.eq) goto loc_82C9C31C;
	// mr r31,r23
	ctx.r31.u64 = ctx.r23.u64;
	// ble cr6,0x82c9c254
	if (!ctx.cr6.gt) goto loc_82C9C254;
loc_82C9BFE4:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9c008
	if (!ctx.cr6.eq) goto loc_82C9C008;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c99808
	ctx.lr = 0x82C9BFFC;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9c050
	if (ctx.cr6.eq) goto loc_82C9C050;
loc_82C9C008:
	// addi r11,r1,84
	ctx.r11.s64 = ctx.r1.s64 + 84;
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lbzx r9,r31,r11
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + ctx.r11.u32);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmpw cr6,r31,r29
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r29.s32, ctx.xer);
	// stb r9,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r9.u8);
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// addi r8,r11,1
	ctx.r8.s64 = ctx.r11.s64 + 1;
	// stw r8,12(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12, ctx.r8.u32);
	// blt cr6,0x82c9bfe4
	if (ctx.cr6.lt) goto loc_82C9BFE4;
	// b 0x82c9c254
	goto loc_82C9C254;
loc_82C9C034:
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c9b1a8
	ctx.lr = 0x82C9C048;
	sub_82C9B1A8(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c9c254
	if (!ctx.cr6.eq) goto loc_82C9C254;
loc_82C9C050:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	// ERROR 82CA2C18
	return;
loc_82C9C05C:
	// lwz r11,68(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 68);
	// add r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 + ctx.r28.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
loc_82C9C068:
	// clrlwi r11,r24,24
	ctx.r11.u64 = ctx.r24.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9c090
	if (!ctx.cr6.eq) goto loc_82C9C090;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// subf. r9,r10,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r10.s64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq 0x82c9c254
	if (ctx.cr0.eq) goto loc_82C9C254;
	// lbz r11,-1(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + -1);
	// cmplwi cr6,r11,32
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 32, ctx.xer);
	// beq cr6,0x82c9c254
	if (ctx.cr6.eq) goto loc_82C9C254;
loc_82C9C090:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c0b4
	if (!ctx.cr6.eq) goto loc_82C9C0B4;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c99808
	ctx.lr = 0x82C9C0A8;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9c050
	if (ctx.cr6.eq) goto loc_82C9C050;
loc_82C9C0B4:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// stb r20,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r20.u8);
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,12(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12, ctx.r10.u32);
	// b 0x82c9c254
	goto loc_82C9C254;
loc_82C9C0CC:
	// lwz r11,68(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 68);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,48(r27)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r27.u32 + 48);
	// add r4,r11,r28
	ctx.r4.u64 = ctx.r11.u64 + ctx.r28.u64;
	// subf r5,r11,r10
	ctx.r5.s64 = ctx.r10.s64 - ctx.r11.s64;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C9C0EC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// extsb r31,r3
	ctx.r31.s64 = ctx.r3.s8;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// beq cr6,0x82c9c134
	if (ctx.cr6.eq) goto loc_82C9C134;
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c11c
	if (!ctx.cr6.eq) goto loc_82C9C11C;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c99808
	ctx.lr = 0x82C9C110;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9c050
	if (ctx.cr6.eq) goto loc_82C9C050;
loc_82C9C11C:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// stb r31,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r31.u8);
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,12(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12, ctx.r10.u32);
	// b 0x82c9c254
	goto loc_82C9C254;
loc_82C9C134:
	// lwz r11,68(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 68);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r3,r26,440
	ctx.r3.s64 = ctx.r26.s64 + 440;
	// add r5,r11,r28
	ctx.r5.u64 = ctx.r11.u64 + ctx.r28.u64;
	// subf r6,r11,r10
	ctx.r6.s64 = ctx.r10.s64 - ctx.r11.s64;
	// bl 0x82c9b2f8
	ctx.lr = 0x82C9C150;
	sub_82C9B2F8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c9c050
	if (ctx.cr6.eq) goto loc_82C9C050;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82c99298
	ctx.lr = 0x82C9C168;
	sub_82C99298(ctx, base);
	// lwz r11,456(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 456);
	// addi r10,r25,80
	ctx.r10.s64 = ctx.r25.s64 + 80;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplw cr6,r30,r10
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r10.u32, ctx.xer);
	// stw r11,452(r26)
	PPC_STORE_U32(ctx.r26.u32 + 452, ctx.r11.u32);
	// bne cr6,0x82c9c1c0
	if (!ctx.cr6.eq) goto loc_82C9C1C0;
	// lwz r11,272(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 272);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c9c1b8
	if (ctx.cr6.eq) goto loc_82C9C1B8;
	// lbz r11,130(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 130);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9c1a0
	if (ctx.cr6.eq) goto loc_82C9C1A0;
	// lwz r11,300(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 300);
	// b 0x82c9c1a4
	goto loc_82C9C1A4;
loc_82C9C1A0:
	// lbz r11,129(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 129);
loc_82C9C1A4:
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r10,27,31,31
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// mr r11,r22
	ctx.r11.u64 = ctx.r22.u64;
	// bne cr6,0x82c9c1e0
	if (!ctx.cr6.eq) goto loc_82C9C1E0;
loc_82C9C1B8:
	// mr r11,r23
	ctx.r11.u64 = ctx.r23.u64;
	// b 0x82c9c1e0
	goto loc_82C9C1E0;
loc_82C9C1C0:
	// lbz r11,129(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 129);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9c1dc
	if (ctx.cr6.eq) goto loc_82C9C1DC;
	// lbz r11,130(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 130);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// mr r11,r23
	ctx.r11.u64 = ctx.r23.u64;
	// beq cr6,0x82c9c1e0
	if (ctx.cr6.eq) goto loc_82C9C1E0;
loc_82C9C1DC:
	// mr r11,r22
	ctx.r11.u64 = ctx.r22.u64;
loc_82C9C1E0:
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c9c29c
	if (ctx.cr6.eq) goto loc_82C9C29C;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82c9c338
	if (ctx.cr6.eq) goto loc_82C9C338;
	// lbz r11,34(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 34);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9c344
	if (ctx.cr6.eq) goto loc_82C9C344;
loc_82C9C204:
	// lbz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9c350
	if (!ctx.cr6.eq) goto loc_82C9C350;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9c36c
	if (!ctx.cr6.eq) goto loc_82C9C36C;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82c9c388
	if (ctx.cr6.eq) goto loc_82C9C388;
	// stb r22,32(r31)
	PPC_STORE_U8(ctx.r31.u32 + 32, ctx.r22.u8);
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lwz r4,228(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 228);
	// add r7,r11,r6
	ctx.r7.u64 = ctx.r11.u64 + ctx.r6.u64;
	// bl 0x82c9be58
	ctx.lr = 0x82C9C248;
	sub_82C9BE58(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// stb r23,32(r31)
	PPC_STORE_U8(ctx.r31.u32 + 32, ctx.r23.u8);
	// bne cr6,0x82c9c294
	if (!ctx.cr6.eq) goto loc_82C9C294;
loc_82C9C254:
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r11,16(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9C274;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r11,r3,4
	ctx.r11.s64 = ctx.r3.s64 + 4;
	// cmplwi cr6,r11,43
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 43, ctx.xer);
	// ble cr6,0x82c9beb4
	if (!ctx.cr6.gt) goto loc_82C9BEB4;
loc_82C9C280:
	// lwz r11,144(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 144);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c290
	if (!ctx.cr6.eq) goto loc_82C9C290;
	// stw r28,288(r26)
	PPC_STORE_U32(ctx.r26.u32 + 288, ctx.r28.u32);
loc_82C9C290:
	// li r3,23
	ctx.r3.s64 = 23;
loc_82C9C294:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	// ERROR 82CA2C18
	return;
loc_82C9C29C:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82c9c204
	if (!ctx.cr6.eq) goto loc_82C9C204;
	// addi r11,r26,416
	ctx.r11.s64 = ctx.r26.s64 + 416;
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c254
	if (!ctx.cr6.eq) goto loc_82C9C254;
	// lwz r11,80(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9c254
	if (ctx.cr6.eq) goto loc_82C9C254;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c98fd8
	ctx.lr = 0x82C9C2D0;
	sub_82C98FD8(ctx, base);
	// b 0x82c9c254
	goto loc_82C9C254;
loc_82C9C2D4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	// ERROR 82CA2C18
	return;
loc_82C9C2E0:
	// lwz r11,144(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 144);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c2f4
	if (!ctx.cr6.eq) goto loc_82C9C2F4;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,288(r26)
	PPC_STORE_U32(ctx.r26.u32 + 288, ctx.r11.u32);
loc_82C9C2F4:
	// li r3,4
	ctx.r3.s64 = 4;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	// ERROR 82CA2C18
	return;
loc_82C9C300:
	// lwz r11,144(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 144);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c310
	if (!ctx.cr6.eq) goto loc_82C9C310;
	// stw r28,288(r26)
	PPC_STORE_U32(ctx.r26.u32 + 288, ctx.r28.u32);
loc_82C9C310:
	// li r3,4
	ctx.r3.s64 = 4;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	// ERROR 82CA2C18
	return;
loc_82C9C31C:
	// lwz r11,144(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 144);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c32c
	if (!ctx.cr6.eq) goto loc_82C9C32C;
	// stw r28,288(r26)
	PPC_STORE_U32(ctx.r26.u32 + 288, ctx.r28.u32);
loc_82C9C32C:
	// li r3,14
	ctx.r3.s64 = 14;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	// ERROR 82CA2C18
	return;
loc_82C9C338:
	// li r3,11
	ctx.r3.s64 = 11;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	// ERROR 82CA2C18
	return;
loc_82C9C344:
	// li r3,24
	ctx.r3.s64 = 24;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	// ERROR 82CA2C18
	return;
loc_82C9C350:
	// lwz r11,144(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 144);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c360
	if (!ctx.cr6.eq) goto loc_82C9C360;
	// stw r28,288(r26)
	PPC_STORE_U32(ctx.r26.u32 + 288, ctx.r28.u32);
loc_82C9C360:
	// li r3,12
	ctx.r3.s64 = 12;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	// ERROR 82CA2C18
	return;
loc_82C9C36C:
	// lwz r11,144(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 144);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c37c
	if (!ctx.cr6.eq) goto loc_82C9C37C;
	// stw r28,288(r26)
	PPC_STORE_U32(ctx.r26.u32 + 288, ctx.r28.u32);
loc_82C9C37C:
	// li r3,15
	ctx.r3.s64 = 15;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	// ERROR 82CA2C18
	return;
loc_82C9C388:
	// lwz r11,144(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 144);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c398
	if (!ctx.cr6.eq) goto loc_82C9C398;
	// stw r28,288(r26)
	PPC_STORE_U32(ctx.r26.u32 + 288, ctx.r28.u32);
loc_82C9C398:
	// li r3,16
	ctx.r3.s64 = 16;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x82ca2c18
	// ERROR 82CA2C18
	return;
}

__attribute__((alias("__imp__sub_82C9C3A4"))) PPC_WEAK_FUNC(sub_82C9C3A4);
PPC_FUNC_IMPL(__imp__sub_82C9C3A4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9C3A8"))) PPC_WEAK_FUNC(sub_82C9C3A8);
PPC_FUNC_IMPL(__imp__sub_82C9C3A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bc4
	ctx.lr = 0x82C9C3B0;
	sub_82CA2BC4(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// li r22,1
	ctx.r22.s64 = 1;
	// li r23,0
	ctx.r23.s64 = 0;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// lwz r25,356(r29)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r29.u32 + 356);
	// mr r21,r6
	ctx.r21.u64 = ctx.r6.u64;
	// lwz r19,276(r29)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r29.u32 + 276);
	// mr r24,r23
	ctx.r24.u64 = ctx.r23.u64;
	// stw r22,276(r29)
	PPC_STORE_U32(ctx.r29.u32 + 276, ctx.r22.u32);
	// addi r26,r25,104
	ctx.r26.s64 = ctx.r25.s64 + 104;
	// lwz r11,104(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 104);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9c40c
	if (!ctx.cr6.eq) goto loc_82C9C40C;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c99808
	ctx.lr = 0x82C9C3F4;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9c40c
	if (!ctx.cr6.eq) goto loc_82C9C40C;
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c14
	// ERROR 82CA2C14
	return;
loc_82C9C40C:
	// lwz r11,20(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9C428;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r11,r3,4
	ctx.r11.s64 = ctx.r3.s64 + 4;
	// cmplwi cr6,r11,32
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 32, ctx.xer);
	// bgt cr6,0x82c9c6fc
	if (ctx.cr6.gt) goto loc_82C9C6FC;
	// li r20,10
	ctx.r20.s64 = 10;
loc_82C9C438:
	// lis r12,-32054
	ctx.r12.s64 = -2100690944;
	// addi r12,r12,-15280
	ctx.r12.s64 = ctx.r12.s64 + -15280;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9C788;
	case 1:
		goto loc_82C9C604;
	case 2:
		goto loc_82C9C6FC;
	case 3:
		goto loc_82C9C7C0;
	case 4:
		goto loc_82C9C7E4;
	case 5:
		goto loc_82C9C6FC;
	case 6:
		goto loc_82C9C6FC;
	case 7:
		goto loc_82C9C6FC;
	case 8:
		goto loc_82C9C6FC;
	case 9:
		goto loc_82C9C6FC;
	case 10:
		goto loc_82C9C5D4;
	case 11:
		goto loc_82C9C610;
	case 12:
		goto loc_82C9C6FC;
	case 13:
		goto loc_82C9C5D4;
	case 14:
		goto loc_82C9C64C;
	case 15:
		goto loc_82C9C6FC;
	case 16:
		goto loc_82C9C6FC;
	case 17:
		goto loc_82C9C6FC;
	case 18:
		goto loc_82C9C6FC;
	case 19:
		goto loc_82C9C6FC;
	case 20:
		goto loc_82C9C6FC;
	case 21:
		goto loc_82C9C6FC;
	case 22:
		goto loc_82C9C6FC;
	case 23:
		goto loc_82C9C6FC;
	case 24:
		goto loc_82C9C6FC;
	case 25:
		goto loc_82C9C6FC;
	case 26:
		goto loc_82C9C6FC;
	case 27:
		goto loc_82C9C6FC;
	case 28:
		goto loc_82C9C6FC;
	case 29:
		goto loc_82C9C6FC;
	case 30:
		goto loc_82C9C6FC;
	case 31:
		goto loc_82C9C6FC;
	case 32:
		goto loc_82C9C4D4;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-14456(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14456);
	// lwz r22,-14844(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14844);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14400(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14400);
	// lwz r22,-14364(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14364);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14892(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14892);
	// lwz r22,-14832(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14832);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14892(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14892);
	// lwz r22,-14772(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14772);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-14596(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14596);
	// lwz r22,-15148(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -15148);
loc_82C9C4D4:
	// lbz r11,488(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 488);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9c4ec
	if (!ctx.cr6.eq) goto loc_82C9C4EC;
	// lwz r11,144(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 144);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82c9c720
	if (ctx.cr6.eq) goto loc_82C9C720;
loc_82C9C4EC:
	// lwz r11,68(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 68);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r3,r29,416
	ctx.r3.s64 = ctx.r29.s64 + 416;
	// add r5,r11,r30
	ctx.r5.u64 = ctx.r11.u64 + ctx.r30.u64;
	// subf r6,r11,r10
	ctx.r6.s64 = ctx.r10.s64 - ctx.r11.s64;
	// bl 0x82c9b2f8
	ctx.lr = 0x82C9C508;
	sub_82C9B2F8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c9c5f0
	if (ctx.cr6.eq) goto loc_82C9C5F0;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r25,132
	ctx.r3.s64 = ctx.r25.s64 + 132;
	// bl 0x82c99298
	ctx.lr = 0x82C9C520;
	sub_82C99298(ctx, base);
	// lwz r11,432(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 432);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// stw r11,428(r29)
	PPC_STORE_U32(ctx.r29.u32 + 428, ctx.r11.u32);
	// beq cr6,0x82c9c738
	if (ctx.cr6.eq) goto loc_82C9C738;
	// lbz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9c750
	if (!ctx.cr6.eq) goto loc_82C9C750;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9c5a4
	if (ctx.cr6.eq) goto loc_82C9C5A4;
	// lwz r11,112(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 112);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9c598
	if (ctx.cr6.eq) goto loc_82C9C598;
	// stb r23,131(r25)
	PPC_STORE_U8(ctx.r25.u32 + 131, ctx.r23.u8);
	// li r4,0
	ctx.r4.s64 = 0;
	// stb r22,32(r31)
	PPC_STORE_U8(ctx.r31.u32 + 32, ctx.r22.u8);
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r3,116(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 116);
	// lwz r11,112(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 112);
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r6,16(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9C580;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// stb r23,32(r31)
	PPC_STORE_U8(ctx.r31.u32 + 32, ctx.r23.u8);
	// beq cr6,0x82c9c774
	if (ctx.cr6.eq) goto loc_82C9C774;
	// lbz r11,131(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 131);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9c6d0
	if (!ctx.cr6.eq) goto loc_82C9C6D0;
loc_82C9C598:
	// lbz r11,130(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 130);
	// stb r11,128(r25)
	PPC_STORE_U8(ctx.r25.u32 + 128, ctx.r11.u8);
	// b 0x82c9c6d0
	goto loc_82C9C6D0;
loc_82C9C5A4:
	// stb r22,32(r31)
	PPC_STORE_U8(ctx.r31.u32 + 32, ctx.r22.u8);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// add r6,r11,r5
	ctx.r6.u64 = ctx.r11.u64 + ctx.r5.u64;
	// lwz r4,228(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 228);
	// bl 0x82c9c3a8
	ctx.lr = 0x82C9C5C0;
	sub_82C9C3A8(ctx, base);
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// stb r23,32(r31)
	PPC_STORE_U8(ctx.r31.u32 + 32, ctx.r23.u8);
	// cmpwi cr6,r24,0
	ctx.cr6.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// bne cr6,0x82c9c710
	if (!ctx.cr6.eq) goto loc_82C9C710;
	// b 0x82c9c6d0
	goto loc_82C9C6D0;
loc_82C9C5D4:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c9b1a8
	ctx.lr = 0x82C9C5E8;
	sub_82C9B1A8(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82c9c6d0
	if (!ctx.cr6.eq) goto loc_82C9C6D0;
loc_82C9C5F0:
	// mr r24,r22
	ctx.r24.u64 = ctx.r22.u64;
	// stw r19,276(r29)
	PPC_STORE_U32(ctx.r29.u32 + 276, ctx.r19.u32);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c14
	// ERROR 82CA2C14
	return;
loc_82C9C604:
	// lwz r11,68(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 68);
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
loc_82C9C610:
	// lwz r11,8(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// lwz r10,12(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 12);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9c634
	if (!ctx.cr6.eq) goto loc_82C9C634;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c99808
	ctx.lr = 0x82C9C628;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9c5f0
	if (ctx.cr6.eq) goto loc_82C9C5F0;
loc_82C9C634:
	// lwz r11,12(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 12);
	// stb r20,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r20.u8);
	// lwz r11,12(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 12);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,12(r26)
	PPC_STORE_U32(ctx.r26.u32 + 12, ctx.r10.u32);
	// b 0x82c9c6d0
	goto loc_82C9C6D0;
loc_82C9C64C:
	// lwz r11,44(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 44);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9C660;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// blt cr6,0x82c9c79c
	if (ctx.cr6.lt) goto loc_82C9C79C;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// bl 0x82c97790
	ctx.lr = 0x82C9C670;
	sub_82C97790(ctx, base);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// cmpwi cr6,r28,0
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// beq cr6,0x82c9c79c
	if (ctx.cr6.eq) goto loc_82C9C79C;
	// mr r31,r23
	ctx.r31.u64 = ctx.r23.u64;
	// ble cr6,0x82c9c6d0
	if (!ctx.cr6.gt) goto loc_82C9C6D0;
loc_82C9C684:
	// lwz r11,8(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// lwz r10,12(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 12);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9c6a8
	if (!ctx.cr6.eq) goto loc_82C9C6A8;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82c99808
	ctx.lr = 0x82C9C69C;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9c5f0
	if (ctx.cr6.eq) goto loc_82C9C5F0;
loc_82C9C6A8:
	// addi r11,r1,84
	ctx.r11.s64 = ctx.r1.s64 + 84;
	// lwz r10,12(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 12);
	// lbzx r9,r31,r11
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + ctx.r11.u32);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmpw cr6,r31,r28
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r28.s32, ctx.xer);
	// stb r9,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r9.u8);
	// lwz r11,12(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 12);
	// addi r8,r11,1
	ctx.r8.s64 = ctx.r11.s64 + 1;
	// stw r8,12(r26)
	PPC_STORE_U32(ctx.r26.u32 + 12, ctx.r8.u32);
	// blt cr6,0x82c9c684
	if (ctx.cr6.lt) goto loc_82C9C684;
loc_82C9C6D0:
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r11,20(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9C6F0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addi r11,r3,4
	ctx.r11.s64 = ctx.r3.s64 + 4;
	// cmplwi cr6,r11,32
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 32, ctx.xer);
	// ble cr6,0x82c9c438
	if (!ctx.cr6.gt) goto loc_82C9C438;
loc_82C9C6FC:
	// lwz r11,144(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 144);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c70c
	if (!ctx.cr6.eq) goto loc_82C9C70C;
	// stw r30,288(r29)
	PPC_STORE_U32(ctx.r29.u32 + 288, ctx.r30.u32);
loc_82C9C70C:
	// li r24,23
	ctx.r24.s64 = 23;
loc_82C9C710:
	// stw r19,276(r29)
	PPC_STORE_U32(ctx.r29.u32 + 276, ctx.r19.u32);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c14
	// ERROR 82CA2C14
	return;
loc_82C9C720:
	// mr r24,r20
	ctx.r24.u64 = ctx.r20.u64;
	// stw r30,288(r29)
	PPC_STORE_U32(ctx.r29.u32 + 288, ctx.r30.u32);
	// stw r19,276(r29)
	PPC_STORE_U32(ctx.r29.u32 + 276, ctx.r19.u32);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c14
	// ERROR 82CA2C14
	return;
loc_82C9C738:
	// lbz r11,130(r25)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r25.u32 + 130);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// stb r11,128(r25)
	PPC_STORE_U8(ctx.r25.u32 + 128, ctx.r11.u8);
	// stw r19,276(r29)
	PPC_STORE_U32(ctx.r29.u32 + 276, ctx.r19.u32);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c14
	// ERROR 82CA2C14
	return;
loc_82C9C750:
	// lwz r11,144(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 144);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c760
	if (!ctx.cr6.eq) goto loc_82C9C760;
	// stw r30,288(r29)
	PPC_STORE_U32(ctx.r29.u32 + 288, ctx.r30.u32);
loc_82C9C760:
	// li r24,12
	ctx.r24.s64 = 12;
	// stw r19,276(r29)
	PPC_STORE_U32(ctx.r29.u32 + 276, ctx.r19.u32);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c14
	// ERROR 82CA2C14
	return;
loc_82C9C774:
	// li r24,21
	ctx.r24.s64 = 21;
	// stw r19,276(r29)
	PPC_STORE_U32(ctx.r29.u32 + 276, ctx.r19.u32);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c14
	// ERROR 82CA2C14
	return;
loc_82C9C788:
	// mr r24,r23
	ctx.r24.u64 = ctx.r23.u64;
	// stw r19,276(r29)
	PPC_STORE_U32(ctx.r29.u32 + 276, ctx.r19.u32);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c14
	// ERROR 82CA2C14
	return;
loc_82C9C79C:
	// lwz r11,144(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 144);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c7ac
	if (!ctx.cr6.eq) goto loc_82C9C7AC;
	// stw r30,288(r29)
	PPC_STORE_U32(ctx.r29.u32 + 288, ctx.r30.u32);
loc_82C9C7AC:
	// li r24,14
	ctx.r24.s64 = 14;
	// stw r19,276(r29)
	PPC_STORE_U32(ctx.r29.u32 + 276, ctx.r19.u32);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c14
	// ERROR 82CA2C14
	return;
loc_82C9C7C0:
	// lwz r11,144(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 144);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c7d0
	if (!ctx.cr6.eq) goto loc_82C9C7D0;
	// stw r30,288(r29)
	PPC_STORE_U32(ctx.r29.u32 + 288, ctx.r30.u32);
loc_82C9C7D0:
	// li r24,4
	ctx.r24.s64 = 4;
	// stw r19,276(r29)
	PPC_STORE_U32(ctx.r29.u32 + 276, ctx.r19.u32);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c14
	// ERROR 82CA2C14
	return;
loc_82C9C7E4:
	// lwz r11,144(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 144);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9c7f8
	if (!ctx.cr6.eq) goto loc_82C9C7F8;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,288(r29)
	PPC_STORE_U32(ctx.r29.u32 + 288, ctx.r11.u32);
loc_82C9C7F8:
	// li r24,4
	ctx.r24.s64 = 4;
	// stw r19,276(r29)
	PPC_STORE_U32(ctx.r29.u32 + 276, ctx.r19.u32);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x82ca2c14
	// ERROR 82CA2C14
	return;
}

__attribute__((alias("__imp__sub_82C9C80C"))) PPC_WEAK_FUNC(sub_82C9C80C);
PPC_FUNC_IMPL(__imp__sub_82C9C80C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9C810"))) PPC_WEAK_FUNC(sub_82C9C810);
PPC_FUNC_IMPL(__imp__sub_82C9C810) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C9C818;
	sub_82CA2BE0(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// lwz r11,64(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 64);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9c850
	if (!ctx.cr6.eq) goto loc_82C9C850;
	// lwz r11,80(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9c90c
	if (ctx.cr6.eq) goto loc_82C9C90C;
	// bl 0x82c98fd8
	ctx.lr = 0x82C9C844;
	sub_82C98FD8(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C9C850:
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// rlwinm r11,r11,1,0,30
	ctx.r11.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r29,r11,r5
	ctx.r29.u64 = ctx.r11.u64 + ctx.r5.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9C870;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// add r27,r3,r29
	ctx.r27.u64 = ctx.r3.u64 + ctx.r29.u64;
	// addi r28,r30,416
	ctx.r28.s64 = ctx.r30.s64 + 416;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82c9b2f8
	ctx.lr = 0x82C9C88C;
	sub_82C9B2F8(ctx, base);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82c9c8a4
	if (!ctx.cr6.eq) goto loc_82C9C8A4;
loc_82C9C898:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C9C8A4:
	// lwz r11,428(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 428);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,432(r30)
	PPC_STORE_U32(ctx.r30.u32 + 432, ctx.r11.u32);
	// lwz r10,68(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r8,36(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// subf r27,r9,r26
	ctx.r27.s64 = ctx.r26.s64 - ctx.r9.s64;
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82C9C8CC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// bl 0x82c9b2f8
	ctx.lr = 0x82C9C8E0;
	sub_82C9B2F8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82c9c898
	if (ctx.cr6.eq) goto loc_82C9C898;
	// bl 0x82c98f58
	ctx.lr = 0x82C9C8F0;
	sub_82C98F58(ctx, base);
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// lwz r11,64(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 64);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9C904;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82c99728
	ctx.lr = 0x82C9C90C;
	sub_82C99728(ctx, base);
loc_82C9C90C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
}

__attribute__((alias("__imp__sub_82C9C918"))) PPC_WEAK_FUNC(sub_82C9C918);
PPC_FUNC_IMPL(__imp__sub_82C9C918) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9c950
	if (!ctx.cr6.eq) goto loc_82C9C950;
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9c9a0
	if (ctx.cr6.eq) goto loc_82C9C9A0;
	// bl 0x82c98fd8
	ctx.lr = 0x82C9C94C;
	sub_82C98FD8(ctx, base);
	// b 0x82c9c9a0
	goto loc_82C9C9A0;
loc_82C9C950:
	// lwz r11,68(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 68);
	// addi r30,r31,416
	ctx.r30.s64 = ctx.r31.s64 + 416;
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// add r5,r10,r5
	ctx.r5.u64 = ctx.r10.u64 + ctx.r5.u64;
	// subf r6,r11,r6
	ctx.r6.s64 = ctx.r6.s64 - ctx.r11.s64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c9b2f8
	ctx.lr = 0x82C9C974;
	sub_82C9B2F8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82c9c9a4
	if (ctx.cr6.eq) goto loc_82C9C9A4;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// bl 0x82c98f58
	ctx.lr = 0x82C9C988;
	sub_82C98F58(ctx, base);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9C998;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82c99728
	ctx.lr = 0x82C9C9A0;
	sub_82C99728(ctx, base);
loc_82C9C9A0:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82C9C9A4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9C9BC"))) PPC_WEAK_FUNC(sub_82C9C9BC);
PPC_FUNC_IMPL(__imp__sub_82C9C9BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9C9C0"))) PPC_WEAK_FUNC(sub_82C9C9C0);
PPC_FUNC_IMPL(__imp__sub_82C9C9C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bd8
	ctx.lr = 0x82C9C9C8;
	sub_82CA2BD8(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// lwz r31,356(r27)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r27.u32 + 356);
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// lwz r10,88(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9ca04
	if (!ctx.cr6.eq) goto loc_82C9CA04;
	// addi r3,r31,80
	ctx.r3.s64 = ctx.r31.s64 + 80;
	// bl 0x82c99808
	ctx.lr = 0x82C9C9F8;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9ca7c
	if (ctx.cr6.eq) goto loc_82C9CA7C;
loc_82C9CA04:
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// li r24,0
	ctx.r24.s64 = 0;
	// addi r25,r31,80
	ctx.r25.s64 = ctx.r31.s64 + 80;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// stb r24,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r24.u8);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r10.u32);
	// bl 0x82c9b2f8
	ctx.lr = 0x82C9CA34;
	sub_82C9B2F8(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c9ca7c
	if (ctx.cr6.eq) goto loc_82C9CA7C;
	// addi r28,r3,1
	ctx.r28.s64 = ctx.r3.s64 + 1;
	// li r5,12
	ctx.r5.s64 = 12;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// addi r3,r31,40
	ctx.r3.s64 = ctx.r31.s64 + 40;
	// bl 0x82c99298
	ctx.lr = 0x82C9CA50;
	sub_82C99298(ctx, base);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82c9ca7c
	if (ctx.cr6.eq) goto loc_82C9CA7C;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82c9ca88
	if (ctx.cr6.eq) goto loc_82C9CA88;
	// lwz r11,96(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
loc_82C9CA6C:
	// stw r11,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r11.u32);
loc_82C9CA70:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
loc_82C9CA7C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
loc_82C9CA88:
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// stw r11,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r11.u32);
	// lbz r10,236(r27)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r27.u32 + 236);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c9ca70
	if (ctx.cr6.eq) goto loc_82C9CA70;
	// lbz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,120
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 120, ctx.xer);
	// bne cr6,0x82c9cb40
	if (!ctx.cr6.eq) goto loc_82C9CB40;
	// lbz r10,1(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 1);
	// cmplwi cr6,r10,109
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 109, ctx.xer);
	// bne cr6,0x82c9cb40
	if (!ctx.cr6.eq) goto loc_82C9CB40;
	// lbz r10,2(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 2);
	// cmplwi cr6,r10,108
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 108, ctx.xer);
	// bne cr6,0x82c9cb40
	if (!ctx.cr6.eq) goto loc_82C9CB40;
	// lbz r10,3(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 3);
	// cmplwi cr6,r10,110
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 110, ctx.xer);
	// bne cr6,0x82c9cb40
	if (!ctx.cr6.eq) goto loc_82C9CB40;
	// lbz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 4);
	// cmplwi cr6,r10,115
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 115, ctx.xer);
	// bne cr6,0x82c9cb40
	if (!ctx.cr6.eq) goto loc_82C9CB40;
	// lbz r10,5(r28)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r28.u32 + 5);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82c9cafc
	if (ctx.cr6.eq) goto loc_82C9CAFC;
	// cmpwi cr6,r10,58
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 58, ctx.xer);
	// bne cr6,0x82c9cb40
	if (!ctx.cr6.eq) goto loc_82C9CB40;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9cb18
	if (!ctx.cr6.eq) goto loc_82C9CB18;
loc_82C9CAFC:
	// addi r11,r31,152
	ctx.r11.s64 = ctx.r31.s64 + 152;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// stw r11,4(r26)
	PPC_STORE_U32(ctx.r26.u32 + 4, ctx.r11.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,9(r26)
	PPC_STORE_U8(ctx.r26.u32 + 9, ctx.r11.u8);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
loc_82C9CB18:
	// li r5,8
	ctx.r5.s64 = 8;
	// addi r4,r28,6
	ctx.r4.s64 = ctx.r28.s64 + 6;
	// addi r3,r31,60
	ctx.r3.s64 = ctx.r31.s64 + 60;
	// bl 0x82c99298
	ctx.lr = 0x82C9CB28;
	sub_82C99298(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r3,4(r26)
	PPC_STORE_U32(ctx.r26.u32 + 4, ctx.r3.u32);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// stb r11,9(r26)
	PPC_STORE_U8(ctx.r26.u32 + 9, ctx.r11.u8);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
loc_82C9CB40:
	// mr r29,r24
	ctx.r29.u64 = ctx.r24.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c9ca70
	if (ctx.cr6.eq) goto loc_82C9CA70;
loc_82C9CB4C:
	// cmpwi cr6,r11,58
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 58, ctx.xer);
	// beq cr6,0x82c9cb74
	if (ctx.cr6.eq) goto loc_82C9CB74;
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// lbzx r11,r29,r28
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + ctx.r28.u32);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c9cb4c
	if (!ctx.cr6.eq) goto loc_82C9CB4C;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
loc_82C9CB74:
	// mr r30,r24
	ctx.r30.u64 = ctx.r24.u64;
	// cmpwi cr6,r29,0
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// ble cr6,0x82c9cbc8
	if (!ctx.cr6.gt) goto loc_82C9CBC8;
loc_82C9CB80:
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// lwz r10,88(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9cba4
	if (!ctx.cr6.eq) goto loc_82C9CBA4;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82c99808
	ctx.lr = 0x82C9CB98;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9ca7c
	if (ctx.cr6.eq) goto loc_82C9CA7C;
loc_82C9CBA4:
	// lbzx r11,r30,r28
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + ctx.r28.u32);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// lwz r10,92(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// cmpw cr6,r30,r29
	ctx.cr6.compare<int32_t>(ctx.r30.s32, ctx.r29.s32, ctx.xer);
	// stb r11,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r11.u8);
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// stw r9,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r9.u32);
	// blt cr6,0x82c9cb80
	if (ctx.cr6.lt) goto loc_82C9CB80;
loc_82C9CBC8:
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// lwz r10,88(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9cbec
	if (!ctx.cr6.eq) goto loc_82C9CBEC;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82c99808
	ctx.lr = 0x82C9CBE0;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9ca7c
	if (ctx.cr6.eq) goto loc_82C9CA7C;
loc_82C9CBEC:
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// li r5,8
	ctx.r5.s64 = 8;
	// addi r3,r31,60
	ctx.r3.s64 = ctx.r31.s64 + 60;
	// stb r24,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r24.u8);
	// lwz r4,96(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r10.u32);
	// bl 0x82c99298
	ctx.lr = 0x82C9CC10;
	sub_82C99298(ctx, base);
	// stw r3,4(r26)
	PPC_STORE_U32(ctx.r26.u32 + 4, ctx.r3.u32);
	// lwz r11,96(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9ca6c
	if (!ctx.cr6.eq) goto loc_82C9CA6C;
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// stw r11,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r11.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x82ca2c28
	// ERROR 82CA2C28
	return;
}

__attribute__((alias("__imp__sub_82C9CC38"))) PPC_WEAK_FUNC(sub_82C9CC38);
PPC_FUNC_IMPL(__imp__sub_82C9CC38) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2bdc
	ctx.lr = 0x82C9CC40;
	sub_82CA2BDC(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r30
	ctx.r28.u64 = ctx.r30.u64;
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// lwz r27,356(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 356);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9cec0
	if (ctx.cr6.eq) goto loc_82C9CEC0;
	// li r26,0
	ctx.r26.s64 = 0;
	// li r25,1
	ctx.r25.s64 = 1;
loc_82C9CC68:
	// lbz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82c9ce44
	if (ctx.cr6.eq) goto loc_82C9CE44;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c9ce44
	if (ctx.cr6.eq) goto loc_82C9CE44;
	// cmpwi cr6,r11,61
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 61, ctx.xer);
	// bne cr6,0x82c9ce00
	if (!ctx.cr6.eq) goto loc_82C9CE00;
	// lwz r10,432(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 432);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// subf. r9,r10,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r10.s64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// bne 0x82c9cca0
	if (!ctx.cr0.eq) goto loc_82C9CCA0;
	// addi r29,r27,152
	ctx.r29.s64 = ctx.r27.s64 + 152;
	// b 0x82c9cd1c
	goto loc_82C9CD1C;
loc_82C9CCA0:
	// lwz r10,424(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9ccc0
	if (!ctx.cr6.eq) goto loc_82C9CCC0;
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99808
	ctx.lr = 0x82C9CCB4;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9cecc
	if (ctx.cr6.eq) goto loc_82C9CECC;
loc_82C9CCC0:
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// li r5,8
	ctx.r5.s64 = 8;
	// addi r3,r27,60
	ctx.r3.s64 = ctx.r27.s64 + 60;
	// stb r26,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r26.u8);
	// lwz r4,432(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 432);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r10.u32);
	// bl 0x82c99298
	ctx.lr = 0x82C9CCE4;
	sub_82C99298(ctx, base);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82c9cecc
	if (ctx.cr6.eq) goto loc_82C9CECC;
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lwz r11,432(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 432);
	// cmplw cr6,r4,r11
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9cd14
	if (!ctx.cr6.eq) goto loc_82C9CD14;
	// addi r3,r27,80
	ctx.r3.s64 = ctx.r27.s64 + 80;
	// bl 0x82c9b268
	ctx.lr = 0x82C9CD08;
	sub_82C9B268(ctx, base);
	// stw r3,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c9cecc
	if (ctx.cr6.eq) goto loc_82C9CECC;
loc_82C9CD14:
	// lwz r11,432(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 432);
	// stw r11,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r11.u32);
loc_82C9CD1C:
	// lbz r11,1(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 1);
	// addi r30,r28,1
	ctx.r30.s64 = ctx.r28.s64 + 1;
	// extsb r11,r11
	ctx.r11.s64 = ctx.r11.s8;
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// beq cr6,0x82c9cd88
	if (ctx.cr6.eq) goto loc_82C9CD88;
loc_82C9CD30:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c9cd88
	if (ctx.cr6.eq) goto loc_82C9CD88;
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// lwz r10,424(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9cd5c
	if (!ctx.cr6.eq) goto loc_82C9CD5C;
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99808
	ctx.lr = 0x82C9CD50;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9cecc
	if (ctx.cr6.eq) goto loc_82C9CECC;
loc_82C9CD5C:
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// lwz r10,428(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// stb r11,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r11.u8);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// stw r9,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r9.u32);
	// lbz r8,0(r30)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// extsb r11,r8
	ctx.r11.s64 = ctx.r8.s8;
	// cmpwi cr6,r11,12
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 12, ctx.xer);
	// bne cr6,0x82c9cd30
	if (!ctx.cr6.eq) goto loc_82C9CD30;
loc_82C9CD88:
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// lwz r10,424(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82c9cdac
	if (!ctx.cr6.eq) goto loc_82C9CDAC;
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99808
	ctx.lr = 0x82C9CDA0;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9cecc
	if (ctx.cr6.eq) goto loc_82C9CECC;
loc_82C9CDAC:
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// addi r7,r31,372
	ctx.r7.s64 = ctx.r31.s64 + 372;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stb r26,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r26.u8);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r10.u32);
	// lwz r6,432(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 432);
	// bl 0x82c98ad0
	ctx.lr = 0x82C9CDD8;
	sub_82C98AD0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c9cecc
	if (!ctx.cr6.eq) goto loc_82C9CECC;
	// lwz r11,432(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 432);
	// stw r11,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r11.u32);
	// lbz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82c9cdf8
	if (ctx.cr6.eq) goto loc_82C9CDF8;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
loc_82C9CDF8:
	// mr r28,r30
	ctx.r28.u64 = ctx.r30.u64;
	// b 0x82c9ceb4
	goto loc_82C9CEB4;
loc_82C9CE00:
	// lwz r11,424(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	// lwz r10,428(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9ce24
	if (!ctx.cr6.eq) goto loc_82C9CE24;
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99808
	ctx.lr = 0x82C9CE18;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9cecc
	if (ctx.cr6.eq) goto loc_82C9CECC;
loc_82C9CE24:
	// lbz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// lwz r10,428(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// stb r11,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r11.u8);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// stw r9,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r9.u32);
	// b 0x82c9ceb4
	goto loc_82C9CEB4;
loc_82C9CE44:
	// lwz r11,424(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	// lwz r10,428(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9ce68
	if (!ctx.cr6.eq) goto loc_82C9CE68;
	// addi r3,r31,416
	ctx.r3.s64 = ctx.r31.s64 + 416;
	// bl 0x82c99808
	ctx.lr = 0x82C9CE5C;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9cecc
	if (ctx.cr6.eq) goto loc_82C9CECC;
loc_82C9CE68:
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stb r26,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r26.u8);
	// lwz r11,428(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 428);
	// lwz r4,432(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 432);
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// stw r10,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r10.u32);
	// bl 0x82c99298
	ctx.lr = 0x82C9CE8C;
	sub_82C99298(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82c9ce98
	if (ctx.cr6.eq) goto loc_82C9CE98;
	// stb r25,32(r3)
	PPC_STORE_U8(ctx.r3.u32 + 32, ctx.r25.u8);
loc_82C9CE98:
	// lbz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9cea8
	if (ctx.cr6.eq) goto loc_82C9CEA8;
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
loc_82C9CEA8:
	// lwz r11,432(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 432);
	// mr r30,r28
	ctx.r30.u64 = ctx.r28.u64;
	// stw r11,428(r31)
	PPC_STORE_U32(ctx.r31.u32 + 428, ctx.r11.u32);
loc_82C9CEB4:
	// lbz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9cc68
	if (!ctx.cr6.eq) goto loc_82C9CC68;
loc_82C9CEC0:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	// ERROR 82CA2C2C
	return;
loc_82C9CECC:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c2c
	// ERROR 82CA2C2C
	return;
}

__attribute__((alias("__imp__sub_82C9CED8"))) PPC_WEAK_FUNC(sub_82C9CED8);
PPC_FUNC_IMPL(__imp__sub_82C9CED8) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9cf38
	if (ctx.cr6.eq) goto loc_82C9CF38;
	// cmpwi cr6,r4,18
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 18, ctx.xer);
	// beq cr6,0x82c9cf1c
	if (ctx.cr6.eq) goto loc_82C9CF1C;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9cf08
	if (!ctx.cr6.eq) goto loc_82C9CF08;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9cf08
	if (!ctx.cr6.eq) goto loc_82C9CF08;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9CF08:
	// lis r10,-31968
	ctx.r10.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r10,-11496
	ctx.r9.s64 = ctx.r10.s64 + -11496;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9CF1C:
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r9,11
	ctx.r9.s64 = 11;
	// addi r8,r10,-18696
	ctx.r8.s64 = ctx.r10.s64 + -18696;
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// li r3,16
	ctx.r3.s64 = 16;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// blr 
	return;
loc_82C9CF38:
	// li r3,11
	ctx.r3.s64 = 11;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9CF40"))) PPC_WEAK_FUNC(sub_82C9CF40);
PPC_FUNC_IMPL(__imp__sub_82C9CF40) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9cf98
	if (ctx.cr6.eq) goto loc_82C9CF98;
	// cmpwi cr6,r4,27
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 27, ctx.xer);
	// beq cr6,0x82c9cf84
	if (ctx.cr6.eq) goto loc_82C9CF84;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9cf70
	if (!ctx.cr6.eq) goto loc_82C9CF70;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9cf70
	if (!ctx.cr6.eq) goto loc_82C9CF70;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9CF70:
	// lis r10,-31968
	ctx.r10.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r10,-11496
	ctx.r9.s64 = ctx.r10.s64 + -11496;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9CF84:
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r3,13
	ctx.r3.s64 = 13;
	// addi r9,r10,-19120
	ctx.r9.s64 = ctx.r10.s64 + -19120;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9CF98:
	// li r3,11
	ctx.r3.s64 = 11;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9CFA0"))) PPC_WEAK_FUNC(sub_82C9CFA0);
PPC_FUNC_IMPL(__imp__sub_82C9CFA0) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9d000
	if (ctx.cr6.eq) goto loc_82C9D000;
	// cmpwi cr6,r4,27
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 27, ctx.xer);
	// beq cr6,0x82c9cfe4
	if (ctx.cr6.eq) goto loc_82C9CFE4;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9cfd0
	if (!ctx.cr6.eq) goto loc_82C9CFD0;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9cfd0
	if (!ctx.cr6.eq) goto loc_82C9CFD0;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9CFD0:
	// lis r10,-31968
	ctx.r10.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r10,-11496
	ctx.r9.s64 = ctx.r10.s64 + -11496;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9CFE4:
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r9,17
	ctx.r9.s64 = 17;
	// addi r8,r10,-18696
	ctx.r8.s64 = ctx.r10.s64 + -18696;
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// li r3,19
	ctx.r3.s64 = 19;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// blr 
	return;
loc_82C9D000:
	// li r3,17
	ctx.r3.s64 = 17;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9D008"))) PPC_WEAK_FUNC(sub_82C9D008);
PPC_FUNC_IMPL(__imp__sub_82C9D008) {
	PPC_FUNC_PROLOGUE();
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9d0a4
	if (ctx.cr6.eq) goto loc_82C9D0A4;
	// cmpwi cr6,r4,17
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 17, ctx.xer);
	// beq cr6,0x82c9d070
	if (ctx.cr6.eq) goto loc_82C9D070;
	// cmpwi cr6,r4,27
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 27, ctx.xer);
	// beq cr6,0x82c9d054
	if (ctx.cr6.eq) goto loc_82C9D054;
	// lwz r11,16(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c9d040
	if (!ctx.cr6.eq) goto loc_82C9D040;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9d040
	if (!ctx.cr6.eq) goto loc_82C9D040;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9D040:
	// lis r11,-31968
	ctx.r11.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r11,-11496
	ctx.r9.s64 = ctx.r11.s64 + -11496;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9D054:
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// li r9,17
	ctx.r9.s64 = 17;
	// addi r8,r11,-18696
	ctx.r8.s64 = ctx.r11.s64 + -18696;
	// stw r9,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r9.u32);
	// li r3,19
	ctx.r3.s64 = 19;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// blr 
	return;
loc_82C9D070:
	// lwz r11,16(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c9d090
	if (ctx.cr6.eq) goto loc_82C9D090;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// li r3,20
	ctx.r3.s64 = 20;
	// addi r11,r11,7224
	ctx.r11.s64 = ctx.r11.s64 + 7224;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r11.u32);
	// blr 
	return;
loc_82C9D090:
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// li r3,20
	ctx.r3.s64 = 20;
	// addi r11,r11,7832
	ctx.r11.s64 = ctx.r11.s64 + 7832;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r11.u32);
	// blr 
	return;
loc_82C9D0A4:
	// li r3,17
	ctx.r3.s64 = 17;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9D0AC"))) PPC_WEAK_FUNC(sub_82C9D0AC);
PPC_FUNC_IMPL(__imp__sub_82C9D0AC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9D0B0"))) PPC_WEAK_FUNC(sub_82C9D0B0);
PPC_FUNC_IMPL(__imp__sub_82C9D0B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C9D0B8;
	sub_82CA2BE0(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r31,r7
	ctx.r31.u64 = ctx.r7.u64;
	// cmpwi cr6,r27,15
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 15, ctx.xer);
	// beq cr6,0x82c9d1bc
	if (ctx.cr6.eq) goto loc_82C9D1BC;
	// cmpwi cr6,r27,20
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 20, ctx.xer);
	// beq cr6,0x82c9d100
	if (ctx.cr6.eq) goto loc_82C9D100;
	// cmpwi cr6,r27,27
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 27, ctx.xer);
	// bne cr6,0x82c9d1c8
	if (!ctx.cr6.eq) goto loc_82C9D1C8;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// li r3,37
	ctx.r3.s64 = 37;
	// addi r10,r11,6656
	ctx.r10.s64 = ctx.r11.s64 + 6656;
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C9D100:
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// addi r30,r11,3128
	ctx.r30.s64 = ctx.r11.s64 + 3128;
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r6,r30,36
	ctx.r6.s64 = ctx.r30.s64 + 36;
	// add r4,r11,r29
	ctx.r4.u64 = ctx.r11.u64 + ctx.r29.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9D128;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9d148
	if (ctx.cr6.eq) goto loc_82C9D148;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// li r3,35
	ctx.r3.s64 = 35;
	// addi r10,r11,6656
	ctx.r10.s64 = ctx.r11.s64 + 6656;
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C9D148:
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// addi r6,r30,108
	ctx.r6.s64 = ctx.r30.s64 + 108;
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// add r4,r11,r29
	ctx.r4.u64 = ctx.r11.u64 + ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9D168;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9d188
	if (ctx.cr6.eq) goto loc_82C9D188;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// li r3,36
	ctx.r3.s64 = 36;
	// addi r10,r11,6656
	ctx.r10.s64 = ctx.r11.s64 + 6656;
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C9D188:
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// add r4,r11,r29
	ctx.r4.u64 = ctx.r11.u64 + ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9D1A8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9d1c8
	if (ctx.cr6.eq) goto loc_82C9D1C8;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r10,r11,-18992
	ctx.r10.s64 = ctx.r11.s64 + -18992;
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
loc_82C9D1BC:
	// li r3,33
	ctx.r3.s64 = 33;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C9D1C8:
	// lwz r11,16(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c9d1e8
	if (!ctx.cr6.eq) goto loc_82C9D1E8;
	// cmpwi cr6,r27,28
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 28, ctx.xer);
	// bne cr6,0x82c9d1e8
	if (!ctx.cr6.eq) goto loc_82C9D1E8;
	// li r3,59
	ctx.r3.s64 = 59;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C9D1E8:
	// lis r11,-31968
	ctx.r11.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r10,r11,-11496
	ctx.r10.s64 = ctx.r11.s64 + -11496;
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
}

__attribute__((alias("__imp__sub_82C9D200"))) PPC_WEAK_FUNC(sub_82C9D200);
PPC_FUNC_IMPL(__imp__sub_82C9D200) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9d274
	if (ctx.cr6.eq) goto loc_82C9D274;
	// cmpwi cr6,r4,21
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 21, ctx.xer);
	// beq cr6,0x82c9d268
	if (ctx.cr6.eq) goto loc_82C9D268;
	// cmpwi cr6,r4,36
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 36, ctx.xer);
	// beq cr6,0x82c9d24c
	if (ctx.cr6.eq) goto loc_82C9D24C;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9d238
	if (!ctx.cr6.eq) goto loc_82C9D238;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9d238
	if (!ctx.cr6.eq) goto loc_82C9D238;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9D238:
	// lis r10,-31968
	ctx.r10.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r10,-11496
	ctx.r9.s64 = ctx.r10.s64 + -11496;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9D24C:
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r9,39
	ctx.r9.s64 = 39;
	// addi r8,r10,-18696
	ctx.r8.s64 = ctx.r10.s64 + -18696;
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// li r3,46
	ctx.r3.s64 = 46;
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
	// blr 
	return;
loc_82C9D268:
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// addi r9,r10,-9576
	ctx.r9.s64 = ctx.r10.s64 + -9576;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
loc_82C9D274:
	// li r3,39
	ctx.r3.s64 = 39;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9D27C"))) PPC_WEAK_FUNC(sub_82C9D27C);
PPC_FUNC_IMPL(__imp__sub_82C9D27C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9D280"))) PPC_WEAK_FUNC(sub_82C9D280);
PPC_FUNC_IMPL(__imp__sub_82C9D280) {
	PPC_FUNC_PROLOGUE();
	// addi r10,r4,-15
	ctx.r10.s64 = ctx.r4.s64 + -15;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r10,23
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 23, ctx.xer);
	// bgt cr6,0x82c9d3e8
	if (ctx.cr6.gt) {
		sub_82C9D3E8(ctx, base);
		return;
	}
	// lis r12,-32054
	ctx.r12.s64 = -2100690944;
	// addi r12,r12,-11608
	ctx.r12.s64 = ctx.r12.s64 + -11608;
	// rlwinm r0,r10,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		// ERROR: 0x82C9D308
		return;
	case 1:
		// ERROR: 0x82C9D3E8
		return;
	case 2:
		// ERROR: 0x82C9D3E8
		return;
	case 3:
		// ERROR: 0x82C9D3E8
		return;
	case 4:
		// ERROR: 0x82C9D3E8
		return;
	case 5:
		// ERROR: 0x82C9D3E8
		return;
	case 6:
		// ERROR: 0x82C9D3D4
		return;
	case 7:
		// ERROR: 0x82C9D3E8
		return;
	case 8:
		// ERROR: 0x82C9D3E8
		return;
	case 9:
		// ERROR: 0x82C9D310
		return;
	case 10:
		// ERROR: 0x82C9D3E8
		return;
	case 11:
		// ERROR: 0x82C9D3E8
		return;
	case 12:
		// ERROR: 0x82C9D3E8
		return;
	case 13:
		// ERROR: 0x82C9D3E8
		return;
	case 14:
		// ERROR: 0x82C9D3E8
		return;
	case 15:
		// ERROR: 0x82C9D3E8
		return;
	case 16:
		// ERROR: 0x82C9D3E8
		return;
	case 17:
		// ERROR: 0x82C9D3E8
		return;
	case 18:
		// ERROR: 0x82C9D3E8
		return;
	case 19:
		// ERROR: 0x82C9D3E8
		return;
	case 20:
		// ERROR: 0x82C9D368
		return;
	case 21:
		// ERROR: 0x82C9D33C
		return;
	case 22:
		// ERROR: 0x82C9D394
		return;
	case 23:
		// ERROR: 0x82C9D3C0
		return;
	default:
		__builtin_unreachable();
	}
}

__attribute__((alias("__imp__sub_82C9D2A8"))) PPC_WEAK_FUNC(sub_82C9D2A8);
PPC_FUNC_IMPL(__imp__sub_82C9D2A8) {
	PPC_FUNC_PROLOGUE();
	// lwz r22,-11512(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11512);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11308(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11308);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11504(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11504);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11288(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11288);
	// lwz r22,-11416(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11416);
	// lwz r22,-11460(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11460);
	// lwz r22,-11372(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11372);
	// lwz r22,-11328(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -11328);
	// li r3,39
	ctx.r3.s64 = 39;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9D310"))) PPC_WEAK_FUNC(sub_82C9D310);
PPC_FUNC_IMPL(__imp__sub_82C9D310) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
	// bne 0x82c9d334
	if (!ctx.cr0.eq) goto loc_82C9D334;
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r9,39
	ctx.r9.s64 = 39;
	// addi r8,r10,-18696
	ctx.r8.s64 = ctx.r10.s64 + -18696;
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
loc_82C9D334:
	// li r3,45
	ctx.r3.s64 = 45;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9D33C"))) PPC_WEAK_FUNC(sub_82C9D33C);
PPC_FUNC_IMPL(__imp__sub_82C9D33C) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
	// bne 0x82c9d360
	if (!ctx.cr0.eq) goto loc_82C9D360;
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r9,39
	ctx.r9.s64 = 39;
	// addi r8,r10,-18696
	ctx.r8.s64 = ctx.r10.s64 + -18696;
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
loc_82C9D360:
	// li r3,46
	ctx.r3.s64 = 46;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9D368"))) PPC_WEAK_FUNC(sub_82C9D368);
PPC_FUNC_IMPL(__imp__sub_82C9D368) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
	// bne 0x82c9d38c
	if (!ctx.cr0.eq) goto loc_82C9D38C;
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r9,39
	ctx.r9.s64 = 39;
	// addi r8,r10,-18696
	ctx.r8.s64 = ctx.r10.s64 + -18696;
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
loc_82C9D38C:
	// li r3,47
	ctx.r3.s64 = 47;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9D394"))) PPC_WEAK_FUNC(sub_82C9D394);
PPC_FUNC_IMPL(__imp__sub_82C9D394) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addic. r10,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
	// bne 0x82c9d3b8
	if (!ctx.cr0.eq) goto loc_82C9D3B8;
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r9,39
	ctx.r9.s64 = 39;
	// addi r8,r10,-18696
	ctx.r8.s64 = ctx.r10.s64 + -18696;
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
loc_82C9D3B8:
	// li r3,48
	ctx.r3.s64 = 48;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9D3C0"))) PPC_WEAK_FUNC(sub_82C9D3C0);
PPC_FUNC_IMPL(__imp__sub_82C9D3C0) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r3,50
	ctx.r3.s64 = 50;
	// addi r9,r10,-9472
	ctx.r9.s64 = ctx.r10.s64 + -9472;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9D3D4"))) PPC_WEAK_FUNC(sub_82C9D3D4);
PPC_FUNC_IMPL(__imp__sub_82C9D3D4) {
	PPC_FUNC_PROLOGUE();
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r3,49
	ctx.r3.s64 = 49;
	// addi r9,r10,-9472
	ctx.r9.s64 = ctx.r10.s64 + -9472;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9D3E8"))) PPC_WEAK_FUNC(sub_82C9D3E8);
PPC_FUNC_IMPL(__imp__sub_82C9D3E8) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9d404
	if (!ctx.cr6.eq) goto loc_82C9D404;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9d404
	if (!ctx.cr6.eq) goto loc_82C9D404;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9D404:
	// lis r10,-31968
	ctx.r10.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r10,-11496
	ctx.r9.s64 = ctx.r10.s64 + -11496;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9D418"))) PPC_WEAK_FUNC(sub_82C9D418);
PPC_FUNC_IMPL(__imp__sub_82C9D418) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be0
	ctx.lr = 0x82C9D420;
	sub_82CA2BE0(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r31,r7
	ctx.r31.u64 = ctx.r7.u64;
	// cmpwi cr6,r27,15
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 15, ctx.xer);
	// beq cr6,0x82c9d480
	if (ctx.cr6.eq) goto loc_82C9D480;
	// cmpwi cr6,r27,18
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 18, ctx.xer);
	// bne cr6,0x82c9d4c8
	if (!ctx.cr6.eq) goto loc_82C9D4C8;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// addi r30,r11,3156
	ctx.r30.s64 = ctx.r11.s64 + 3156;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r6,r30,16
	ctx.r6.s64 = ctx.r30.s64 + 16;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9D46C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9d48c
	if (ctx.cr6.eq) goto loc_82C9D48C;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r10,r11,-18896
	ctx.r10.s64 = ctx.r11.s64 + -18896;
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
loc_82C9D480:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C9D48C:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// bctrl 
	ctx.lr = 0x82C9D4A8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9d4c8
	if (ctx.cr6.eq) goto loc_82C9D4C8;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r10,r11,-18792
	ctx.r10.s64 = ctx.r11.s64 + -18792;
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C9D4C8:
	// lwz r11,16(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c9d4e8
	if (!ctx.cr6.eq) goto loc_82C9D4E8;
	// cmpwi cr6,r27,28
	ctx.cr6.compare<int32_t>(ctx.r27.s32, 28, ctx.xer);
	// bne cr6,0x82c9d4e8
	if (!ctx.cr6.eq) goto loc_82C9D4E8;
	// li r3,59
	ctx.r3.s64 = 59;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
loc_82C9D4E8:
	// lis r11,-31968
	ctx.r11.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r10,r11,-11496
	ctx.r10.s64 = ctx.r11.s64 + -11496;
	// stw r10,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r10.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c30
	// ERROR 82CA2C30
	return;
}

__attribute__((alias("__imp__sub_82C9D500"))) PPC_WEAK_FUNC(sub_82C9D500);
PPC_FUNC_IMPL(__imp__sub_82C9D500) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x82ca2be4
	ctx.lr = 0x82C9D508;
	sub_82CA2BE4(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// li r28,0
	ctx.r28.s64 = 0;
	// addi r10,r11,-11008
	ctx.r10.s64 = ctx.r11.s64 + -11008;
	// lwz r3,144(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// stw r30,288(r31)
	PPC_STORE_U32(ctx.r31.u32 + 288, ctx.r30.u32);
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stw r10,280(r31)
	PPC_STORE_U32(ctx.r31.u32 + 280, ctx.r10.u32);
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x82C9D548;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r3,15
	ctx.r11.s64 = ctx.r3.s64 + 15;
	// cmplwi cr6,r11,30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 30, ctx.xer);
	// stw r6,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r6.u32);
	// bgt cr6,0x82c9d694
	if (ctx.cr6.gt) goto loc_82C9D694;
loc_82C9D55C:
	// lis r12,-32054
	ctx.r12.s64 = -2100690944;
	// addi r12,r12,-10892
	ctx.r12.s64 = ctx.r12.s64 + -10892;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = __builtin_rotateleft64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_82C9D6A0;
	case 1:
		goto loc_82C9D694;
	case 2:
		goto loc_82C9D694;
	case 3:
		goto loc_82C9D694;
	case 4:
		goto loc_82C9D694;
	case 5:
		goto loc_82C9D694;
	case 6:
		goto loc_82C9D694;
	case 7:
		goto loc_82C9D694;
	case 8:
		goto loc_82C9D694;
	case 9:
		goto loc_82C9D694;
	case 10:
		goto loc_82C9D694;
	case 11:
		goto loc_82C9D6E8;
	case 12:
		goto loc_82C9D694;
	case 13:
		goto loc_82C9D72C;
	case 14:
		goto loc_82C9D714;
	case 15:
		goto loc_82C9D704;
	case 16:
		goto loc_82C9D694;
	case 17:
		goto loc_82C9D694;
	case 18:
		goto loc_82C9D694;
	case 19:
		goto loc_82C9D694;
	case 20:
		goto loc_82C9D694;
	case 21:
		goto loc_82C9D694;
	case 22:
		goto loc_82C9D694;
	case 23:
		goto loc_82C9D694;
	case 24:
		goto loc_82C9D694;
	case 25:
		goto loc_82C9D694;
	case 26:
		goto loc_82C9D610;
	case 27:
		goto loc_82C9D694;
	case 28:
		goto loc_82C9D624;
	case 29:
		goto loc_82C9D694;
	case 30:
		goto loc_82C9D5F0;
	default:
		__builtin_unreachable();
	}
	// lwz r22,-10592(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10592);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10520(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10520);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10452(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10452);
	// lwz r22,-10476(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10476);
	// lwz r22,-10492(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10492);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10736(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10736);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10716(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10716);
	// lwz r22,-10604(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10604);
	// lwz r22,-10768(r9)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r9.u32 + -10768);
loc_82C9D5F0:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9d640
	if (ctx.cr6.eq) goto loc_82C9D640;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,144(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c98fd8
	ctx.lr = 0x82C9D60C;
	sub_82C98FD8(ctx, base);
	// b 0x82c9d63c
	goto loc_82C9D63C;
loc_82C9D610:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,144(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c9c810
	ctx.lr = 0x82C9D620;
	sub_82C9C810(ctx, base);
	// b 0x82c9d634
	goto loc_82C9D634;
loc_82C9D624:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,144(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c9c918
	ctx.lr = 0x82C9D634;
	sub_82C9C918(ctx, base);
loc_82C9D634:
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9d6f8
	if (ctx.cr6.eq) goto loc_82C9D6F8;
loc_82C9D63C:
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82C9D640:
	// lwz r11,480(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// stw r6,288(r31)
	PPC_STORE_U32(ctx.r31.u32 + 288, ctx.r6.u32);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x82c9d6c8
	if (ctx.cr6.eq) goto loc_82C9D6C8;
	// cmpwi cr6,r11,3
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 3, ctx.xer);
	// beq cr6,0x82c9d6d8
	if (ctx.cr6.eq) goto loc_82C9D6D8;
	// lwz r11,144(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9D680;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r3,15
	ctx.r11.s64 = ctx.r3.s64 + 15;
	// cmplwi cr6,r11,30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 30, ctx.xer);
	// stw r6,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r6.u32);
	// ble cr6,0x82c9d55c
	if (!ctx.cr6.gt) goto loc_82C9D55C;
loc_82C9D694:
	// li r3,9
	ctx.r3.s64 = 9;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
loc_82C9D6A0:
	// lwz r11,80(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9d6d8
	if (ctx.cr6.eq) goto loc_82C9D6D8;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,144(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 144);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c98fd8
	ctx.lr = 0x82C9D6BC;
	sub_82C98FD8(ctx, base);
	// lwz r11,480(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 480);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// bne cr6,0x82c9d6d4
	if (!ctx.cr6.eq) goto loc_82C9D6D4;
loc_82C9D6C8:
	// li r3,35
	ctx.r3.s64 = 35;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
loc_82C9D6D4:
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82C9D6D8:
	// stw r6,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r6.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
loc_82C9D6E8:
	// stw r30,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r30.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
loc_82C9D6F8:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
loc_82C9D704:
	// stw r6,288(r31)
	PPC_STORE_U32(ctx.r31.u32 + 288, ctx.r6.u32);
	// li r3,4
	ctx.r3.s64 = 4;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
loc_82C9D714:
	// lbz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 484);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9d6e8
	if (ctx.cr6.eq) goto loc_82C9D6E8;
	// li r3,5
	ctx.r3.s64 = 5;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
loc_82C9D72C:
	// lbz r11,484(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 484);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9d6e8
	if (ctx.cr6.eq) goto loc_82C9D6E8;
	// li r3,6
	ctx.r3.s64 = 6;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x82ca2c34
	// ERROR 82CA2C34
	return;
}

__attribute__((alias("__imp__sub_82C9D744"))) PPC_WEAK_FUNC(sub_82C9D744);
PPC_FUNC_IMPL(__imp__sub_82C9D744) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9D748"))) PPC_WEAK_FUNC(sub_82C9D748);
PPC_FUNC_IMPL(__imp__sub_82C9D748) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r31,r8
	ctx.r31.u64 = ctx.r8.u64;
	// bl 0x82c9be58
	ctx.lr = 0x82C9D768;
	sub_82C9BE58(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x82c9d7e0
	if (!ctx.cr6.eq) goto loc_82C9D7E0;
	// clrlwi r11,r30,24
	ctx.r11.u64 = ctx.r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82c9d7a0
	if (!ctx.cr6.eq) goto loc_82C9D7A0;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// subf. r9,r10,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r10.s64;
	ctx.cr0.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq 0x82c9d7a0
	if (ctx.cr0.eq) goto loc_82C9D7A0;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,32
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 32, ctx.xer);
	// bne cr6,0x82c9d7a0
	if (!ctx.cr6.eq) goto loc_82C9D7A0;
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
loc_82C9D7A0:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82c9d7c4
	if (!ctx.cr6.eq) goto loc_82C9D7C4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82c99808
	ctx.lr = 0x82C9D7B8;
	sub_82C99808(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82c9d7f8
	if (ctx.cr6.eq) goto loc_82C9D7F8;
loc_82C9D7C4:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stb r10,0(r11)
	PPC_STORE_U8(ctx.r11.u32 + 0, ctx.r10.u8);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// stw r9,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r9.u32);
loc_82C9D7E0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C9D7F8:
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82c9d7e0
	goto loc_82C9D7E0;
}

__attribute__((alias("__imp__sub_82C9D800"))) PPC_WEAK_FUNC(sub_82C9D800);
PPC_FUNC_IMPL(__imp__sub_82C9D800) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// cmpwi cr6,r31,15
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 15, ctx.xer);
	// beq cr6,0x82c9d868
	if (ctx.cr6.eq) goto loc_82C9D868;
	// cmpwi cr6,r31,17
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 17, ctx.xer);
	// beq cr6,0x82c9d8b4
	if (ctx.cr6.eq) goto loc_82C9D8B4;
	// cmpwi cr6,r31,18
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 18, ctx.xer);
	// bne cr6,0x82c9d884
	if (!ctx.cr6.eq) goto loc_82C9D884;
	// lis r11,-32255
	ctx.r11.s64 = -2113863680;
	// lwz r10,28(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 28);
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// addi r6,r11,3180
	ctx.r6.s64 = ctx.r11.s64 + 3180;
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82C9D854;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82c9d884
	if (ctx.cr6.eq) goto loc_82C9D884;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// addi r10,r11,-12584
	ctx.r10.s64 = ctx.r11.s64 + -12584;
	// stw r10,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r10.u32);
loc_82C9D868:
	// li r3,11
	ctx.r3.s64 = 11;
loc_82C9D86C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82C9D884:
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82c9d8a0
	if (!ctx.cr6.eq) goto loc_82C9D8A0;
	// cmpwi cr6,r31,28
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 28, ctx.xer);
	// bne cr6,0x82c9d8a0
	if (!ctx.cr6.eq) goto loc_82C9D8A0;
	// li r3,59
	ctx.r3.s64 = 59;
	// b 0x82c9d86c
	goto loc_82C9D86C;
loc_82C9D8A0:
	// lis r11,-31968
	ctx.r11.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r10,r11,-11496
	ctx.r10.s64 = ctx.r11.s64 + -11496;
	// stw r10,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r10.u32);
	// b 0x82c9d86c
	goto loc_82C9D86C;
loc_82C9D8B4:
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82c9d8d4
	if (ctx.cr6.eq) goto loc_82C9D8D4;
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// li r3,15
	ctx.r3.s64 = 15;
	// addi r11,r11,7224
	ctx.r11.s64 = ctx.r11.s64 + 7224;
	// stw r11,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r11.u32);
	// b 0x82c9d86c
	goto loc_82C9D86C;
loc_82C9D8D4:
	// lis r11,-32054
	ctx.r11.s64 = -2100690944;
	// li r3,15
	ctx.r3.s64 = 15;
	// addi r11,r11,7832
	ctx.r11.s64 = ctx.r11.s64 + 7832;
	// stw r11,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r11.u32);
	// b 0x82c9d86c
	goto loc_82C9D86C;
}

__attribute__((alias("__imp__sub_82C9D8E8"))) PPC_WEAK_FUNC(sub_82C9D8E8);
PPC_FUNC_IMPL(__imp__sub_82C9D8E8) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9d940
	if (ctx.cr6.eq) goto loc_82C9D940;
	// cmpwi cr6,r4,27
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 27, ctx.xer);
	// beq cr6,0x82c9d92c
	if (ctx.cr6.eq) goto loc_82C9D92C;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9d918
	if (!ctx.cr6.eq) goto loc_82C9D918;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9d918
	if (!ctx.cr6.eq) goto loc_82C9D918;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9D918:
	// lis r10,-31968
	ctx.r10.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r10,-11496
	ctx.r9.s64 = ctx.r10.s64 + -11496;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9D92C:
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r3,14
	ctx.r3.s64 = 14;
	// addi r9,r10,-12480
	ctx.r9.s64 = ctx.r10.s64 + -12480;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9D940:
	// li r3,11
	ctx.r3.s64 = 11;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9D948"))) PPC_WEAK_FUNC(sub_82C9D948);
PPC_FUNC_IMPL(__imp__sub_82C9D948) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9d9a0
	if (ctx.cr6.eq) goto loc_82C9D9A0;
	// cmpwi cr6,r4,27
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 27, ctx.xer);
	// beq cr6,0x82c9d98c
	if (ctx.cr6.eq) goto loc_82C9D98C;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9d978
	if (!ctx.cr6.eq) goto loc_82C9D978;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9d978
	if (!ctx.cr6.eq) goto loc_82C9D978;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9D978:
	// lis r10,-31968
	ctx.r10.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r10,-11496
	ctx.r9.s64 = ctx.r10.s64 + -11496;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9D98C:
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r3,21
	ctx.r3.s64 = 21;
	// addi r9,r10,-12280
	ctx.r9.s64 = ctx.r10.s64 + -12280;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9D9A0:
	// li r3,17
	ctx.r3.s64 = 17;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9D9A8"))) PPC_WEAK_FUNC(sub_82C9D9A8);
PPC_FUNC_IMPL(__imp__sub_82C9D9A8) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9da14
	if (ctx.cr6.eq) goto loc_82C9DA14;
	// cmpwi cr6,r4,21
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 21, ctx.xer);
	// beq cr6,0x82c9da08
	if (ctx.cr6.eq) goto loc_82C9DA08;
	// cmpwi cr6,r4,24
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 24, ctx.xer);
	// beq cr6,0x82c9d9f4
	if (ctx.cr6.eq) goto loc_82C9D9F4;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9d9e0
	if (!ctx.cr6.eq) goto loc_82C9D9E0;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9d9e0
	if (!ctx.cr6.eq) goto loc_82C9D9E0;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9D9E0:
	// lis r10,-31968
	ctx.r10.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r10,-11496
	ctx.r9.s64 = ctx.r10.s64 + -11496;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9D9F4:
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r3,33
	ctx.r3.s64 = 33;
	// addi r9,r10,-12112
	ctx.r9.s64 = ctx.r10.s64 + -12112;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9DA08:
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// addi r9,r10,-6024
	ctx.r9.s64 = ctx.r10.s64 + -6024;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
loc_82C9DA14:
	// li r3,33
	ctx.r3.s64 = 33;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9DA1C"))) PPC_WEAK_FUNC(sub_82C9DA1C);
PPC_FUNC_IMPL(__imp__sub_82C9DA1C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82C9DA20"))) PPC_WEAK_FUNC(sub_82C9DA20);
PPC_FUNC_IMPL(__imp__sub_82C9DA20) {
	PPC_FUNC_PROLOGUE();
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,15
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 15, ctx.xer);
	// beq cr6,0x82c9da8c
	if (ctx.cr6.eq) goto loc_82C9DA8C;
	// cmpwi cr6,r4,21
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 21, ctx.xer);
	// beq cr6,0x82c9da80
	if (ctx.cr6.eq) goto loc_82C9DA80;
	// cmpwi cr6,r4,24
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 24, ctx.xer);
	// beq cr6,0x82c9da6c
	if (ctx.cr6.eq) goto loc_82C9DA6C;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// bne cr6,0x82c9da58
	if (!ctx.cr6.eq) goto loc_82C9DA58;
	// cmpwi cr6,r4,28
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 28, ctx.xer);
	// bne cr6,0x82c9da58
	if (!ctx.cr6.eq) goto loc_82C9DA58;
	// li r3,59
	ctx.r3.s64 = 59;
	// blr 
	return;
loc_82C9DA58:
	// lis r10,-31968
	ctx.r10.s64 = -2095054848;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r9,r10,-11496
	ctx.r9.s64 = ctx.r10.s64 + -11496;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9DA6C:
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// li r3,33
	ctx.r3.s64 = 33;
	// addi r9,r10,-12112
	ctx.r9.s64 = ctx.r10.s64 + -12112;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_82C9DA80:
	// lis r10,-32054
	ctx.r10.s64 = -2100690944;
	// addi r9,r10,-5800
	ctx.r9.s64 = ctx.r10.s64 + -5800;
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
loc_82C9DA8C:
	// li r3,33
	ctx.r3.s64 = 33;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82C9DA94"))) PPC_WEAK_FUNC(sub_82C9DA94);
PPC_FUNC_IMPL(__imp__sub_82C9DA94) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

